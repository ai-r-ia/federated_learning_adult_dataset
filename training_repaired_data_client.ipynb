{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cb54a96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T12:48:49.512456Z",
     "start_time": "2021-07-15T12:48:46.946937Z"
    }
   },
   "source": [
    "Repairing the dataset at client level.\n",
    "\n",
    "Note: This has not been implemented in this notebook. To implement please make changes to the architecture and distribute the dataframe amongst clients before converting it into batched datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0b816358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U numpy\n",
    "# !python -c \"import numpy;print(numpy.__version__);print(numpy.__file__)\";\n",
    "# !python -m pip install numpy -I\n",
    "# !pip install numpy==1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "09b7dd46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:57:57.590963Z",
     "start_time": "2021-07-15T23:57:57.572204Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.metrics import precision_score,recall_score, accuracy_score,confusion_matrix,f1_score\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import History\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "00b9bf6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:52.574848Z",
     "start_time": "2021-07-15T23:59:52.208912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'age',\n",
       " 'fnlwgt',\n",
       " 'education',\n",
       " 'educational-num',\n",
       " 'capital-gain',\n",
       " 'capital-loss',\n",
       " 'hours-per-week',\n",
       " 'marital-status_Divorced',\n",
       " 'marital-status_Married-AF-spouse',\n",
       " 'marital-status_Married-civ-spouse',\n",
       " 'marital-status_Married-spouse-absent',\n",
       " 'marital-status_Never-married',\n",
       " 'marital-status_Separated',\n",
       " 'marital-status_Widowed',\n",
       " 'occupation_?',\n",
       " 'occupation_Adm-clerical',\n",
       " 'occupation_Armed-Forces',\n",
       " 'occupation_Craft-repair',\n",
       " 'occupation_Exec-managerial',\n",
       " 'occupation_Farming-fishing',\n",
       " 'occupation_Handlers-cleaners',\n",
       " 'occupation_Machine-op-inspct',\n",
       " 'occupation_Other-service',\n",
       " 'occupation_Priv-house-serv',\n",
       " 'occupation_Prof-specialty',\n",
       " 'occupation_Protective-serv',\n",
       " 'occupation_Sales',\n",
       " 'occupation_Tech-support',\n",
       " 'occupation_Transport-moving',\n",
       " 'relationship_Husband',\n",
       " 'relationship_Not-in-family',\n",
       " 'relationship_Other-relative',\n",
       " 'relationship_Own-child',\n",
       " 'relationship_Unmarried',\n",
       " 'relationship_Wife',\n",
       " 'workclass_?',\n",
       " 'workclass_Federal-gov',\n",
       " 'workclass_Local-gov',\n",
       " 'workclass_Never-worked',\n",
       " 'workclass_Private',\n",
       " 'workclass_Self-emp-inc',\n",
       " 'workclass_Self-emp-not-inc',\n",
       " 'workclass_State-gov',\n",
       " 'workclass_Without-pay',\n",
       " 'race_Amer-Indian-Eskimo',\n",
       " 'race_Asian-Pac-Islander',\n",
       " 'race_Black',\n",
       " 'race_Other',\n",
       " 'race_White',\n",
       " 'gender_Female',\n",
       " 'gender_Male',\n",
       " 'native-country_?',\n",
       " 'native-country_Cambodia',\n",
       " 'native-country_Canada',\n",
       " 'native-country_China',\n",
       " 'native-country_Columbia',\n",
       " 'native-country_Cuba',\n",
       " 'native-country_Dominican-Republic',\n",
       " 'native-country_Ecuador',\n",
       " 'native-country_El-Salvador',\n",
       " 'native-country_England',\n",
       " 'native-country_France',\n",
       " 'native-country_Germany',\n",
       " 'native-country_Greece',\n",
       " 'native-country_Guatemala',\n",
       " 'native-country_Haiti',\n",
       " 'native-country_Holand-Netherlands',\n",
       " 'native-country_Honduras',\n",
       " 'native-country_Hong',\n",
       " 'native-country_Hungary',\n",
       " 'native-country_India',\n",
       " 'native-country_Iran',\n",
       " 'native-country_Ireland',\n",
       " 'native-country_Italy',\n",
       " 'native-country_Jamaica',\n",
       " 'native-country_Japan',\n",
       " 'native-country_Laos',\n",
       " 'native-country_Mexico',\n",
       " 'native-country_Nicaragua',\n",
       " 'native-country_Outlying-US(Guam-USVI-etc)',\n",
       " 'native-country_Peru',\n",
       " 'native-country_Philippines',\n",
       " 'native-country_Poland',\n",
       " 'native-country_Portugal',\n",
       " 'native-country_Puerto-Rico',\n",
       " 'native-country_Scotland',\n",
       " 'native-country_South',\n",
       " 'native-country_Taiwan',\n",
       " 'native-country_Thailand',\n",
       " 'native-country_Trinadad&Tobago',\n",
       " 'native-country_United-States',\n",
       " 'native-country_Vietnam',\n",
       " 'native-country_Yugoslavia']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Train/Test Data seperation\n",
    "\n",
    "file_out = pd.read_csv('Data/adult_processed.csv')\n",
    "cols = []\n",
    "\n",
    "for i in list(file_out.columns):\n",
    "    if  i != 'income':\n",
    "        cols.append(i)\n",
    "\n",
    "feature_set1 = pd.read_csv('Data/train.csv')\n",
    "feature_set2 = pd.read_csv('Data/test.csv')\n",
    "\n",
    "x = feature_set1[cols]\n",
    "y = feature_set1[['income']]\n",
    "        \n",
    "sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(x)\n",
    "X_train = x\n",
    "y_train = y\n",
    "\n",
    "x2 = feature_set2[cols]\n",
    "y2 = feature_set2[['income']]\n",
    "        \n",
    "# X_test = sc.fit_transform(x2)\n",
    "X_test = x2\n",
    "y_test = y2\n",
    "# print(\"in sdg!  x_test \", type(X_test))\n",
    "\n",
    "# X_test.shape, y_test.shape \n",
    "# if cols == cols_train:\n",
    "#     print(\"yes\")\n",
    "# diff = np.setdiff1d(cols_train,cols)\n",
    "# diff\n",
    "# feature_set1\n",
    "cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3c0f2a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_clients = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "76379dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender split\n",
    "\n",
    "dict_users = {i: np.array([]) for i in range(10)}\n",
    "data_out = []\n",
    "\n",
    "def create_hetero_clients( image_list, label_list, start_client = 0, num_clients=10, initial='clients'):\n",
    "    \n",
    "    selected_inds = []\n",
    "\n",
    "    max_y = np.argmax(label_list, axis=-1)\n",
    "    sorted_zip = sorted(zip(max_y, label_list, image_list), key=lambda x: x[0])\n",
    "    data = [(x,y) for _,y,x in sorted_zip]\n",
    "    \n",
    "    data_out = data\n",
    "    \n",
    "    num_shards, num_imgs = int(len(image_list)/30), 30\n",
    "    idx_shard = [i for i in range(num_shards)]\n",
    "\n",
    "    min_shard = 1\n",
    "    max_shard = 60  #953/15 = 63.53\n",
    "    \n",
    "    random_shard_size = np.random.randint(min_shard, max_shard+1,\n",
    "                                          size=(num_clients-start_client))\n",
    "    random_shard_size = np.around(random_shard_size /\n",
    "                                  sum(random_shard_size) * num_shards)\n",
    "    random_shard_size = random_shard_size.astype(int)\n",
    "\n",
    "\n",
    "    if sum(random_shard_size) > num_shards:\n",
    "        \n",
    "        for i in range(start_client, num_clients):\n",
    "            # First assign each client 1 shard to ensure every client has\n",
    "            # atleast one shard of data\n",
    "            rand_set = set(np.random.choice(idx_shard, 1, replace=False))\n",
    "            idx_shard = list(set(idx_shard) - rand_set)\n",
    "            for rand in rand_set:\n",
    "                ind1 = rand*num_imgs\n",
    "                ind2 = (rand+1)*num_imgs\n",
    "                if(len(dict_users[i]) == 0):\n",
    "                    dict_users[i] = data[ind1: ind2]\n",
    "                else:\n",
    "                    dict_users[i] = np.concatenate(\n",
    "                    (dict_users[i],data[ind1: ind2]),\n",
    "                    axis=0)\n",
    "                selected_inds.extend([[ind1, ind2]])\n",
    "\n",
    "        random_shard_size = random_shard_size-1\n",
    "\n",
    "        # Next, randomly assign the remaining shards\n",
    "        for i in range(start_client, num_clients):\n",
    "            if len(idx_shard) == 0:\n",
    "                continue\n",
    "#             print(random_shard_size)\n",
    "            shard_size = random_shard_size[i-start_client]\n",
    "            if shard_size > len(idx_shard):\n",
    "                shard_size = len(idx_shard)\n",
    "            rand_set = set(np.random.choice(idx_shard, shard_size,\n",
    "                                            replace=False))\n",
    "            idx_shard = list(set(idx_shard) - rand_set)\n",
    "            for rand in rand_set:\n",
    "                ind1 = rand*num_imgs\n",
    "                ind2 = (rand+1)*num_imgs\n",
    "                if(len(dict_users[i]) == 0):\n",
    "                    dict_users[i] = data[ind1: ind2]\n",
    "                else:\n",
    "                    dict_users[i] = np.concatenate(\n",
    "                    (dict_users[i],data[ind1: ind2]),\n",
    "                    axis=0)\n",
    "                selected_inds.extend([[ind1, ind2]])\n",
    "\n",
    "    else:\n",
    "\n",
    "        for i in range(start_client, num_clients):\n",
    "#             print(random_shard_size)\n",
    "            shard_size = random_shard_size[i-start_client]\n",
    "#             shard_size = random_shard_size[int(i/len(random_shard_size)) - 1]\n",
    "            rand_set = set(np.random.choice(idx_shard, shard_size,\n",
    "                                            replace=False))\n",
    "            idx_shard = list(set(idx_shard) - rand_set)\n",
    "            for rand in rand_set:\n",
    "                ind1 = rand*num_imgs\n",
    "                ind2 = (rand+1)*num_imgs\n",
    "                if(len(dict_users[i]) == 0):\n",
    "                    dict_users[i] = data[ind1: ind2]\n",
    "                else:\n",
    "                    dict_users[i] = np.concatenate(\n",
    "                    (dict_users[i],data[ind1: ind2]),\n",
    "                    axis=0)\n",
    "                selected_inds.extend([[ind1, ind2]])\n",
    "\n",
    "        if len(idx_shard) > 0:\n",
    "            # Add the leftover shards to the client with minimum images:\n",
    "            shard_size = len(idx_shard)\n",
    "            # Add the remaining shard to the client with lowest data\n",
    "            k = min(dict_users, key=lambda x: len(dict_users.get(x)))\n",
    "            rand_set = set(np.random.choice(idx_shard, shard_size,\n",
    "                                            replace=False))\n",
    "            idx_shard = list(set(idx_shard) - rand_set)\n",
    "            for rand in rand_set:\n",
    "                ind1 = rand*num_imgs\n",
    "                ind2 = (rand+1)*num_imgs\n",
    "                if(len(dict_users[k]) == 0):\n",
    "                    dict_users[k] = data[ind1: ind2]\n",
    "                else:\n",
    "                    dict_users[k] = np.concatenate(\n",
    "                    (dict_users[k],data[ind1: ind2]),\n",
    "                    axis=0)\n",
    "                selected_inds.extend([[ind1, ind2]])\n",
    "                \n",
    "                \n",
    "    return dict_users, selected_inds, data_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6cdec0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "dict_users = {i: np.array([]) for i in range(no_clients)}\n",
    "\n",
    "def create_client_iid(image_list, label_list, client_num):    \n",
    "#     max_y = np.argmax(label_list, axis=-1)\n",
    "#     sorted_zip = sorted(zip(max_y, label_list, image_list), key=lambda x: x[0])\n",
    "#     data = [(x,y) for _,y,x in sorted_zip]\n",
    "    \n",
    "#     dict_users[client_num] = data\n",
    "    size  = len(label_list) / (client_num)\n",
    "    # print(math.floor(size))\n",
    "    for i in range(client_num):\n",
    "        dict_users[i] = pd.concat([image_list,label_list], \n",
    "                  axis = 1).head(math.floor(size))\n",
    "#     print(\"disease \",dict_users[client_num])    \n",
    "    return dict_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fb1235d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function differs from all other files sincehere dataframes are being returned instead of list of values\n",
    "def initializer_income():\n",
    "    \n",
    "    x_feats = feature_set1[cols]\n",
    "    y_feats = feature_set1[['income']]\n",
    "\n",
    "    X_train_new = x_feats\n",
    "    y_train_new = y_feats\n",
    "    # print(\"in initializewr!  x_test \", type(X_test))\n",
    "#     print(y_train_new)\n",
    "    return [X_train_new, y_train_new]\n",
    "    \n",
    "#     x_feats = feature_set1[cols].copy()\n",
    "#     y_feats = feature_set1[['income']].copy()\n",
    "\n",
    "\n",
    "#     return [x_feats, y_feats]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a4278841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hetero_clients_gender(train_sets):\n",
    "    \n",
    "#     print(train_sets[0])\n",
    "#     print(train_sets[1])\n",
    "    data = pd.concat([train_sets[0], train_sets[1]], \n",
    "                  axis = 1)\n",
    "    data = data.sample(frac = 1)\n",
    "#     data = list(zip(train_sets[0], train_sets[1]))\n",
    "#     random.shuffle(data)\n",
    "#     print(data[cols])\n",
    "#     print(type(train_sets), type(train_sets[0]),type(list(list(zip(*data))[0]) ), type(data))\n",
    "    \n",
    "#     train_sets[0] = list(list(zip(*data))[0])\n",
    "#     train_sets[1] = list(list(zip(*data))[1])\n",
    "    \n",
    "    train_sets[0] = data[cols]\n",
    "    train_sets[1] = data[['income']]\n",
    "#     print(train_sets[0])\n",
    "#     print(train_sets[1])\n",
    "    \n",
    "#     NON_IID\n",
    "#     clients, inds, data_out1 = create_hetero_clients(train_sets[0], train_sets[1], start_client = 0, num_clients=10, initial='client') \n",
    "#     print(\"data_out1\")\n",
    "#     print(type(data_out1))\n",
    "#     print(data_out1[0])\n",
    "\n",
    "# #     IID\n",
    "    clients = create_client_iid(train_sets[0], train_sets[1], no_clients)\n",
    "    # print(\"in get_cls!  x_test \", type(X_test))\n",
    "    \n",
    "#     clients2 = create_client_iid(train_sets[2], train_sets[3], 1)\n",
    "#     clients = {**clients, **clients2}\n",
    "    \n",
    "#     clients3 = create_client_iid(train_sets[4], train_sets[5], 2)\n",
    "#     clients = {**clients, **clients3}\n",
    "    \n",
    "#     clients4 = create_client_iid(train_sets[6], train_sets[7], 3)\n",
    "#     clients = {**clients, **clients4}\n",
    "    \n",
    "\n",
    "    \n",
    "    return clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "715ed657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:52.579114Z",
     "start_time": "2021-07-15T23:59:52.576244Z"
    }
   },
   "outputs": [],
   "source": [
    "# take bs = 128 for 5 clients and 10 rounds\n",
    "def batch_data(data_shard, bs=64):\n",
    "    '''Takes in a clients data shard and create a tfds object off it\n",
    "    args:\n",
    "        shard: a data, label constituting a client's data shard\n",
    "        bs:batch size\n",
    "    return:\n",
    "        tfds object'''\n",
    "    # print(type(data_shard))\n",
    "#     data = []\n",
    "#     label = []\n",
    "#     for x in data_shard:\n",
    "#         data.append(x[0])\n",
    "#         label.append(x[1])\n",
    "    #seperate shard into data and labels lists\n",
    "#     data, label = zip(*data_shard)\n",
    "#     print(type(data[0][0]))\n",
    "#     print(\"data: \", data)\n",
    "#     print(\"label: \", label[0])\n",
    "    dataset = data_shard.sample(frac = 1).head(bs)\n",
    "#     dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
    "#     print( label[0])\n",
    "#     return dataset.shuffle(len(label)).batch(bs)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dfd80728",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:54.563066Z",
     "start_time": "2021-07-15T23:59:52.773340Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#process and batch the training data for each client\n",
    "def batch_clients(clients):\n",
    "    clients_batched = dict()\n",
    "    for (client_name, data) in clients.items():\n",
    "        # print(\"client \", client_name ,\" data \",type(data))\n",
    "#         clients_batched[client_name] = data[126:]#non-IID\n",
    "\n",
    "        clients_batched[client_name] = batch_data(data,126)#non-IID\n",
    "#         clients_batched[client_name] = batch_data(data,1) #IID\n",
    "    \n",
    "\n",
    "    #process and batch the test set  \n",
    "\n",
    "    # test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))\n",
    "    # print(\"in batch!  x_test \", type(X_test))\n",
    "    test_batched = (X_test, y_test)\n",
    "    \n",
    "#     test_batched\n",
    "    return clients_batched, test_batched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9dcf2ff7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:54.568193Z",
     "start_time": "2021-07-15T23:59:54.564443Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleMLP:\n",
    "    @staticmethod\n",
    "    def build(shape, classes=2 , learning_rate = 0.001, metric = \"accuracy\"):\n",
    "\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128, input_shape = (shape,)))\n",
    "#         model.add(Dense(128, Activation(\"relu\")))\n",
    "#         model.add(Dense(64, Activation(\"relu\")))\n",
    "#         model.add(Dense(32, Activation(\"relu\")))\n",
    "#         model.add(Dense(1))\n",
    "        \n",
    "        model.add(Dense(128, Activation(\"tanh\")))\n",
    "        model.add(Dense(64, Activation(\"tanh\")))\n",
    "        model.add(Dense(32, Activation(\"tanh\")))\n",
    "        model.add(Dense(1,Activation('sigmoid')))\n",
    "        \n",
    "\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f71dc14a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:00:30.156165Z",
     "start_time": "2021-07-16T00:00:30.152576Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.005\n",
    "comms_round = 10\n",
    "loss=tf.keras.losses.BinaryCrossentropy(from_logits = False)\n",
    "\n",
    "metrics = ['binary_accuracy']\n",
    "\n",
    "optimizer = SGD(learning_rate=lr, \n",
    "                decay=lr / comms_round, \n",
    "                momentum=0.5\n",
    "               )     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "eebf9376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:00:30.412962Z",
     "start_time": "2021-07-16T00:00:30.399142Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def weight_scalling_factor(fitter):\n",
    "    # client_names = list(clients_trn_data.keys())\n",
    "    #get the bs\n",
    "#     print(len(clients_trn_data[client_name]))\n",
    "    # bs = len(clients_trn_data[client_name])\n",
    "    bs = list(fitter)[0][0].shape[0]\n",
    "    #first calculate the total training data points across clinets\n",
    "    global_count = sum([tf.data.experimental.cardinality(fitter).numpy() ])*bs\n",
    "    # get the total number of data points held by a client\n",
    "    local_count = tf.data.experimental.cardinality(fitter).numpy()*bs\n",
    "    return local_count/global_count\n",
    "\n",
    "\n",
    "def scale_model_weights(weight, scalar):\n",
    "    '''function for scaling a models weights'''\n",
    "    weight_final = []\n",
    "    steps = len(weight)\n",
    "    for i in range(steps):\n",
    "        weight_final.append(scalar * weight[i])\n",
    "    return weight_final\n",
    "\n",
    "\n",
    "\n",
    "def sum_scaled_weights(scaled_weight_list):\n",
    "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
    "    avg_grad = list()\n",
    "    #get the average grad accross all client gradients\n",
    "#     print(len(scaled_weight_list))\n",
    "    for grad_list_tuple in zip(*scaled_weight_list):\n",
    "#         print(len(grad_list_tuple))\n",
    "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
    "        avg_grad.append(layer_mean)\n",
    "        \n",
    "    return avg_grad\n",
    "\n",
    "\n",
    "def test_model(X_test, Y_test,  model, comm_round):\n",
    "    \n",
    "#     cce = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "#     cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    logits = model.predict(X_test)\n",
    "\n",
    "    score = global_model.evaluate(X_test, y_test, verbose=0)\n",
    "    acc = score[1] ; loss = score[0]\n",
    "    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n",
    "\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9dd79b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# female_features =  feature_set1[feature_set1['gender_Female']==1]\n",
    "# final_female  = pd.DataFrame()\n",
    "# for i in range(10): \n",
    "#     female_fts = female_features[female_features[\"fnlwgt\"]<= female_quantiles[i]]\n",
    "#     female_fts[\"fnlwgt\"] = quantiles[i]\n",
    "    \n",
    "    \n",
    "#     print(female_fts.index)\n",
    "#     female_features = female_features.drop(female_fts.index)\n",
    "#     print(\"\\n\")\n",
    "#     print((female_features.shape), final_female.shape)\n",
    "#     final_female = pd.concat([final_female, female_fts])\n",
    "#     print(female_fts[\"fnlwgt\"], female_quantiles[i])\n",
    "    \n",
    "# male_features = feature_set1[feature_set1['gender_Male']==1] \n",
    "# final_male  = pd.DataFrame()\n",
    "# for i in range(10): \n",
    "#     male_fts = male_features[male_features[\"fnlwgt\"]<= male_quantiles[i]]\n",
    "#     male_fts[\"fnlwgt\"] = quantiles[i]\n",
    "    \n",
    "    \n",
    "# #     print(male_fts.index)\n",
    "#     male_features = male_features.drop(male_fts.index)\n",
    "# #     print(\"\\n\")\n",
    "# #     print((male_features.shape), final_male.shape)\n",
    "#     final_male = pd.concat([final_male, male_fts])\n",
    "    \n",
    "    \n",
    "#     repaired_data = pd.DataFrame()\n",
    "# repaired_data = pd.concat([final_male, final_female])\n",
    "# repaired_data = shuffle(repaired_data)\n",
    "# sensitive_atrributes =  [ 'age',\n",
    "#     'race_Amer-Indian-Eskimo',\n",
    "#     'race_Asian-Pac-Islander',\n",
    "#     'race_Black',\n",
    "#     'race_Other',\n",
    "#     'race_White',\n",
    "#     'gender_Female',\n",
    "#     'gender_Male']\n",
    "# for i in sensitive_atrributes: \n",
    "#     repaired_data[i] = 0\n",
    "    \n",
    "#     repaired_data = repaired_data.drop('Unnamed: 0', axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ab5179d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DI(df):\n",
    "#     print((df[df[['gender_Female']]==1].dropna()))\n",
    "    df1 = df.loc[df['gender_Female']==1]\n",
    "#     print(df1)\n",
    "    sensitive = len(df.loc[(df['gender_Female']==1) & (df['income']==1)])\n",
    "    base = len(df.loc[(df['gender_Male']==1) & (df['income']==1)])\n",
    "    # print(sensitive)\n",
    "    # print(base) \n",
    "    \n",
    "    return sensitive/base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4aef41d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:01:47.756094Z",
     "start_time": "2021-07-16T00:00:30.586083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7936 - binary_accuracy: 0.4444\n",
      "client 7 \n",
      "loss --> [0.7935681343078613] \n",
      "freq-> [126] \n",
      "accuracy-> [0.4444444477558136] \n",
      "DI--> [0.34782608695652173]\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7791 - binary_accuracy: 0.4683\n",
      "client 1 \n",
      "loss --> [0.7790867686271667] \n",
      "freq-> [126] \n",
      "accuracy-> [0.4682539701461792] \n",
      "DI--> [0.15384615384615385]\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8160 - binary_accuracy: 0.4683\n",
      "client 6 \n",
      "loss --> [0.8160042762756348] \n",
      "freq-> [126] \n",
      "accuracy-> [0.4682539701461792] \n",
      "DI--> [0.5882352941176471]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7849 - binary_accuracy: 0.4286\n",
      "client 2 \n",
      "loss --> [0.7849360108375549] \n",
      "freq-> [126] \n",
      "accuracy-> [0.4285714328289032] \n",
      "DI--> [0.21875]\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8219 - binary_accuracy: 0.4206\n",
      "client 0 \n",
      "loss --> [0.8219147324562073] \n",
      "freq-> [126] \n",
      "accuracy-> [0.420634925365448] \n",
      "DI--> [0.08823529411764706]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7723 - binary_accuracy: 0.4841\n",
      "client 9 \n",
      "loss --> [0.772266685962677] \n",
      "freq-> [126] \n",
      "accuracy-> [0.4841269850730896] \n",
      "DI--> [0.13793103448275862]\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8026 - binary_accuracy: 0.4286\n",
      "client 3 \n",
      "loss --> [0.8026105165481567] \n",
      "freq-> [126] \n",
      "accuracy-> [0.4285714328289032] \n",
      "DI--> [0.3076923076923077]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8185 - binary_accuracy: 0.4127\n",
      "client 4 \n",
      "loss --> [0.8185461759567261] \n",
      "freq-> [126] \n",
      "accuracy-> [0.4126984179019928] \n",
      "DI--> [0.10344827586206896]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7897 - binary_accuracy: 0.4841\n",
      "client 5 \n",
      "loss --> [0.7897441983222961] \n",
      "freq-> [126] \n",
      "accuracy-> [0.4841269850730896] \n",
      "DI--> [0.16666666666666666]\n",
      "1/1 [==============================] - 0s 958us/step - loss: 0.7544 - binary_accuracy: 0.4841\n",
      "client 8 \n",
      "loss --> [0.7543772459030151] \n",
      "freq-> [126] \n",
      "accuracy-> [0.4841269850730896] \n",
      "DI--> [0.13636363636363635]\n",
      "comm_round: 0 | global_acc: 47.195% | global_loss: 5.813995361328125\n",
      "global_loss_list:  [5.813995361328125]\n",
      "global_acc_list:  [0.4719492197036743]\n",
      "global_freq_list:  [1260]\n",
      "global_di_list:  [0.18661257606490872]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.1481 - binary_accuracy: 0.5000\n",
      "client 0 \n",
      "loss --> [0.82191473 5.14807892] \n",
      "freq-> [126 126] \n",
      "accuracy-> [0.42063493 0.5       ] \n",
      "DI--> [0.08823529 0.17241379]\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.0658 - binary_accuracy: 0.5238\n",
      "client 3 \n",
      "loss --> [0.80261052 5.06576204] \n",
      "freq-> [126 126] \n",
      "accuracy-> [0.42857143 0.52380955] \n",
      "DI--> [0.30769231 0.04347826]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.2744 - binary_accuracy: 0.4444\n",
      "client 5 \n",
      "loss --> [0.7897442  6.27440405] \n",
      "freq-> [126 126] \n",
      "accuracy-> [0.48412699 0.44444445] \n",
      "DI--> [0.16666667 0.11538462]\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9517 - binary_accuracy: 0.4524\n",
      "client 6 \n",
      "loss --> [0.81600428 6.95172691] \n",
      "freq-> [126 126] \n",
      "accuracy-> [0.46825397 0.45238096] \n",
      "DI--> [0.58823529 0.25      ]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7709 - binary_accuracy: 0.5159\n",
      "client 4 \n",
      "loss --> [0.81854618 5.77085161] \n",
      "freq-> [126 126] \n",
      "accuracy-> [0.41269842 0.51587301] \n",
      "DI--> [0.10344828 0.33333333]\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2415 - binary_accuracy: 0.4524\n",
      "client 8 \n",
      "loss --> [0.75437725 5.24154329] \n",
      "freq-> [126 126] \n",
      "accuracy-> [0.48412699 0.45238096] \n",
      "DI--> [0.13636364 0.25925926]\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.6231 - binary_accuracy: 0.4524\n",
      "client 2 \n",
      "loss --> [0.78493601 5.6230526 ] \n",
      "freq-> [126 126] \n",
      "accuracy-> [0.42857143 0.45238096] \n",
      "DI--> [0.21875    0.35714286]\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5817 - binary_accuracy: 0.4921\n",
      "client 1 \n",
      "loss --> [0.77908677 5.58165359] \n",
      "freq-> [126 126] \n",
      "accuracy-> [0.46825397 0.49206349] \n",
      "DI--> [0.15384615 0.04761905]\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.4886 - binary_accuracy: 0.4365\n",
      "client 9 \n",
      "loss --> [0.77226669 5.488554  ] \n",
      "freq-> [126 126] \n",
      "accuracy-> [0.48412699 0.43650794] \n",
      "DI--> [0.13793103 0.375     ]\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9758 - binary_accuracy: 0.5476\n",
      "client 7 \n",
      "loss --> [0.79356813 4.97581959] \n",
      "freq-> [126 126] \n",
      "accuracy-> [0.44444445 0.54761904] \n",
      "DI--> [0.34782609 0.13043478]\n",
      "comm_round: 1 | global_acc: 47.369% | global_loss: 58.23781204223633\n",
      "global_loss_list:  [5.813995361328125, 58.23781204223633]\n",
      "global_acc_list:  [0.4719492197036743, 0.47368958592414856]\n",
      "global_freq_list:  [1260, 1260]\n",
      "global_di_list:  [0.18661257606490872, 0.18661257606490872]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 58.3665 - binary_accuracy: 0.4444\n",
      "client 7 \n",
      "loss --> [ 0.79356813  4.97581959 58.36645126] \n",
      "freq-> [126 126 126] \n",
      "accuracy-> [0.44444445 0.54761904 0.44444445] \n",
      "DI--> [0.34782609 0.13043478 0.19354839]\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 56.4449 - binary_accuracy: 0.4365\n",
      "client 4 \n",
      "loss --> [ 0.81854618  5.77085161 56.44488525] \n",
      "freq-> [126 126 126] \n",
      "accuracy-> [0.41269842 0.51587301 0.43650794] \n",
      "DI--> [0.10344828 0.33333333 0.07692308]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 57.8398 - binary_accuracy: 0.5159\n",
      "client 3 \n",
      "loss --> [ 0.80261052  5.06576204 57.83975601] \n",
      "freq-> [126 126 126] \n",
      "accuracy-> [0.42857143 0.52380955 0.51587301] \n",
      "DI--> [0.30769231 0.04347826 0.17241379]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 51.1115 - binary_accuracy: 0.5159\n",
      "client 2 \n",
      "loss --> [ 0.78493601  5.6230526  51.11152649] \n",
      "freq-> [126 126 126] \n",
      "accuracy-> [0.42857143 0.45238096 0.51587301] \n",
      "DI--> [0.21875    0.35714286 0.09375   ]\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 57.7234 - binary_accuracy: 0.4762\n",
      "client 1 \n",
      "loss --> [ 0.77908677  5.58165359 57.72340775] \n",
      "freq-> [126 126 126] \n",
      "accuracy-> [0.46825397 0.49206349 0.47619048] \n",
      "DI--> [0.15384615 0.04761905 0.28      ]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 58.2194 - binary_accuracy: 0.4762\n",
      "client 9 \n",
      "loss --> [ 0.77226669  5.488554   58.21939468] \n",
      "freq-> [126 126 126] \n",
      "accuracy-> [0.48412699 0.43650794 0.47619048] \n",
      "DI--> [0.13793103 0.375      0.21052632]\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 60.9078 - binary_accuracy: 0.4603\n",
      "client 6 \n",
      "loss --> [ 0.81600428  6.95172691 60.90775681] \n",
      "freq-> [126 126 126] \n",
      "accuracy-> [0.46825397 0.45238096 0.46031746] \n",
      "DI--> [0.58823529 0.25       0.12820513]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 65.5615 - binary_accuracy: 0.5079\n",
      "client 5 \n",
      "loss --> [ 0.7897442   6.27440405 65.56147003] \n",
      "freq-> [126 126 126] \n",
      "accuracy-> [0.48412699 0.44444445 0.50793654] \n",
      "DI--> [0.16666667 0.11538462 0.19230769]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 50.5377 - binary_accuracy: 0.4603\n",
      "client 0 \n",
      "loss --> [ 0.82191473  5.14807892 50.53765488] \n",
      "freq-> [126 126 126] \n",
      "accuracy-> [0.42063493 0.5        0.46031746] \n",
      "DI--> [0.08823529 0.17241379 0.08108108]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 60.1871 - binary_accuracy: 0.5000\n",
      "client 8 \n",
      "loss --> [ 0.75437725  5.24154329 60.18710327] \n",
      "freq-> [126 126 126] \n",
      "accuracy-> [0.48412699 0.45238096 0.5       ] \n",
      "DI--> [0.13636364 0.25925926 0.34482759]\n",
      "comm_round: 2 | global_acc: 47.441% | global_loss: 588.8887939453125\n",
      "global_loss_list:  [5.813995361328125, 58.23781204223633, 588.8887939453125]\n",
      "global_acc_list:  [0.4719492197036743, 0.47368958592414856, 0.4744062125682831]\n",
      "global_freq_list:  [1260, 1260, 1260]\n",
      "global_di_list:  [0.18661257606490872, 0.18661257606490872, 0.18661257606490872]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 601.0320 - binary_accuracy: 0.4365\n",
      "client 2 \n",
      "loss --> [  0.78493601   5.6230526   51.11152649 601.03204346] \n",
      "freq-> [126 126 126 126] \n",
      "accuracy-> [0.42857143 0.45238096 0.51587301 0.43650794] \n",
      "DI--> [0.21875    0.35714286 0.09375    0.03846154]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 587.1890 - binary_accuracy: 0.4603\n",
      "client 3 \n",
      "loss --> [  0.80261052   5.06576204  57.83975601 587.18902588] \n",
      "freq-> [126 126 126 126] \n",
      "accuracy-> [0.42857143 0.52380955 0.51587301 0.46031746] \n",
      "DI--> [0.30769231 0.04347826 0.17241379 0.13333333]\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 731.6632 - binary_accuracy: 0.3810\n",
      "client 9 \n",
      "loss --> [  0.77226669   5.488554    58.21939468 731.66320801] \n",
      "freq-> [126 126 126 126] \n",
      "accuracy-> [0.48412699 0.43650794 0.47619048 0.38095239] \n",
      "DI--> [0.13793103 0.375      0.21052632 0.15      ]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 489.4047 - binary_accuracy: 0.5635\n",
      "client 1 \n",
      "loss --> [  0.77908677   5.58165359  57.72340775 489.4046936 ] \n",
      "freq-> [126 126 126 126] \n",
      "accuracy-> [0.46825397 0.49206349 0.47619048 0.56349206] \n",
      "DI--> [0.15384615 0.04761905 0.28       0.0952381 ]\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 620.3553 - binary_accuracy: 0.4841\n",
      "client 0 \n",
      "loss --> [  0.82191473   5.14807892  50.53765488 620.35528564] \n",
      "freq-> [126 126 126 126] \n",
      "accuracy-> [0.42063493 0.5        0.46031746 0.48412699] \n",
      "DI--> [0.08823529 0.17241379 0.08108108 0.08333333]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 521.0205 - binary_accuracy: 0.4603\n",
      "client 4 \n",
      "loss --> [  0.81854618   5.77085161  56.44488525 521.02050781] \n",
      "freq-> [126 126 126 126] \n",
      "accuracy-> [0.41269842 0.51587301 0.43650794 0.46031746] \n",
      "DI--> [0.10344828 0.33333333 0.07692308 0.15384615]\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 600.0221 - binary_accuracy: 0.4762\n",
      "client 7 \n",
      "loss --> [  0.79356813   4.97581959  58.36645126 600.02209473] \n",
      "freq-> [126 126 126 126] \n",
      "accuracy-> [0.44444445 0.54761904 0.44444445 0.47619048] \n",
      "DI--> [0.34782609 0.13043478 0.19354839 0.03225806]\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 535.2638 - binary_accuracy: 0.4365\n",
      "client 5 \n",
      "loss --> [  0.7897442    6.27440405  65.56147003 535.26379395] \n",
      "freq-> [126 126 126 126] \n",
      "accuracy-> [0.48412699 0.44444445 0.50793654 0.43650794] \n",
      "DI--> [0.16666667 0.11538462 0.19230769 0.17647059]\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 630.1536 - binary_accuracy: 0.4444\n",
      "client 8 \n",
      "loss --> [  0.75437725   5.24154329  60.18710327 630.15362549] \n",
      "freq-> [126 126 126 126] \n",
      "accuracy-> [0.48412699 0.45238096 0.5        0.44444445] \n",
      "DI--> [0.13636364 0.25925926 0.34482759 0.24242424]\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 569.7890 - binary_accuracy: 0.4683\n",
      "client 6 \n",
      "loss --> [  0.81600428   6.95172691  60.90775681 569.78900146] \n",
      "freq-> [126 126 126 126] \n",
      "accuracy-> [0.46825397 0.45238096 0.46031746 0.46825397] \n",
      "DI--> [0.58823529 0.25       0.12820513 0.08      ]\n",
      "comm_round: 3 | global_acc: 47.441% | global_loss: 5892.9921875\n",
      "global_loss_list:  [5.813995361328125, 58.23781204223633, 588.8887939453125, 5892.9921875]\n",
      "global_acc_list:  [0.4719492197036743, 0.47368958592414856, 0.4744062125682831, 0.4744062125682831]\n",
      "global_freq_list:  [1260, 1260, 1260, 1260]\n",
      "global_di_list:  [0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7010.8872 - binary_accuracy: 0.3730\n",
      "client 4 \n",
      "loss --> [8.18546176e-01 5.77085161e+00 5.64448853e+01 5.21020508e+02\n",
      " 7.01088721e+03] \n",
      "freq-> [126 126 126 126 126] \n",
      "accuracy-> [0.41269842 0.51587301 0.43650794 0.46031746 0.37301588] \n",
      "DI--> [0.10344828 0.33333333 0.07692308 0.15384615 0.2       ]\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5241.4419 - binary_accuracy: 0.5317\n",
      "client 8 \n",
      "loss --> [7.54377246e-01 5.24154329e+00 6.01871033e+01 6.30153625e+02\n",
      " 5.24144189e+03] \n",
      "freq-> [126 126 126 126 126] \n",
      "accuracy-> [0.48412699 0.45238096 0.5        0.44444445 0.53174603] \n",
      "DI--> [0.13636364 0.25925926 0.34482759 0.24242424 0.16666667]\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4839.6655 - binary_accuracy: 0.5476\n",
      "client 3 \n",
      "loss --> [8.02610517e-01 5.06576204e+00 5.78397560e+01 5.87189026e+02\n",
      " 4.83966553e+03] \n",
      "freq-> [126 126 126 126 126] \n",
      "accuracy-> [0.42857143 0.52380955 0.51587301 0.46031746 0.54761904] \n",
      "DI--> [0.30769231 0.04347826 0.17241379 0.13333333 0.13333333]\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5026.7173 - binary_accuracy: 0.4762\n",
      "client 1 \n",
      "loss --> [7.79086769e-01 5.58165359e+00 5.77234077e+01 4.89404694e+02\n",
      " 5.02671729e+03] \n",
      "freq-> [126 126 126 126 126] \n",
      "accuracy-> [0.46825397 0.49206349 0.47619048 0.56349206 0.47619048] \n",
      "DI--> [0.15384615 0.04761905 0.28       0.0952381  0.18181818]\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6326.9058 - binary_accuracy: 0.3968\n",
      "client 5 \n",
      "loss --> [7.89744198e-01 6.27440405e+00 6.55614700e+01 5.35263794e+02\n",
      " 6.32690576e+03] \n",
      "freq-> [126 126 126 126 126] \n",
      "accuracy-> [0.48412699 0.44444445 0.50793654 0.43650794 0.3968254 ] \n",
      "DI--> [0.16666667 0.11538462 0.19230769 0.17647059 0.28      ]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6487.2017 - binary_accuracy: 0.3810\n",
      "client 6 \n",
      "loss --> [8.16004276e-01 6.95172691e+00 6.09077568e+01 5.69789001e+02\n",
      " 6.48720166e+03] \n",
      "freq-> [126 126 126 126 126] \n",
      "accuracy-> [0.46825397 0.45238096 0.46031746 0.46825397 0.38095239] \n",
      "DI--> [0.58823529 0.25       0.12820513 0.08       0.08      ]\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5983.1040 - binary_accuracy: 0.4286\n",
      "client 2 \n",
      "loss --> [7.84936011e-01 5.62305260e+00 5.11115265e+01 6.01032043e+02\n",
      " 5.98310400e+03] \n",
      "freq-> [126 126 126 126 126] \n",
      "accuracy-> [0.42857143 0.45238096 0.51587301 0.43650794 0.42857143] \n",
      "DI--> [0.21875    0.35714286 0.09375    0.03846154 0.03333333]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6244.4585 - binary_accuracy: 0.4921\n",
      "client 0 \n",
      "loss --> [8.21914732e-01 5.14807892e+00 5.05376549e+01 6.20355286e+02\n",
      " 6.24445850e+03] \n",
      "freq-> [126 126 126 126 126] \n",
      "accuracy-> [0.42063493 0.5        0.46031746 0.48412699 0.49206349] \n",
      "DI--> [0.08823529 0.17241379 0.08108108 0.08333333 0.07142857]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6659.3613 - binary_accuracy: 0.4841\n",
      "client 7 \n",
      "loss --> [7.93568134e-01 4.97581959e+00 5.83664513e+01 6.00022095e+02\n",
      " 6.65936133e+03] \n",
      "freq-> [126 126 126 126 126] \n",
      "accuracy-> [0.44444445 0.54761904 0.44444445 0.47619048 0.48412699] \n",
      "DI--> [0.34782609 0.13043478 0.19354839 0.03225806 0.2962963 ]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6108.1602 - binary_accuracy: 0.4921\n",
      "client 9 \n",
      "loss --> [7.72266686e-01 5.48855400e+00 5.82193947e+01 7.31663208e+02\n",
      " 6.10816016e+03] \n",
      "freq-> [126 126 126 126 126] \n",
      "accuracy-> [0.48412699 0.43650794 0.47619048 0.38095239 0.49206349] \n",
      "DI--> [0.13793103 0.375      0.21052632 0.15       0.2       ]\n",
      "comm_round: 4 | global_acc: 47.430% | global_loss: 58934.69140625\n",
      "global_loss_list:  [5.813995361328125, 58.23781204223633, 588.8887939453125, 5892.9921875, 58934.69140625]\n",
      "global_acc_list:  [0.4719492197036743, 0.47368958592414856, 0.4744062125682831, 0.4744062125682831, 0.47430384159088135]\n",
      "global_freq_list:  [1260, 1260, 1260, 1260, 1260]\n",
      "global_di_list:  [0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872]\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 67140.2422 - binary_accuracy: 0.4206\n",
      "client 8 \n",
      "loss --> [7.54377246e-01 5.24154329e+00 6.01871033e+01 6.30153625e+02\n",
      " 5.24144189e+03 6.71402422e+04] \n",
      "freq-> [126 126 126 126 126 126] \n",
      "accuracy-> [0.48412699 0.45238096 0.5        0.44444445 0.53174603 0.42063493] \n",
      "DI--> [0.13636364 0.25925926 0.34482759 0.24242424 0.16666667 0.58823529]\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 48030.3906 - binary_accuracy: 0.5476\n",
      "client 5 \n",
      "loss --> [7.89744198e-01 6.27440405e+00 6.55614700e+01 5.35263794e+02\n",
      " 6.32690576e+03 4.80303906e+04] \n",
      "freq-> [126 126 126 126 126 126] \n",
      "accuracy-> [0.48412699 0.44444445 0.50793654 0.43650794 0.3968254  0.54761904] \n",
      "DI--> [0.16666667 0.11538462 0.19230769 0.17647059 0.28       0.28571429]\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 57517.4727 - binary_accuracy: 0.5000\n",
      "client 4 \n",
      "loss --> [8.18546176e-01 5.77085161e+00 5.64448853e+01 5.21020508e+02\n",
      " 7.01088721e+03 5.75174727e+04] \n",
      "freq-> [126 126 126 126 126 126] \n",
      "accuracy-> [0.41269842 0.51587301 0.43650794 0.46031746 0.37301588 0.5       ] \n",
      "DI--> [0.10344828 0.33333333 0.07692308 0.15384615 0.2        0.08      ]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 64601.2656 - binary_accuracy: 0.3968\n",
      "client 1 \n",
      "loss --> [7.79086769e-01 5.58165359e+00 5.77234077e+01 4.89404694e+02\n",
      " 5.02671729e+03 6.46012656e+04] \n",
      "freq-> [126 126 126 126 126 126] \n",
      "accuracy-> [0.46825397 0.49206349 0.47619048 0.56349206 0.47619048 0.3968254 ] \n",
      "DI--> [0.15384615 0.04761905 0.28       0.0952381  0.18181818 0.22222222]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 57859.0859 - binary_accuracy: 0.4127\n",
      "client 9 \n",
      "loss --> [7.72266686e-01 5.48855400e+00 5.82193947e+01 7.31663208e+02\n",
      " 6.10816016e+03 5.78590859e+04] \n",
      "freq-> [126 126 126 126 126 126] \n",
      "accuracy-> [0.48412699 0.43650794 0.47619048 0.38095239 0.49206349 0.41269842] \n",
      "DI--> [0.13793103 0.375      0.21052632 0.15       0.2        0.26086957]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 64515.5352 - binary_accuracy: 0.4286\n",
      "client 6 \n",
      "loss --> [8.16004276e-01 6.95172691e+00 6.09077568e+01 5.69789001e+02\n",
      " 6.48720166e+03 6.45155352e+04] \n",
      "freq-> [126 126 126 126 126 126] \n",
      "accuracy-> [0.46825397 0.45238096 0.46031746 0.46825397 0.38095239 0.42857143] \n",
      "DI--> [0.58823529 0.25       0.12820513 0.08       0.08       0.06896552]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 52323.7617 - binary_accuracy: 0.5397\n",
      "client 0 \n",
      "loss --> [8.21914732e-01 5.14807892e+00 5.05376549e+01 6.20355286e+02\n",
      " 6.24445850e+03 5.23237617e+04] \n",
      "freq-> [126 126 126 126 126 126] \n",
      "accuracy-> [0.42063493 0.5        0.46031746 0.48412699 0.49206349 0.53968257] \n",
      "DI--> [0.08823529 0.17241379 0.08108108 0.08333333 0.07142857 0.08333333]\n",
      "1/1 [==============================] - 0s 959us/step - loss: 63010.8867 - binary_accuracy: 0.4524\n",
      "client 2 \n",
      "loss --> [7.84936011e-01 5.62305260e+00 5.11115265e+01 6.01032043e+02\n",
      " 5.98310400e+03 6.30108867e+04] \n",
      "freq-> [126 126 126 126 126 126] \n",
      "accuracy-> [0.42857143 0.45238096 0.51587301 0.43650794 0.42857143 0.45238096] \n",
      "DI--> [0.21875    0.35714286 0.09375    0.03846154 0.03333333 0.07142857]\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 53605.1016 - binary_accuracy: 0.5317\n",
      "client 7 \n",
      "loss --> [7.93568134e-01 4.97581959e+00 5.83664513e+01 6.00022095e+02\n",
      " 6.65936133e+03 5.36051016e+04] \n",
      "freq-> [126 126 126 126 126 126] \n",
      "accuracy-> [0.44444445 0.54761904 0.44444445 0.47619048 0.48412699 0.53174603] \n",
      "DI--> [0.34782609 0.13043478 0.19354839 0.03225806 0.2962963  0.44444444]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 53276.0195 - binary_accuracy: 0.5476\n",
      "client 3 \n",
      "loss --> [8.02610517e-01 5.06576204e+00 5.78397560e+01 5.87189026e+02\n",
      " 4.83966553e+03 5.32760195e+04] \n",
      "freq-> [126 126 126 126 126 126] \n",
      "accuracy-> [0.42857143 0.52380955 0.51587301 0.46031746 0.54761904 0.54761904] \n",
      "DI--> [0.30769231 0.04347826 0.17241379 0.13333333 0.13333333 0.36363636]\n",
      "comm_round: 5 | global_acc: 47.420% | global_loss: 589337.5\n",
      "global_loss_list:  [5.813995361328125, 58.23781204223633, 588.8887939453125, 5892.9921875, 58934.69140625, 589337.5]\n",
      "global_acc_list:  [0.4719492197036743, 0.47368958592414856, 0.4744062125682831, 0.4744062125682831, 0.47430384159088135, 0.4742014706134796]\n",
      "global_freq_list:  [1260, 1260, 1260, 1260, 1260, 1260]\n",
      "global_di_list:  [0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872]\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 728413.8750 - binary_accuracy: 0.3889\n",
      "client 3 \n",
      "loss --> [8.02610517e-01 5.06576204e+00 5.78397560e+01 5.87189026e+02\n",
      " 4.83966553e+03 5.32760195e+04 7.28413875e+05] \n",
      "freq-> [126 126 126 126 126 126 126] \n",
      "accuracy-> [0.42857143 0.52380955 0.51587301 0.46031746 0.54761904 0.54761904\n",
      " 0.3888889 ] \n",
      "DI--> [0.30769231 0.04347826 0.17241379 0.13333333 0.13333333 0.36363636\n",
      " 0.17857143]\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 574731.3750 - binary_accuracy: 0.4603\n",
      "client 8 \n",
      "loss --> [7.54377246e-01 5.24154329e+00 6.01871033e+01 6.30153625e+02\n",
      " 5.24144189e+03 6.71402422e+04 5.74731375e+05] \n",
      "freq-> [126 126 126 126 126 126 126] \n",
      "accuracy-> [0.48412699 0.45238096 0.5        0.44444445 0.53174603 0.42063493\n",
      " 0.46031746] \n",
      "DI--> [0.13636364 0.25925926 0.34482759 0.24242424 0.16666667 0.58823529\n",
      " 0.35      ]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 539950.6875 - binary_accuracy: 0.5079\n",
      "client 9 \n",
      "loss --> [7.72266686e-01 5.48855400e+00 5.82193947e+01 7.31663208e+02\n",
      " 6.10816016e+03 5.78590859e+04 5.39950688e+05] \n",
      "freq-> [126 126 126 126 126 126 126] \n",
      "accuracy-> [0.48412699 0.43650794 0.47619048 0.38095239 0.49206349 0.41269842\n",
      " 0.50793654] \n",
      "DI--> [0.13793103 0.375      0.21052632 0.15       0.2        0.26086957\n",
      " 0.12      ]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 575767.1875 - binary_accuracy: 0.4206\n",
      "client 7 \n",
      "loss --> [7.93568134e-01 4.97581959e+00 5.83664513e+01 6.00022095e+02\n",
      " 6.65936133e+03 5.36051016e+04 5.75767188e+05] \n",
      "freq-> [126 126 126 126 126 126 126] \n",
      "accuracy-> [0.44444445 0.54761904 0.44444445 0.47619048 0.48412699 0.53174603\n",
      " 0.42063493] \n",
      "DI--> [0.34782609 0.13043478 0.19354839 0.03225806 0.2962963  0.44444444\n",
      " 0.2       ]\n",
      "1/1 [==============================] - 0s 939us/step - loss: 565160.9375 - binary_accuracy: 0.4841\n",
      "client 0 \n",
      "loss --> [8.21914732e-01 5.14807892e+00 5.05376549e+01 6.20355286e+02\n",
      " 6.24445850e+03 5.23237617e+04 5.65160938e+05] \n",
      "freq-> [126 126 126 126 126 126 126] \n",
      "accuracy-> [0.42063493 0.5        0.46031746 0.48412699 0.49206349 0.53968257\n",
      " 0.48412699] \n",
      "DI--> [0.08823529 0.17241379 0.08108108 0.08333333 0.07142857 0.08333333\n",
      " 0.4       ]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 441926.8125 - binary_accuracy: 0.5556\n",
      "client 1 \n",
      "loss --> [7.79086769e-01 5.58165359e+00 5.77234077e+01 4.89404694e+02\n",
      " 5.02671729e+03 6.46012656e+04 4.41926812e+05] \n",
      "freq-> [126 126 126 126 126 126 126] \n",
      "accuracy-> [0.46825397 0.49206349 0.47619048 0.56349206 0.47619048 0.3968254\n",
      " 0.55555558] \n",
      "DI--> [0.15384615 0.04761905 0.28       0.0952381  0.18181818 0.22222222\n",
      " 0.33333333]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 569691.8125 - binary_accuracy: 0.5079\n",
      "client 4 \n",
      "loss --> [8.18546176e-01 5.77085161e+00 5.64448853e+01 5.21020508e+02\n",
      " 7.01088721e+03 5.75174727e+04 5.69691812e+05] \n",
      "freq-> [126 126 126 126 126 126 126] \n",
      "accuracy-> [0.41269842 0.51587301 0.43650794 0.46031746 0.37301588 0.5\n",
      " 0.50793654] \n",
      "DI--> [0.10344828 0.33333333 0.07692308 0.15384615 0.2        0.08\n",
      " 0.13888889]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 545656.3750 - binary_accuracy: 0.4762\n",
      "client 5 \n",
      "loss --> [7.89744198e-01 6.27440405e+00 6.55614700e+01 5.35263794e+02\n",
      " 6.32690576e+03 4.80303906e+04 5.45656375e+05] \n",
      "freq-> [126 126 126 126 126 126 126] \n",
      "accuracy-> [0.48412699 0.44444445 0.50793654 0.43650794 0.3968254  0.54761904\n",
      " 0.47619048] \n",
      "DI--> [0.16666667 0.11538462 0.19230769 0.17647059 0.28       0.28571429\n",
      " 0.32142857]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 570527.6250 - binary_accuracy: 0.3889\n",
      "client 2 \n",
      "loss --> [7.84936011e-01 5.62305260e+00 5.11115265e+01 6.01032043e+02\n",
      " 5.98310400e+03 6.30108867e+04 5.70527625e+05] \n",
      "freq-> [126 126 126 126 126 126 126] \n",
      "accuracy-> [0.42857143 0.45238096 0.51587301 0.43650794 0.42857143 0.45238096\n",
      " 0.3888889 ] \n",
      "DI--> [0.21875    0.35714286 0.09375    0.03846154 0.03333333 0.07142857\n",
      " 0.29166667]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 606522.4375 - binary_accuracy: 0.5079\n",
      "client 6 \n",
      "loss --> [8.16004276e-01 6.95172691e+00 6.09077568e+01 5.69789001e+02\n",
      " 6.48720166e+03 6.45155352e+04 6.06522438e+05] \n",
      "freq-> [126 126 126 126 126 126 126] \n",
      "accuracy-> [0.46825397 0.45238096 0.46031746 0.46825397 0.38095239 0.42857143\n",
      " 0.50793654] \n",
      "DI--> [0.58823529 0.25       0.12820513 0.08       0.08       0.06896552\n",
      " 0.16      ]\n",
      "comm_round: 6 | global_acc: 47.420% | global_loss: 5893379.5\n",
      "global_loss_list:  [5.813995361328125, 58.23781204223633, 588.8887939453125, 5892.9921875, 58934.69140625, 589337.5, 5893379.5]\n",
      "global_acc_list:  [0.4719492197036743, 0.47368958592414856, 0.4744062125682831, 0.4744062125682831, 0.47430384159088135, 0.4742014706134796, 0.4742014706134796]\n",
      "global_freq_list:  [1260, 1260, 1260, 1260, 1260, 1260, 1260]\n",
      "global_di_list:  [0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5049219.0000 - binary_accuracy: 0.5317\n",
      "client 8 \n",
      "loss --> [7.54377246e-01 5.24154329e+00 6.01871033e+01 6.30153625e+02\n",
      " 5.24144189e+03 6.71402422e+04 5.74731375e+05 5.04921900e+06] \n",
      "freq-> [126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.48412699 0.45238096 0.5        0.44444445 0.53174603 0.42063493\n",
      " 0.46031746 0.53174603] \n",
      "DI--> [0.13636364 0.25925926 0.34482759 0.24242424 0.16666667 0.58823529\n",
      " 0.35       0.17647059]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6325023.5000 - binary_accuracy: 0.4683\n",
      "client 9 \n",
      "loss --> [7.72266686e-01 5.48855400e+00 5.82193947e+01 7.31663208e+02\n",
      " 6.10816016e+03 5.78590859e+04 5.39950688e+05 6.32502350e+06] \n",
      "freq-> [126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.48412699 0.43650794 0.47619048 0.38095239 0.49206349 0.41269842\n",
      " 0.50793654 0.46825397] \n",
      "DI--> [0.13793103 0.375      0.21052632 0.15       0.2        0.26086957\n",
      " 0.12       0.20833333]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5937803.0000 - binary_accuracy: 0.4206\n",
      "client 1 \n",
      "loss --> [7.79086769e-01 5.58165359e+00 5.77234077e+01 4.89404694e+02\n",
      " 5.02671729e+03 6.46012656e+04 4.41926812e+05 5.93780300e+06] \n",
      "freq-> [126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.46825397 0.49206349 0.47619048 0.56349206 0.47619048 0.3968254\n",
      " 0.55555558 0.42063493] \n",
      "DI--> [0.15384615 0.04761905 0.28       0.0952381  0.18181818 0.22222222\n",
      " 0.33333333 0.        ]\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5437167.0000 - binary_accuracy: 0.4206\n",
      "client 2 \n",
      "loss --> [7.84936011e-01 5.62305260e+00 5.11115265e+01 6.01032043e+02\n",
      " 5.98310400e+03 6.30108867e+04 5.70527625e+05 5.43716700e+06] \n",
      "freq-> [126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.42857143 0.45238096 0.51587301 0.43650794 0.42857143 0.45238096\n",
      " 0.3888889  0.42063493] \n",
      "DI--> [0.21875    0.35714286 0.09375    0.03846154 0.03333333 0.07142857\n",
      " 0.29166667 0.0952381 ]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6187689.0000 - binary_accuracy: 0.4365\n",
      "client 3 \n",
      "loss --> [8.02610517e-01 5.06576204e+00 5.78397560e+01 5.87189026e+02\n",
      " 4.83966553e+03 5.32760195e+04 7.28413875e+05 6.18768900e+06] \n",
      "freq-> [126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.42857143 0.52380955 0.51587301 0.46031746 0.54761904 0.54761904\n",
      " 0.3888889  0.43650794] \n",
      "DI--> [0.30769231 0.04347826 0.17241379 0.13333333 0.13333333 0.36363636\n",
      " 0.17857143 0.15151515]\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6295862.0000 - binary_accuracy: 0.4683\n",
      "client 0 \n",
      "loss --> [8.21914732e-01 5.14807892e+00 5.05376549e+01 6.20355286e+02\n",
      " 6.24445850e+03 5.23237617e+04 5.65160938e+05 6.29586200e+06] \n",
      "freq-> [126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.42063493 0.5        0.46031746 0.48412699 0.49206349 0.53968257\n",
      " 0.48412699 0.46825397] \n",
      "DI--> [0.08823529 0.17241379 0.08108108 0.08333333 0.07142857 0.08333333\n",
      " 0.4        0.39130435]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5337693.0000 - binary_accuracy: 0.4524\n",
      "client 4 \n",
      "loss --> [8.18546176e-01 5.77085161e+00 5.64448853e+01 5.21020508e+02\n",
      " 7.01088721e+03 5.75174727e+04 5.69691812e+05 5.33769300e+06] \n",
      "freq-> [126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.41269842 0.51587301 0.43650794 0.46031746 0.37301588 0.5\n",
      " 0.50793654 0.45238096] \n",
      "DI--> [0.10344828 0.33333333 0.07692308 0.15384615 0.2        0.08\n",
      " 0.13888889 0.06666667]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6018702.5000 - binary_accuracy: 0.4127\n",
      "client 6 \n",
      "loss --> [8.16004276e-01 6.95172691e+00 6.09077568e+01 5.69789001e+02\n",
      " 6.48720166e+03 6.45155352e+04 6.06522438e+05 6.01870250e+06] \n",
      "freq-> [126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.46825397 0.45238096 0.46031746 0.46825397 0.38095239 0.42857143\n",
      " 0.50793654 0.41269842] \n",
      "DI--> [0.58823529 0.25       0.12820513 0.08       0.08       0.06896552\n",
      " 0.16       0.15384615]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 4919497.0000 - binary_accuracy: 0.4921\n",
      "client 5 \n",
      "loss --> [7.89744198e-01 6.27440405e+00 6.55614700e+01 5.35263794e+02\n",
      " 6.32690576e+03 4.80303906e+04 5.45656375e+05 4.91949700e+06] \n",
      "freq-> [126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.48412699 0.44444445 0.50793654 0.43650794 0.3968254  0.54761904\n",
      " 0.47619048 0.49206349] \n",
      "DI--> [0.16666667 0.11538462 0.19230769 0.17647059 0.28       0.28571429\n",
      " 0.32142857 0.05405405]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5479385.5000 - binary_accuracy: 0.4524\n",
      "client 7 \n",
      "loss --> [7.93568134e-01 4.97581959e+00 5.83664513e+01 6.00022095e+02\n",
      " 6.65936133e+03 5.36051016e+04 5.75767188e+05 5.47938550e+06] \n",
      "freq-> [126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.44444445 0.54761904 0.44444445 0.47619048 0.48412699 0.53174603\n",
      " 0.42063493 0.45238096] \n",
      "DI--> [0.34782609 0.13043478 0.19354839 0.03225806 0.2962963  0.44444444\n",
      " 0.2        0.2       ]\n",
      "comm_round: 7 | global_acc: 47.420% | global_loss: 58933756.0\n",
      "global_loss_list:  [5.813995361328125, 58.23781204223633, 588.8887939453125, 5892.9921875, 58934.69140625, 589337.5, 5893379.5, 58933756.0]\n",
      "global_acc_list:  [0.4719492197036743, 0.47368958592414856, 0.4744062125682831, 0.4744062125682831, 0.47430384159088135, 0.4742014706134796, 0.4742014706134796, 0.4742014706134796]\n",
      "global_freq_list:  [1260, 1260, 1260, 1260, 1260, 1260, 1260, 1260]\n",
      "global_di_list:  [0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 59791360.0000 - binary_accuracy: 0.5000\n",
      "client 8 \n",
      "loss --> [7.54377246e-01 5.24154329e+00 6.01871033e+01 6.30153625e+02\n",
      " 5.24144189e+03 6.71402422e+04 5.74731375e+05 5.04921900e+06\n",
      " 5.97913600e+07] \n",
      "freq-> [126 126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.48412699 0.45238096 0.5        0.44444445 0.53174603 0.42063493\n",
      " 0.46031746 0.53174603 0.5       ] \n",
      "DI--> [0.13636364 0.25925926 0.34482759 0.24242424 0.16666667 0.58823529\n",
      " 0.35       0.17647059 0.2173913 ]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 50632952.0000 - binary_accuracy: 0.5635\n",
      "client 4 \n",
      "loss --> [8.18546176e-01 5.77085161e+00 5.64448853e+01 5.21020508e+02\n",
      " 7.01088721e+03 5.75174727e+04 5.69691812e+05 5.33769300e+06\n",
      " 5.06329520e+07] \n",
      "freq-> [126 126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.41269842 0.51587301 0.43650794 0.46031746 0.37301588 0.5\n",
      " 0.50793654 0.45238096 0.56349206] \n",
      "DI--> [0.10344828 0.33333333 0.07692308 0.15384615 0.2        0.08\n",
      " 0.13888889 0.06666667 0.11538462]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 55164236.0000 - binary_accuracy: 0.4841\n",
      "client 3 \n",
      "loss --> [8.02610517e-01 5.06576204e+00 5.78397560e+01 5.87189026e+02\n",
      " 4.83966553e+03 5.32760195e+04 7.28413875e+05 6.18768900e+06\n",
      " 5.51642360e+07] \n",
      "freq-> [126 126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.42857143 0.52380955 0.51587301 0.46031746 0.54761904 0.54761904\n",
      " 0.3888889  0.43650794 0.48412699] \n",
      "DI--> [0.30769231 0.04347826 0.17241379 0.13333333 0.13333333 0.36363636\n",
      " 0.17857143 0.15151515 0.21428571]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 60697232.0000 - binary_accuracy: 0.4603\n",
      "client 0 \n",
      "loss --> [8.21914732e-01 5.14807892e+00 5.05376549e+01 6.20355286e+02\n",
      " 6.24445850e+03 5.23237617e+04 5.65160938e+05 6.29586200e+06\n",
      " 6.06972320e+07] \n",
      "freq-> [126 126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.42063493 0.5        0.46031746 0.48412699 0.49206349 0.53968257\n",
      " 0.48412699 0.46825397 0.46031746] \n",
      "DI--> [0.08823529 0.17241379 0.08108108 0.08333333 0.07142857 0.08333333\n",
      " 0.4        0.39130435 0.13043478]\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 54668012.0000 - binary_accuracy: 0.5397\n",
      "client 9 \n",
      "loss --> [7.72266686e-01 5.48855400e+00 5.82193947e+01 7.31663208e+02\n",
      " 6.10816016e+03 5.78590859e+04 5.39950688e+05 6.32502350e+06\n",
      " 5.46680120e+07] \n",
      "freq-> [126 126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.48412699 0.43650794 0.47619048 0.38095239 0.49206349 0.41269842\n",
      " 0.50793654 0.46825397 0.53968257] \n",
      "DI--> [0.13793103 0.375      0.21052632 0.15       0.2        0.26086957\n",
      " 0.12       0.20833333 0.4       ]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 57663144.0000 - binary_accuracy: 0.4286\n",
      "client 1 \n",
      "loss --> [7.79086769e-01 5.58165359e+00 5.77234077e+01 4.89404694e+02\n",
      " 5.02671729e+03 6.46012656e+04 4.41926812e+05 5.93780300e+06\n",
      " 5.76631440e+07] \n",
      "freq-> [126 126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.46825397 0.49206349 0.47619048 0.56349206 0.47619048 0.3968254\n",
      " 0.55555558 0.42063493 0.42857143] \n",
      "DI--> [0.15384615 0.04761905 0.28       0.0952381  0.18181818 0.22222222\n",
      " 0.33333333 0.         0.25      ]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 56031816.0000 - binary_accuracy: 0.4603\n",
      "client 7 \n",
      "loss --> [7.93568134e-01 4.97581959e+00 5.83664513e+01 6.00022095e+02\n",
      " 6.65936133e+03 5.36051016e+04 5.75767188e+05 5.47938550e+06\n",
      " 5.60318160e+07] \n",
      "freq-> [126 126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.44444445 0.54761904 0.44444445 0.47619048 0.48412699 0.53174603\n",
      " 0.42063493 0.45238096 0.46031746] \n",
      "DI--> [0.34782609 0.13043478 0.19354839 0.03225806 0.2962963  0.44444444\n",
      " 0.2        0.2        0.15625   ]\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 59822584.0000 - binary_accuracy: 0.4683\n",
      "client 2 \n",
      "loss --> [7.84936011e-01 5.62305260e+00 5.11115265e+01 6.01032043e+02\n",
      " 5.98310400e+03 6.30108867e+04 5.70527625e+05 5.43716700e+06\n",
      " 5.98225840e+07] \n",
      "freq-> [126 126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.42857143 0.45238096 0.51587301 0.43650794 0.42857143 0.45238096\n",
      " 0.3888889  0.42063493 0.46825397] \n",
      "DI--> [0.21875    0.35714286 0.09375    0.03846154 0.03333333 0.07142857\n",
      " 0.29166667 0.0952381  0.11428571]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 52721988.0000 - binary_accuracy: 0.4762\n",
      "client 5 \n",
      "loss --> [7.89744198e-01 6.27440405e+00 6.55614700e+01 5.35263794e+02\n",
      " 6.32690576e+03 4.80303906e+04 5.45656375e+05 4.91949700e+06\n",
      " 5.27219880e+07] \n",
      "freq-> [126 126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.48412699 0.44444445 0.50793654 0.43650794 0.3968254  0.54761904\n",
      " 0.47619048 0.49206349 0.47619048] \n",
      "DI--> [0.16666667 0.11538462 0.19230769 0.17647059 0.28       0.28571429\n",
      " 0.32142857 0.05405405 0.21428571]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 64599156.0000 - binary_accuracy: 0.4683\n",
      "client 6 \n",
      "loss --> [8.16004276e-01 6.95172691e+00 6.09077568e+01 5.69789001e+02\n",
      " 6.48720166e+03 6.45155352e+04 6.06522438e+05 6.01870250e+06\n",
      " 6.45991560e+07] \n",
      "freq-> [126 126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.46825397 0.45238096 0.46031746 0.46825397 0.38095239 0.42857143\n",
      " 0.50793654 0.41269842 0.46825397] \n",
      "DI--> [0.58823529 0.25       0.12820513 0.08       0.08       0.06896552\n",
      " 0.16       0.15384615 0.16666667]\n",
      "comm_round: 8 | global_acc: 47.420% | global_loss: 589337600.0\n",
      "global_loss_list:  [5.813995361328125, 58.23781204223633, 588.8887939453125, 5892.9921875, 58934.69140625, 589337.5, 5893379.5, 58933756.0, 589337600.0]\n",
      "global_acc_list:  [0.4719492197036743, 0.47368958592414856, 0.4744062125682831, 0.4744062125682831, 0.47430384159088135, 0.4742014706134796, 0.4742014706134796, 0.4742014706134796, 0.4742014706134796]\n",
      "global_freq_list:  [1260, 1260, 1260, 1260, 1260, 1260, 1260, 1260, 1260]\n",
      "global_di_list:  [0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872]\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 665569216.0000 - binary_accuracy: 0.4444\n",
      "client 6 \n",
      "loss --> [8.16004276e-01 6.95172691e+00 6.09077568e+01 5.69789001e+02\n",
      " 6.48720166e+03 6.45155352e+04 6.06522438e+05 6.01870250e+06\n",
      " 6.45991560e+07 6.65569216e+08] \n",
      "freq-> [126 126 126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.46825397 0.45238096 0.46031746 0.46825397 0.38095239 0.42857143\n",
      " 0.50793654 0.41269842 0.46825397 0.44444445] \n",
      "DI--> [0.58823529 0.25       0.12820513 0.08       0.08       0.06896552\n",
      " 0.16       0.15384615 0.16666667 0.11428571]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 610121408.0000 - binary_accuracy: 0.4444\n",
      "client 4 \n",
      "loss --> [8.18546176e-01 5.77085161e+00 5.64448853e+01 5.21020508e+02\n",
      " 7.01088721e+03 5.75174727e+04 5.69691812e+05 5.33769300e+06\n",
      " 5.06329520e+07 6.10121408e+08] \n",
      "freq-> [126 126 126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.41269842 0.51587301 0.43650794 0.46031746 0.37301588 0.5\n",
      " 0.50793654 0.45238096 0.56349206 0.44444445] \n",
      "DI--> [0.10344828 0.33333333 0.07692308 0.15384615 0.2        0.08\n",
      " 0.13888889 0.06666667 0.11538462 0.18518519]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 512045568.0000 - binary_accuracy: 0.4206\n",
      "client 9 \n",
      "loss --> [7.72266686e-01 5.48855400e+00 5.82193947e+01 7.31663208e+02\n",
      " 6.10816016e+03 5.78590859e+04 5.39950688e+05 6.32502350e+06\n",
      " 5.46680120e+07 5.12045568e+08] \n",
      "freq-> [126 126 126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.48412699 0.43650794 0.47619048 0.38095239 0.49206349 0.41269842\n",
      " 0.50793654 0.46825397 0.53968257 0.42063493] \n",
      "DI--> [0.13793103 0.375      0.21052632 0.15       0.2        0.26086957\n",
      " 0.12       0.20833333 0.4        0.17857143]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 652878592.0000 - binary_accuracy: 0.4683\n",
      "client 1 \n",
      "loss --> [7.79086769e-01 5.58165359e+00 5.77234077e+01 4.89404694e+02\n",
      " 5.02671729e+03 6.46012656e+04 4.41926812e+05 5.93780300e+06\n",
      " 5.76631440e+07 6.52878592e+08] \n",
      "freq-> [126 126 126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.46825397 0.49206349 0.47619048 0.56349206 0.47619048 0.3968254\n",
      " 0.55555558 0.42063493 0.42857143 0.46825397] \n",
      "DI--> [0.15384615 0.04761905 0.28       0.0952381  0.18181818 0.22222222\n",
      " 0.33333333 0.         0.25       0.125     ]\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 530674048.0000 - binary_accuracy: 0.5397\n",
      "client 8 \n",
      "loss --> [7.54377246e-01 5.24154329e+00 6.01871033e+01 6.30153625e+02\n",
      " 5.24144189e+03 6.71402422e+04 5.74731375e+05 5.04921900e+06\n",
      " 5.97913600e+07 5.30674048e+08] \n",
      "freq-> [126 126 126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.48412699 0.45238096 0.5        0.44444445 0.53174603 0.42063493\n",
      " 0.46031746 0.53174603 0.5        0.53968257] \n",
      "DI--> [0.13636364 0.25925926 0.34482759 0.24242424 0.16666667 0.58823529\n",
      " 0.35       0.17647059 0.2173913  0.11111111]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 622574656.0000 - binary_accuracy: 0.4921\n",
      "client 2 \n",
      "loss --> [7.84936011e-01 5.62305260e+00 5.11115265e+01 6.01032043e+02\n",
      " 5.98310400e+03 6.30108867e+04 5.70527625e+05 5.43716700e+06\n",
      " 5.98225840e+07 6.22574656e+08] \n",
      "freq-> [126 126 126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.42857143 0.45238096 0.51587301 0.43650794 0.42857143 0.45238096\n",
      " 0.3888889  0.42063493 0.46825397 0.49206349] \n",
      "DI--> [0.21875    0.35714286 0.09375    0.03846154 0.03333333 0.07142857\n",
      " 0.29166667 0.0952381  0.11428571 0.11111111]\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 504053312.0000 - binary_accuracy: 0.5476\n",
      "client 3 \n",
      "loss --> [8.02610517e-01 5.06576204e+00 5.78397560e+01 5.87189026e+02\n",
      " 4.83966553e+03 5.32760195e+04 7.28413875e+05 6.18768900e+06\n",
      " 5.51642360e+07 5.04053312e+08] \n",
      "freq-> [126 126 126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.42857143 0.52380955 0.51587301 0.46031746 0.54761904 0.54761904\n",
      " 0.3888889  0.43650794 0.48412699 0.54761904] \n",
      "DI--> [0.30769231 0.04347826 0.17241379 0.13333333 0.13333333 0.36363636\n",
      " 0.17857143 0.15151515 0.21428571 0.36842105]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 580730304.0000 - binary_accuracy: 0.4683\n",
      "client 7 \n",
      "loss --> [7.93568134e-01 4.97581959e+00 5.83664513e+01 6.00022095e+02\n",
      " 6.65936133e+03 5.36051016e+04 5.75767188e+05 5.47938550e+06\n",
      " 5.60318160e+07 5.80730304e+08] \n",
      "freq-> [126 126 126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.44444445 0.54761904 0.44444445 0.47619048 0.48412699 0.53174603\n",
      " 0.42063493 0.45238096 0.46031746 0.46825397] \n",
      "DI--> [0.34782609 0.13043478 0.19354839 0.03225806 0.2962963  0.44444444\n",
      " 0.2        0.2        0.15625    0.2       ]\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 560608768.0000 - binary_accuracy: 0.5000\n",
      "client 5 \n",
      "loss --> [7.89744198e-01 6.27440405e+00 6.55614700e+01 5.35263794e+02\n",
      " 6.32690576e+03 4.80303906e+04 5.45656375e+05 4.91949700e+06\n",
      " 5.27219880e+07 5.60608768e+08] \n",
      "freq-> [126 126 126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.48412699 0.44444445 0.50793654 0.43650794 0.3968254  0.54761904\n",
      " 0.47619048 0.49206349 0.47619048 0.5       ] \n",
      "DI--> [0.16666667 0.11538462 0.19230769 0.17647059 0.28       0.28571429\n",
      " 0.32142857 0.05405405 0.21428571 0.3125    ]\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 576787072.0000 - binary_accuracy: 0.5556\n",
      "client 0 \n",
      "loss --> [8.21914732e-01 5.14807892e+00 5.05376549e+01 6.20355286e+02\n",
      " 6.24445850e+03 5.23237617e+04 5.65160938e+05 6.29586200e+06\n",
      " 6.06972320e+07 5.76787072e+08] \n",
      "freq-> [126 126 126 126 126 126 126 126 126 126] \n",
      "accuracy-> [0.42063493 0.5        0.46031746 0.48412699 0.49206349 0.53968257\n",
      " 0.48412699 0.46825397 0.46031746 0.55555558] \n",
      "DI--> [0.08823529 0.17241379 0.08108108 0.08333333 0.07142857 0.08333333\n",
      " 0.4        0.39130435 0.13043478 0.35294118]\n",
      "comm_round: 9 | global_acc: 47.420% | global_loss: 5893377024.0\n",
      "global_loss_list:  [5.813995361328125, 58.23781204223633, 588.8887939453125, 5892.9921875, 58934.69140625, 589337.5, 5893379.5, 58933756.0, 589337600.0, 5893377024.0]\n",
      "global_acc_list:  [0.4719492197036743, 0.47368958592414856, 0.4744062125682831, 0.4744062125682831, 0.47430384159088135, 0.4742014706134796, 0.4742014706134796, 0.4742014706134796, 0.4742014706134796, 0.4742014706134796]\n",
      "global_freq_list:  [1260, 1260, 1260, 1260, 1260, 1260, 1260, 1260, 1260, 1260]\n",
      "global_di_list:  [0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872, 0.18661257606490872]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#initialize global model\n",
    "smlp_global = SimpleMLP()\n",
    "global_model = smlp_global.build(X_train.shape[1] ,classes=2)\n",
    "global_model.compile(optimizer=optimizer, loss=loss, metrics=metrics) \n",
    "sc = StandardScaler()\n",
    "\n",
    "client_names = [0, 1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "\n",
    "global_loss_list = []\n",
    "global_freq_list = []\n",
    "global_acc_list = []\n",
    "global_di_list = []\n",
    "client_loss = {i: np.array([]) for i in range(len(client_names))}\n",
    "client_accuracy = {i: np.array([]) for i in range(len(client_names))}\n",
    "client_frequency = {i: np.array([]) for i in range(len(client_names))}\n",
    "client_DI = {i: np.array([]) for i in range(len(client_names))}\n",
    "\n",
    "train_sets = initializer_income()\n",
    "# train_sets = initializer_income_race_gender()\n",
    "\n",
    "#commence global training loop\n",
    "for comm_round in range(comms_round):\n",
    "    epoch_freq = 0\n",
    "#     clients = create_clients(X_train, y_train, num_clients=15, initial='client')\n",
    "#     clients = get_hetero_clients()\n",
    "#     print(type(train_sets[0]))\n",
    "\n",
    "#     print(train_sets)\n",
    "    clients = get_hetero_clients_gender(list(train_sets) )\n",
    "#     clients = get_hetero_clients_gender_race(list(train_sets) )\n",
    "#     print(\"client0: \", clients[0])\n",
    "\n",
    "    clients_batched, test_batched = batch_clients(clients)\n",
    "#     print(\"client batched 0: \", clients_batched[1])\n",
    "    # get the global model's weights - will serve as the initial weights for all local models\n",
    "    global_weights = global_model.get_weights()\n",
    "    \n",
    "    #initial list to collect local model weights after scalling\n",
    "    scaled_local_weight_list = list()\n",
    "\n",
    "    #randomize client data - using keys\n",
    "    client_names= list(clients_batched.keys())\n",
    "#     print(client_names)\n",
    "    random.shuffle(client_names)\n",
    "    \n",
    "    #loop through each client and create new local model\n",
    "    for client in client_names:\n",
    "        smlp_local = SimpleMLP()\n",
    "        local_model = smlp_local.build(X_train.shape[1],classes=2)\n",
    "        local_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "        \n",
    "        #set local model weight to the weight of the global model\n",
    "        local_model.set_weights(global_weights)\n",
    "        \n",
    "        #fit local model with client's data\n",
    "        \n",
    "        \n",
    "        # print(\"//////////////////////////////\")\n",
    "#         example = list(clients_batched[client].as_numpy_iterator())\n",
    "#         example[0]['age']\n",
    "        \n",
    "#         print(\"clients_batched: \", clients_batched[client])\n",
    "        \n",
    "#                 print(\"clients: \", (clients[0][0]) )\n",
    "        di = get_DI(clients_batched[client])\n",
    "#         print(clients_batched[client])\n",
    "        xi = clients_batched[client][cols].copy().values\n",
    "        x = sc.fit_transform(xi)\n",
    "        y = clients_batched[client][['income']].copy().values\n",
    "        \n",
    "        # print(type(list(zip(x,y))) )\n",
    "        data = list(zip(x,y))\n",
    "        train_data = list(list(zip(*data))[0])\n",
    "        train_label = list(list(zip(*data))[1])\n",
    "\n",
    "        max_y = np.argmax(train_label, axis=-1)\n",
    "        sorted_zip = sorted(zip(max_y, train_label, train_data), key=lambda x: x[0])\n",
    "        data_shard = [(x,y) for _,y,x in sorted_zip]\n",
    "\n",
    "        data_x = []\n",
    "        label_y = []\n",
    "        for x in data_shard:\n",
    "            data_x.append(x[0])\n",
    "            label_y.append(x[1])\n",
    "        # data_x, label_y = zip(*data_shard)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((list(np.array(data_x)),list(np.array(label_y))))\n",
    "        fitter = dataset.shuffle(len(y)).batch(126)\n",
    "        # print(type(fitter))\n",
    "#         fitter = sc.fit_transform(clients_batched[client])\n",
    "#         fitter = tf.data.Dataset.from_tensor_slices(( fitter))\n",
    "        # fitter = tf.data.Dataset.from_tensor_slices((x, y)).batch(len(y))\n",
    "        \n",
    "        history = local_model.fit(fitter, epochs=1, verbose=1)\n",
    "        \n",
    "#         get client acc, loss\n",
    "#         print(client)\n",
    "        if(len(client_loss[client])== 0):\n",
    "            client_loss[client] = [history.history['loss'][0]]\n",
    "            client_accuracy[client] = [history.history['binary_accuracy'][0]]\n",
    "            client_frequency[client] = [len(clients_batched[client])]\n",
    "            client_DI[client] = [di]\n",
    "        \n",
    "        else:\n",
    "            client_loss[client] = np.append(client_loss[client], (history.history['loss'][0]))\n",
    "            client_frequency[client] = np.append(client_frequency[client], len(clients_batched[client]))\n",
    "            client_accuracy[client] = np.append(client_accuracy[client], (history.history['binary_accuracy'][0]))\n",
    "            client_DI[client] = np.append(client_DI[client] ,di)\n",
    "        \n",
    "        epoch_freq += len(clients_batched[client])\n",
    "        \n",
    "        print(\"client\", client, \"\\nloss -->\" ,client_loss[client], \"\\nfreq->\", client_frequency[client], \"\\naccuracy->\", client_accuracy[client], \n",
    "             \"\\nDI-->\", client_DI[client])\n",
    "        \n",
    "        #scale the model weights and add to list\n",
    "        scaling_factor = weight_scalling_factor(fitter)\n",
    "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "        scaled_local_weight_list.append(scaled_weights)\n",
    "        \n",
    "        #clear session to free memory after each communication round\n",
    "        K.clear_session()\n",
    "        \n",
    "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "    \n",
    "    #update global model \n",
    "    global_model.set_weights(average_weights)\n",
    "    \n",
    "    global_freq_list.append(epoch_freq)\n",
    "    epoch_freq = 0\n",
    "    \n",
    "\n",
    "#     test global model and print out metrics after each communications round\n",
    "    # print(\"x_test\" , type(X_test))\n",
    "    X_test_trans = sc.fit_transform(X_test)\n",
    "    test_batched_tensor = tf.data.Dataset.from_tensor_slices(( X_test_trans,y_test)).batch(len(y_test))\n",
    "    for(X_test1, Y_test1) in test_batched_tensor:\n",
    "        global_acc, global_loss = test_model(X_test1, Y_test1, global_model, comm_round)\n",
    "        global_loss_list.append(global_loss)\n",
    "        global_acc_list.append(global_acc)\n",
    "\n",
    "        # print(\"x_test\" , type(X_test), \" y_test \", type(y_test),  )\n",
    "        di_global = get_DI(pd.concat([X_test,y_test], axis = 1))\n",
    "        global_di_list.append(di_global)\n",
    "        \n",
    "        print(\"global_loss_list: \", global_loss_list )\n",
    "        print(\"global_acc_list: \", global_acc_list )\n",
    "        print(\"global_freq_list: \", global_freq_list)\n",
    "        print(\"global_di_list: \", global_di_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f7eba6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>marital-status_Divorced</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Portugal</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36945</td>\n",
       "      <td>77</td>\n",
       "      <td>158847</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37802</td>\n",
       "      <td>37</td>\n",
       "      <td>709445</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43538</td>\n",
       "      <td>61</td>\n",
       "      <td>225970</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>52</td>\n",
       "      <td>155233</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25439</td>\n",
       "      <td>23</td>\n",
       "      <td>235894</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39068</th>\n",
       "      <td>1539</td>\n",
       "      <td>38</td>\n",
       "      <td>452353</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39069</th>\n",
       "      <td>48723</td>\n",
       "      <td>25</td>\n",
       "      <td>390657</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39070</th>\n",
       "      <td>32005</td>\n",
       "      <td>45</td>\n",
       "      <td>178922</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39071</th>\n",
       "      <td>14825</td>\n",
       "      <td>45</td>\n",
       "      <td>151817</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39072</th>\n",
       "      <td>9567</td>\n",
       "      <td>21</td>\n",
       "      <td>121468</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39073 rows  95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  age  fnlwgt  education  educational-num  capital-gain  \\\n",
       "0           36945   77  158847        8.0               11             0   \n",
       "1           37802   37  709445       11.0                9             0   \n",
       "2           43538   61  225970       11.0                9             0   \n",
       "3             104   52  155233       11.0                9             0   \n",
       "4           25439   23  235894        1.0                7             0   \n",
       "...           ...  ...     ...        ...              ...           ...   \n",
       "39068        1539   38  452353       15.0               10             0   \n",
       "39069       48723   25  390657       15.0               10             0   \n",
       "39070       32005   45  178922       11.0                9             0   \n",
       "39071       14825   45  151817       12.0               14             0   \n",
       "39072        9567   21  121468       15.0               10             0   \n",
       "\n",
       "       capital-loss  hours-per-week  income  marital-status_Divorced  ...  \\\n",
       "0                 0              25       0                    False  ...   \n",
       "1                 0              40       0                    False  ...   \n",
       "2                 0              40       1                    False  ...   \n",
       "3                 0              28       0                    False  ...   \n",
       "4                 0              55       0                    False  ...   \n",
       "...             ...             ...     ...                      ...  ...   \n",
       "39068             0              40       0                     True  ...   \n",
       "39069             0              40       0                    False  ...   \n",
       "39070             0              20       0                    False  ...   \n",
       "39071             0              36       0                    False  ...   \n",
       "39072             0              40       0                    False  ...   \n",
       "\n",
       "       native-country_Portugal  native-country_Puerto-Rico  \\\n",
       "0                        False                       False   \n",
       "1                        False                       False   \n",
       "2                        False                       False   \n",
       "3                        False                       False   \n",
       "4                        False                       False   \n",
       "...                        ...                         ...   \n",
       "39068                    False                       False   \n",
       "39069                    False                       False   \n",
       "39070                    False                       False   \n",
       "39071                    False                       False   \n",
       "39072                    False                       False   \n",
       "\n",
       "       native-country_Scotland  native-country_South  native-country_Taiwan  \\\n",
       "0                        False                 False                  False   \n",
       "1                        False                 False                  False   \n",
       "2                        False                 False                  False   \n",
       "3                        False                 False                  False   \n",
       "4                        False                 False                  False   \n",
       "...                        ...                   ...                    ...   \n",
       "39068                    False                 False                  False   \n",
       "39069                    False                 False                  False   \n",
       "39070                    False                 False                  False   \n",
       "39071                    False                 False                  False   \n",
       "39072                    False                 False                  False   \n",
       "\n",
       "       native-country_Thailand  native-country_Trinadad&Tobago  \\\n",
       "0                        False                           False   \n",
       "1                        False                           False   \n",
       "2                        False                           False   \n",
       "3                        False                           False   \n",
       "4                        False                           False   \n",
       "...                        ...                             ...   \n",
       "39068                    False                           False   \n",
       "39069                    False                           False   \n",
       "39070                    False                           False   \n",
       "39071                    False                           False   \n",
       "39072                    False                           False   \n",
       "\n",
       "       native-country_United-States  native-country_Vietnam  \\\n",
       "0                              True                   False   \n",
       "1                              True                   False   \n",
       "2                              True                   False   \n",
       "3                              True                   False   \n",
       "4                              True                   False   \n",
       "...                             ...                     ...   \n",
       "39068                          True                   False   \n",
       "39069                          True                   False   \n",
       "39070                          True                   False   \n",
       "39071                          True                   False   \n",
       "39072                          True                   False   \n",
       "\n",
       "       native-country_Yugoslavia  \n",
       "0                          False  \n",
       "1                          False  \n",
       "2                          False  \n",
       "3                          False  \n",
       "4                          False  \n",
       "...                          ...  \n",
       "39068                      False  \n",
       "39069                      False  \n",
       "39070                      False  \n",
       "39071                      False  \n",
       "39072                      False  \n",
       "\n",
       "[39073 rows x 95 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_set1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2208b3c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[123], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mstats\u001b[39;00m \n\u001b[0;32m      5\u001b[0m pdfs \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats \n",
    "\n",
    "pdfs = []\n",
    "for i in list(client_accuracy.keys()):\n",
    "    print(\"client_\",i, \" loss: \", client_loss[i],\"freq: \", client_frequency[i], \"acc\", client_accuracy[i])\n",
    "    \n",
    "#     norm\n",
    "#     mean, std = stats.norm.fit(client_loss[i])\n",
    "#     pdf =  stats.norm.pdf(client_loss[i], mean, std)\n",
    "\n",
    "#     df_mean = np.mean(client_frequency[i])\n",
    "#     df_std = np.std(client_frequency[i])\n",
    "#     pdf = stats.norm.pdf(client_frequency[i], df_mean, df_std)\n",
    "    \n",
    "#     lognorm\n",
    "#     shape, loc, scale = stats.lognorm.fit(client_loss[i])\n",
    "#     pdf = stats.lognorm.pdf(client_loss[i], shape, loc, scale)\n",
    "\n",
    "#     beta\n",
    "#     beta_params = stats.beta.fit(client_loss[i])\n",
    "#     pdf = stats.beta.pdf(client_loss[i], beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "\n",
    "#     burr\n",
    "#     burr_params = stats.burr.fit(client_loss[i])\n",
    "#     pdf = stats.burr.pdf(client_loss[i], burr_params[0], burr_params[1], burr_params[2], burr_params[3])\n",
    "\n",
    "    \n",
    "#  gamma\n",
    "    shape, loc, scale = stats.gamma.fit(client_loss[i])\n",
    "    pdf = stats.gamma.cdf(client_loss[i], shape, loc=loc, scale=scale)\n",
    "    \n",
    "    pdfs.append(pdf)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    ax = sns.displot( x = pdf, kind = \"kde\", height=10, aspect=2,\n",
    "                linewidth = 5 )\n",
    "    plt.ylabel(\"LOSS\")\n",
    "#     plt.xlabel(\"Loss\")\n",
    "    plt.xlabel(\"CDF\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739fe197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats \n",
    "\n",
    "for i in list(client_accuracy.keys()):\n",
    "    print(\"client_\",i, \"\\nloss: \", client_loss[i],\"\\nfreq: \", client_frequency[i], \"\\nacc\", client_accuracy[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cb1f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"_GAMMA_\")\n",
    "\n",
    "cdfs_loss_gamma = []\n",
    "cdfs_acc_gamma = []\n",
    "cdfs_freq_gamma = []\n",
    "for i in list(client_accuracy.keys()):\n",
    "#     print(\"client_\",i, \"\\nloss: \", client_loss[i],\"\\nfreq: \", client_frequency[i], \"\\nacc\", client_accuracy[i])\n",
    "\n",
    "    shape, loc, scale = stats.gamma.fit(client_loss[i])\n",
    "    cdf_loss_gamma =  stats.gamma.cdf(client_loss[i], shape, loc, scale)\n",
    "    cdfs_loss_gamma.append(cdf_loss_gamma)\n",
    "\n",
    "    shape, loc, scale= stats.gamma.fit(client_accuracy[i])\n",
    "    cdf_acc_gamma = stats.gamma.cdf(client_accuracy[i],shape, loc, scale)\n",
    "    cdfs_acc_gamma.append(cdf_acc_gamma)\n",
    "\n",
    "    shape, loc, scale  = stats.gamma.fit(client_frequency[i])\n",
    "    cdf_freq_gamma = stats.gamma.cdf(client_frequency[i],shape, loc, scale )\n",
    "    cdfs_freq_gamma.append(cdf_freq_gamma)\n",
    "\n",
    "\n",
    "print(\"ACCURACY\")\n",
    "for i in range(len(cdfs_acc_gamma)):\n",
    "    for j in range(i+1,len(cdfs_acc_gamma)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(cdfs_acc_gamma[i], cdfs_acc_gamma[j]))\n",
    "\n",
    "\n",
    "shape, loc, scale = stats.gamma.fit(global_acc_list)\n",
    "cdf_global_acc_gamma =  stats.gamma.cdf(global_acc_list, shape, loc, scale)\n",
    "\n",
    "for i in range(len(cdfs_acc_gamma)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(cdfs_acc_gamma[i], cdf_global_acc_gamma))\n",
    "\n",
    "print(\"LOSS\")\n",
    "for i in range(len(cdfs_loss_gamma)):\n",
    "    for j in range(i+1,len(cdfs_loss_gamma)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(cdfs_loss_gamma[i], cdfs_loss_gamma[j]))\n",
    "\n",
    "\n",
    "shape, loc, scale = stats.gamma.fit(global_loss_list)\n",
    "cdf_global_loss_gamma =  stats.gamma.cdf(global_loss_list, shape, loc, scale)\n",
    "\n",
    "for i in range(len(cdfs_loss_gamma)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(cdfs_loss_gamma[i], cdf_global_loss_gamma))\n",
    "\n",
    "print(\"FREQUENCY\")\n",
    "for i in range(len(cdfs_freq_gamma)):\n",
    "    for j in range(i+1,len(cdfs_freq_gamma)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(cdfs_freq_gamma[i], cdfs_freq_gamma[j]))\n",
    "\n",
    "\n",
    "shape, loc, scale = stats.gamma.fit(global_freq_list)\n",
    "cdf_global_freq_gamma =  stats.gamma.cdf(global_freq_list,shape, loc, scale)\n",
    "\n",
    "for i in range(len(cdfs_freq_gamma)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(cdfs_freq_gamma[i], cdf_global_freq_gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30032e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in range(len(pdfs_loss_gamma)):\n",
    "#     print(i,\" and global: \" , stats.wasserstein_distance(pdfs_loss_gamma[i], pdf_global_loss_gamma))\n",
    "#     M = ot.dist(pdfs_loss_gamma[i], pdf_global_loss_gamma, metric='euclidean')\n",
    "#     W = ot.emd2(pdfs_loss_gamma[i], pdf_global_loss_gamma, M)\n",
    "#     print(\"actual \", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c29d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"_NORM_\")\n",
    "\n",
    "pdfs_loss_norm = []\n",
    "pdfs_acc_norm = []\n",
    "pdfs_freq_norm = []\n",
    "for i in list(client_accuracy.keys()):\n",
    "#     print(\"client_\",i, \" loss: \", client_loss[i],\"freq: \", client_frequency[i], \"acc\", client_accuracy[i])\n",
    "    \n",
    "    mean, std = stats.norm.fit(client_loss[i])\n",
    "    pdf_loss_norm =  stats.norm.pdf(client_loss[i], mean, std)\n",
    "    pdfs_loss_norm.append(pdf_loss_norm)\n",
    "\n",
    "    mean, std = stats.norm.fit(client_accuracy[i])\n",
    "    pdf_acc_norm = stats.norm.pdf(client_accuracy[i],mean, std )\n",
    "    pdfs_acc_norm.append(pdf_acc_norm)\n",
    "    \n",
    "    mean, std  = stats.norm.fit(client_frequency[i])\n",
    "    pdf_freq_norm = stats.norm.pdf(client_frequency[i], mean, std )\n",
    "    pdfs_freq_norm.append(pdf_freq_norm)\n",
    "    \n",
    "    \n",
    "print(\"ACCURACY\")\n",
    "for i in range(len(pdfs_acc_norm)):\n",
    "    for j in range(i+1,len(pdfs_acc_norm)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_acc_norm[i], pdfs_acc_norm[j]))\n",
    "        \n",
    "        \n",
    "mean, std = stats.norm.fit(global_acc_list)\n",
    "pdf_global_acc_norm =  stats.norm.pdf(global_acc_list, mean, std)\n",
    "\n",
    "for i in range(len(pdfs_acc_norm)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_acc_norm[i], pdf_global_acc_norm))\n",
    "    \n",
    "print(\"LOSS\")\n",
    "for i in range(len(pdfs_loss_norm)):\n",
    "    for j in range(i+1,len(pdfs_loss_norm)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_loss_norm[i], pdfs_loss_norm[j]))\n",
    "        \n",
    "        \n",
    "mean, std = stats.norm.fit(global_loss_list)\n",
    "pdf_global_loss_norm =  stats.norm.pdf(global_loss_list, mean, std)\n",
    "\n",
    "for i in range(len(pdfs_loss_norm)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_loss_norm[i], pdf_global_loss_norm))\n",
    "    \n",
    "print(\"FREQUENCY\")\n",
    "for i in range(len(pdfs_freq_norm)):\n",
    "    for j in range(i+1,len(pdfs_freq_norm)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_freq_norm[i], pdfs_freq_norm[j]))\n",
    "        \n",
    "        \n",
    "mean, std = stats.norm.fit(global_freq_list)\n",
    "pdf_global_freq_norm =  stats.norm.pdf(global_freq_list, mean, std)\n",
    "\n",
    "for i in range(len(pdfs_freq_norm)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_freq_norm[i], pdf_global_freq_norm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a177e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"_LOGNORM_\")\n",
    "\n",
    "pdfs_loss = []\n",
    "pdfs_acc = []\n",
    "pdfs_freq = []\n",
    "for i in list(client_accuracy.keys()):\n",
    "#     print(\"client_\",i, \"\\nloss: \", client_loss[i],\"\\nfreq: \", client_frequency[i], \"\\nacc\", client_accuracy[i])\n",
    "\n",
    "    shape, loc, scale = stats.lognorm.fit(client_loss[i])\n",
    "    pdf_loss =  stats.lognorm.pdf(client_loss[i], shape, loc, scale)\n",
    "    pdfs_loss.append(pdf_loss)\n",
    "\n",
    "    shape, loc, scale= stats.lognorm.fit(client_accuracy[i])\n",
    "    pdf_acc = stats.lognorm.pdf(client_accuracy[i],shape, loc, scale)\n",
    "    pdfs_acc.append(pdf_acc)\n",
    "\n",
    "    shape, loc, scale  = stats.lognorm.fit(client_frequency[i])\n",
    "    pdf_freq = stats.lognorm.pdf(client_frequency[i],shape, loc, scale )\n",
    "    pdfs_freq.append(pdf_freq)\n",
    "\n",
    "\n",
    "print(\"ACCURACY\")\n",
    "for i in range(len(pdfs_acc)):\n",
    "    for j in range(i+1,len(pdfs_acc)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_acc[i], pdfs_acc[j]))\n",
    "\n",
    "\n",
    "shape, loc, scale = stats.lognorm.fit(global_acc_list)\n",
    "pdf_global_acc =  stats.lognorm.pdf(global_acc_list, shape, loc, scale)\n",
    "\n",
    "for i in range(len(pdfs_acc)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_acc[i], pdf_global_acc))\n",
    "\n",
    "print(\"LOSS\")\n",
    "for i in range(len(pdfs_loss)):\n",
    "    for j in range(i+1,len(pdfs_loss)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_loss[i], pdfs_loss[j]))\n",
    "\n",
    "\n",
    "shape, loc, scale = stats.lognorm.fit(global_loss_list)\n",
    "pdf_global_loss =  stats.lognorm.pdf(global_loss_list, shape, loc, scale)\n",
    "\n",
    "for i in range(len(pdfs_loss)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_loss[i], pdf_global_loss))\n",
    "\n",
    "print(\"FREQUENCY\")\n",
    "for i in range(len(pdfs_freq)):\n",
    "    for j in range(i+1,len(pdfs_freq)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_freq[i], pdfs_freq[j]))\n",
    "\n",
    "\n",
    "shape, loc, scale = stats.lognorm.fit(global_freq_list)\n",
    "pdf_global_freq =  stats.lognorm.pdf(global_freq_list,shape, loc, scale)\n",
    "\n",
    "for i in range(len(pdfs_freq)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_freq[i], pdf_global_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10261017",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"_BETA_\")\n",
    "\n",
    "pdfs_loss = []\n",
    "pdfs_acc = []\n",
    "pdfs_freq = []\n",
    "for i in list(client_accuracy.keys()):\n",
    "\n",
    "    beta_params = stats.beta.fit(client_loss[i])\n",
    "    pdf_loss =  stats.beta.pdf(client_loss[i],beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "    pdfs_loss.append(pdf_loss)\n",
    "\n",
    "    beta_params = stats.beta.fit(client_accuracy[i])\n",
    "    pdf_acc = stats.beta.pdf(client_accuracy[i],beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "    pdfs_acc.append(pdf_acc)\n",
    "\n",
    "    beta_params  = stats.beta.fit(client_frequency[i])\n",
    "    pdf_freq = stats.beta.pdf(client_frequency[i],beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "    pdfs_freq.append(pdf_freq)\n",
    "\n",
    "\n",
    "print(\"ACCURACY\")\n",
    "for i in range(len(pdfs_acc)):\n",
    "    for j in range(i+1,len(pdfs_acc)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_acc[i], pdfs_acc[j]))\n",
    "\n",
    "\n",
    "beta_params = stats.beta.fit(global_acc_list)\n",
    "pdf_global_acc =  stats.beta.pdf(global_acc_list, beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "\n",
    "for i in range(len(pdfs_acc)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_acc[i], pdf_global_acc))\n",
    "\n",
    "print(\"LOSS\")\n",
    "for i in range(len(pdfs_loss)):\n",
    "    for j in range(i+1,len(pdfs_loss)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_loss[i], pdfs_loss[j]))\n",
    "\n",
    "\n",
    "beta_params = stats.beta.fit(global_loss_list)\n",
    "pdf_global_loss =  stats.beta.pdf(global_loss_list, beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "\n",
    "for i in range(len(pdfs_loss)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_loss[i], pdf_global_loss))\n",
    "\n",
    "print(\"FREQUENCY\")\n",
    "for i in range(len(pdfs_freq)):\n",
    "    for j in range(i+1,len(pdfs_freq)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_freq[i], pdfs_freq[j]))\n",
    "\n",
    "\n",
    "beta_params = stats.beta.fit(global_freq_list)\n",
    "pdf_global_freq =  stats.beta.pdf(global_freq_list,beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "\n",
    "for i in range(len(pdfs_freq)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_freq[i], pdf_global_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3cc154",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"_BURR_\")\n",
    "\n",
    "pdfs_loss = []\n",
    "pdfs_acc = []\n",
    "pdfs_freq = []\n",
    "for i in list(client_accuracy.keys()):\n",
    "\n",
    "    params = stats.burr.fit(client_loss[i])\n",
    "    pdf_loss =  stats.burr.pdf(client_loss[i],params[0], params[1], params[2], params[3])\n",
    "    pdfs_loss.append(pdf_loss)\n",
    "\n",
    "    beta_params = stats.burr.fit(client_accuracy[i])\n",
    "    pdf_acc = stats.burr.pdf(client_accuracy[i],beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "    pdfs_acc.append(pdf_acc)\n",
    "\n",
    "    beta_params  = stats.burr.fit(client_frequency[i])\n",
    "    pdf_freq = stats.burr.pdf(client_frequency[i],beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "    pdfs_freq.append(pdf_freq)\n",
    "\n",
    "\n",
    "print(\"ACCURACY\")\n",
    "for i in range(len(pdfs_acc)):\n",
    "    for j in range(i+1,len(pdfs_acc)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_acc[i], pdfs_acc[j]))\n",
    "\n",
    "\n",
    "beta_params = stats.burr.fit(global_acc_list)\n",
    "pdf_global_acc =  stats.burr.pdf(global_acc_list, beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "\n",
    "for i in range(len(pdfs_acc)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_acc[i], pdf_global_acc))\n",
    "\n",
    "print(\"LOSS\")\n",
    "for i in range(len(pdfs_loss)):\n",
    "    for j in range(i+1,len(pdfs_loss)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_loss[i], pdfs_loss[j]))\n",
    "\n",
    "\n",
    "beta_params = stats.burr.fit(global_loss_list)\n",
    "pdf_global_loss =  stats.burr.pdf(global_loss_list, beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "\n",
    "for i in range(len(pdfs_loss)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_loss[i], pdf_global_loss))\n",
    "\n",
    "print(\"FREQUENCY\")\n",
    "for i in range(len(pdfs_freq)):\n",
    "    for j in range(i+1,len(pdfs_freq)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_freq[i], pdfs_freq[j]))\n",
    "\n",
    "\n",
    "beta_params = stats.burr.fit(global_freq_list)\n",
    "pdf_global_freq =  stats.burr.pdf(global_freq_list,beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "\n",
    "for i in range(len(pdfs_freq)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_freq[i], pdf_global_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd01c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(client_loss.keys()):\n",
    "#     if(i== len(list(client_loss.keys()))-1):\n",
    "#         continue\n",
    "    print(\"client_\",i, \"loss: \", client_loss[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650336b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(client_loss.keys()):\n",
    "#     if(i== len(list(client_loss.keys()))-1):\n",
    "#         continue\n",
    "    print(\"client_\",i, \"freq: \", client_frequency[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a70793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdfs)):\n",
    "    for j in range(i+1,len(pdfs)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs[i], pdfs[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2620a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gamma\n",
    "shape, loc, scale = stats.gamma.fit(global_freq_list)\n",
    "pdf_global = stats.gamma.pdf(global_freq_list, shape, loc=loc, scale=scale)\n",
    "\n",
    "# df_mean = np.mean(global_loss_list)\n",
    "# df_std = np.std(global_loss_list)\n",
    "# pdf_global = stats.norm.pdf(global_loss_list, df_mean, df_std)\n",
    "\n",
    "# mean, std = stats.norm.fit(global_freq_list)\n",
    "# pdf_global =  stats.norm.pdf(global_freq_list, mean, std)\n",
    "\n",
    "# lognorm\n",
    "# shape, loc, scale = stats.lognorm.fit(global_loss_list)\n",
    "# pdf_global = stats.lognorm.pdf(global_loss_list, shape, loc, scale)\n",
    "\n",
    "# global_acc_list\n",
    "# global_freq_list\n",
    "\n",
    "# burr\n",
    "# burr_params = stats.beta.fit(global_freq_list)\n",
    "# pdf_global = stats.beta.pdf(global_freq_list, burr_params[0], burr_params[1], burr_params[2], burr_params[3])\n",
    "\n",
    "for i in range(len(pdfs)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs[i], pdf_global))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de13219",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8879a3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fitter import Fitter, get_common_distributions, get_distributions\n",
    "\n",
    "# for i in list(client_loss.keys()):\n",
    "#     height = client_loss[i]\n",
    "\n",
    "#     f = Fitter(height,\n",
    "#                distributions=['gamma',\n",
    "#                               'lognorm',\n",
    "#                               \"beta\",\n",
    "#                               \"burr\",\n",
    "#                               \"norm\"])\n",
    "#     f.fit()\n",
    "#     f.summary()\n",
    "\n",
    "#     sns.set_style('white')\n",
    "#     sns.set_context(\"paper\", font_scale = 2)\n",
    "#     sns.displot(data=dataset, x=\"Height\", kind=\"hist\", bins = 100, aspect = 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93def9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 clients---> gender, race, income\n",
    "pdfs = []\n",
    "for i in list(client_loss.keys()):\n",
    "    if(i== len(list(client_loss.keys()))-1):\n",
    "        continue\n",
    "    print(\"client_\",i, \" loss: \", client_loss[i],\"freq: \", client_frequency[i])\n",
    "\n",
    "#     shape, loc, scale = stats.gamma.fit(client_loss[i])\n",
    "    \n",
    "#     # Printing the estimated parameters\n",
    "#     print(\"Shape:\", shape)\n",
    "#     print(\"Location:\", loc)\n",
    "#     print(\"Scale:\", scale)\n",
    "#     pdf = stats.gamma.pdf(client_loss[i], shape, loc=loc, scale=scale)\n",
    "    \n",
    "    \n",
    "    df_mean = np.mean(client_loss[i])\n",
    "    df_std = np.std(client_loss[i])\n",
    "    pdf = stats.norm.pdf(client_loss[i], df_mean, df_std)\n",
    "    pdfs.append(pdf)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    ax = sns.displot( x = pdf, kind = \"kde\", height=10, aspect=2,\n",
    "                linewidth = 5 )\n",
    "    ax.fig.suptitle('Original distribution', size = 20)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xlabel(\"Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c9992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdfs)):\n",
    "    for j in range(i+1,len(pdfs)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs[i], pdfs[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bbbe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape, loc, scale = stats.gamma.fit(global_loss_list)\n",
    "pdf_global = stats.gamma.pdf(global_loss_list, shape, loc=loc, scale=scale)\n",
    "\n",
    "for i in range(len(pdfs)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs[i], pdf_global))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d36ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment plotter\n",
    "\n",
    "# for i in list(client_loss.keys()):\n",
    "#     if(i== len(list(client_loss.keys()))-1):\n",
    "#         continue\n",
    "#     print(\"client_\",i, \" loss: \", client_loss[i],\"freq: \", client_frequency[i])\n",
    "    \n",
    "# #     df_mean = np.mean(client_loss[i])\n",
    "# #     df_std = np.std(client_loss[i])\n",
    "# #     pdf = stats.norm.pdf(client_loss[i], df_mean, df_std)\n",
    "\n",
    "#     shape, loc, scale = stats.gamma.fit(client_loss[i])\n",
    "    \n",
    "#     # Printing the estimated parameters\n",
    "# #     print(\"Shape:\", shape)\n",
    "# #     print(\"Location:\", loc)\n",
    "# #     print(\"Scale:\", scale)\n",
    "#     pdf = stats.gamma.pdf(client_loss[i], shape, loc=loc, scale=scale)\n",
    "\n",
    "# #     plt.plot(client_loss[i], pdf, \"-o\", label = i)\n",
    "\n",
    "# #     client_loss[i] = stats.gamma.rvs(1, size=5000)+5\n",
    "#     sns.set_style(\"whitegrid\")\n",
    "\n",
    "#     ax = sns.displot( x = pdf, kind = \"kde\", height=10, aspect=2,\n",
    "#                 linewidth = 5 )\n",
    "#     ax.fig.suptitle('Original distribution', size = 20)\n",
    "# #     plt.plot(client_loss[i], client_frequency[i], \"-o\", label = i)\n",
    "# #     plt.legend()\n",
    "#     plt.ylabel(\"Frequency\")\n",
    "#     plt.xlabel(\"Loss\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670d1d42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:03:08.033027Z",
     "start_time": "2021-07-16T00:03:07.867893Z"
    }
   },
   "outputs": [],
   "source": [
    "score = global_model.evaluate(X_test, y_test, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcaa73e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:03:08.653744Z",
     "start_time": "2021-07-16T00:03:08.484057Z"
    }
   },
   "outputs": [],
   "source": [
    "nn_preds = global_model.predict(X_test)\n",
    "nn_preds = (nn_preds > 0.5)\n",
    "\n",
    "nn_precision =precision_score(y_test, nn_preds)\n",
    "nn_recall = recall_score(y_test, nn_preds)\n",
    "nn_accuracy = accuracy_score(y_test, nn_preds)\n",
    "nn_f1 = f1_score(y_test, nn_preds)\n",
    "\n",
    "\n",
    "print(\"Precision = {}\".format(nn_precision))\n",
    "print(\"Recall = {}\".format(nn_recall))\n",
    "print(\"Accuracy = {}\".format(nn_accuracy))\n",
    "print(\"f1 = {}\".format(nn_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6360dd5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:03:09.275052Z",
     "start_time": "2021-07-16T00:03:09.268152Z"
    }
   },
   "outputs": [],
   "source": [
    "arr = nn_preds > 0.5\n",
    "\n",
    "unique, counts = np.unique(arr, return_counts=True)\n",
    "\n",
    "np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a5ee99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T19:56:25.650336Z",
     "start_time": "2021-07-14T19:56:25.620Z"
    }
   },
   "outputs": [],
   "source": [
    "# pdf for client losses\n",
    "# x-loss\n",
    "# y- frequency\n",
    "# each client has one pdf for all rounds\n",
    "# using histogram\n",
    "\n",
    "\n",
    "# drop client\n",
    "# non iid\n",
    "# fedavg\n",
    "\n",
    "\n",
    "# gender dist\n",
    "# kernel density\n",
    "\n",
    "\n",
    "# non-iid, loss to accuracy\n",
    "# 4client"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
