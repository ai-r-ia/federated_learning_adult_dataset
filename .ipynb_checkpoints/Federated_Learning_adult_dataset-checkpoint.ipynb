{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cb54a96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T12:48:49.512456Z",
     "start_time": "2021-07-15T12:48:46.946937Z"
    }
   },
   "source": [
    "# Federated Learning Implementation with tensorflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b29fd2ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:57:57.329013Z",
     "start_time": "2021-07-15T23:57:57.321303Z"
    }
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Adult Dataset Salary Prediction \n",
    "# This is part of a study to investigate Differetinal privacy in Machine learning, Naturally we wish to compare it with federated learning.\n",
    "\n",
    "\n",
    "\n",
    "# Refrences:\n",
    "\n",
    "# [1] Federated Learning with Non-IID Data, Yue Zhao et al, arXiv: 1806.00582v1, 2 Jun 2018\n",
    "# [2] Communication-Efficient Learning of Deep Networks from Decentralized Data, H. Brendan McMahan et al, arXiv:1602.05629v3 [cs.LG] 28 Feb 2017\n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09b7dd46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:57:57.590963Z",
     "start_time": "2021-07-15T23:57:57.572204Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riash\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\riash\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\riash\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.metrics import precision_score,recall_score, accuracy_score,confusion_matrix,f1_score\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import History\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00b9bf6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:52.574848Z",
     "start_time": "2021-07-15T23:59:52.208912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "39068    0\n",
      "39069    1\n",
      "39070    1\n",
      "39071    1\n",
      "39072    1\n",
      "Name: race_White, Length: 39073, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((9768, 94), (9768, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Train/Test Data seperation\n",
    "\n",
    "file_out = pd.read_csv('Data/adult_processed.csv')\n",
    "cols = []\n",
    "for i in list(file_out.columns):\n",
    "    if  i != 'income':\n",
    "        cols.append(i)\n",
    "\n",
    "feature_set1 = pd.read_csv('Data/train.csv')\n",
    "feature_set2 = pd.read_csv('Data/test.csv')\n",
    "\n",
    "print(feature_set1['race_White'])\n",
    "x = feature_set1[cols].copy().values\n",
    "y = feature_set1[['income']].copy().values\n",
    "        \n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(x)\n",
    "y_train = y\n",
    "\n",
    "x2 = feature_set2[cols].copy().values\n",
    "y2 = feature_set2[['income']].copy().values\n",
    "        \n",
    "X_test = sc.transform(x2)\n",
    "y_test = y2\n",
    "\n",
    "\n",
    "X_test.shape, y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1b1abdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39073, 94), (12919, 94), (26154, 94))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/Test data based on  gender: 4 sets\n",
    "\n",
    "# train\n",
    "\n",
    "female_features =  feature_set1[feature_set1['gender_Female']==1]\n",
    "x_female = female_features[cols].copy().values\n",
    "y_female = female_features[['income']].copy().values\n",
    "\n",
    "X_train_female = sc.fit_transform(x_female)\n",
    "y_train_female = y_female\n",
    "\n",
    "male_features = feature_set1[feature_set1['gender_Male']==1] \n",
    "x_male = male_features[cols].copy().values\n",
    "y_male = male_features[['income']].copy().values\n",
    "\n",
    "X_train_male = sc.fit_transform(x_male)\n",
    "y_train_male = y_male\n",
    "\n",
    "# test\n",
    "\n",
    "female_features2 =  feature_set2[feature_set2['gender_Female']==1]\n",
    "x_female2 = female_features2[cols].copy().values\n",
    "y_female2 = female_features2[['income']].copy().values\n",
    "\n",
    "X_test_female = sc.fit_transform(x_female2)\n",
    "y_test_female = y_female2 \n",
    "\n",
    "male_features2 = feature_set2[feature_set2['gender_Male']==1] \n",
    "x_male2 = male_features2[cols].copy().values\n",
    "y_male2 = male_features2[['income']].copy().values\n",
    "\n",
    "X_test_male = sc.fit_transform(x_male2)\n",
    "y_test_male = y_male2\n",
    "\n",
    "\n",
    "# checks\n",
    "X_train.shape, X_train_female.shape, X_train_male.shape\n",
    "# X_test.shape, X_test_female.shape, X_test_male.shape\n",
    "# y_train.shape, y_train_female.shape, y_train_male.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f11a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# female_features_above30 = female_features[female_features['age']>30]\n",
    "# x_female_age = female_features_above30[cols].copy().values\n",
    "# y_female_age = female_features_above30[['income']].copy().values\n",
    "\n",
    "# X_train_female_age = sc.fit_transform(x_female_age)\n",
    "# y_train_female_age = y_female_age\n",
    "\n",
    "# male_features_above30 = male_features[male_features['age']>30]\n",
    "# x_male_age = male_features_above30[cols].copy().values\n",
    "# y_male_age = male_features_above30[['income']].copy().values\n",
    "\n",
    "# X_train_male_age = sc.fit_transform(x_male_age)\n",
    "# y_train_male_age = y_male_age\n",
    "\n",
    "# # test\n",
    "\n",
    "# female_features_above30_2 =  female_features2[female_features2['age']>30]\n",
    "# x_female_age2 = female_features_above30_2[cols].copy().values\n",
    "# y_female_age2 = female_features_above30_2[['income']].copy().values\n",
    "\n",
    "# X_test_female_age = sc.fit_transform(x_female_age2)\n",
    "# y_test_female_age = y_female_age2 \n",
    "\n",
    "# male_features_above30_2 = male_features2[male_features2['age']>30]\n",
    "# x_male_age2 = male_features_above30_2[cols].copy().values\n",
    "# y_male_age2 = male_features_above30_2[['income']].copy().values\n",
    "\n",
    "# X_test_male_age = sc.fit_transform(x_male_age2)\n",
    "# y_test_male_age = y_male_age2\n",
    "\n",
    "\n",
    "# # checks\n",
    "# X_train.shape, X_train_female_age.shape, X_train_male_age.shape\n",
    "# X_test.shape, X_test_female.shape, X_test_male.shape\n",
    "# y_train.shape, y_train_female.shape, y_train_male.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "066207c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:51.783759Z",
     "start_time": "2021-07-15T23:59:51.727576Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# def create_clients(image_list, label_list, num_clients=10, initial='clients'):\n",
    "    \n",
    "#     ''' return: a dictionary with keys clients' names and value as \n",
    "#                 data shards - tuple of images and label lists.\n",
    "#         args: \n",
    "#             image_list: a list of numpy arrays of training images\n",
    "#             label_list:a list of binarized labels for each image\n",
    "#             num_client: number of fedrated members (clients)\n",
    "#             initials: the clients'name prefix, e.g, clients_1 \n",
    "            \n",
    "#     '''\n",
    "\n",
    "#     #create a list of client names\n",
    "# #     client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n",
    "\n",
    "# #     iid\n",
    "# #     #randomize the data\n",
    "# #     data = list(zip(image_list, label_list))\n",
    "# #     random.shuffle(data)\n",
    "    \n",
    "   \n",
    "    \n",
    "# #     non-iid //////////////////////////////////////\n",
    "#     max_y = np.argmax(label_list, axis=-1)\n",
    "#     sorted_zip = sorted(zip(max_y, label_list, image_list), key=lambda x: x[0])\n",
    "#     data = [(x,y) for _,y,x in sorted_zip]\n",
    "\n",
    "# # LOGIC:\n",
    "# #    image_list length-->total data items\n",
    "# #    taking 50 images in each shard--> num_shards = image_list/41 gives 953 shards\n",
    "# #    num_shard = num_shards + 1 if(image_list%50 >0) \n",
    "\n",
    "#     num_shards, num_imgs = 953, 41\n",
    "#     idx_shard = [i for i in range(num_shards)]\n",
    "#     dict_users = {i: np.array([]) for i in range(num_clients)}\n",
    "# #     dict_users = [i for i in range(num_clients)]\n",
    "# #     idxs = np.arange(num_shards*num_imgs)\n",
    "# #     labels = dataset.train_labels.numpy()\n",
    "\n",
    "#     max_y = np.argmax(label_list, axis=-1)\n",
    "# #     image_list = np.argmax(image_list, axis=-1)\n",
    "# #     print(idxs.shape, label_list.shape)\n",
    "    \n",
    "# #     idxs_labels = np.vstack((idxs, max_y))\n",
    "# #     idxs_labels = idxs_labels[:, idxs_labels[1, :].argsort()]\n",
    "# #     idxs = idxs_labels[0, :]\n",
    "\n",
    "\n",
    "# #   ////////////////////////////////////////////////////  \n",
    "#     #shard data and place at each client\n",
    "# #     size = len(data)//num_clients\n",
    "# #     shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n",
    "\n",
    "# #     #number of clients must equal number of shards\n",
    "# #     assert(len(shards) == len(client_names))\n",
    "\n",
    "# #     print(len(image_list))\n",
    "# #     for i in range(len(client_names)):\n",
    "# #         print(client_names[i], len(shards[i]))\n",
    "              \n",
    "# #     return {client_names[i] : shards[i] for i in range(len(client_names))} \n",
    "\n",
    "\n",
    "# clients = create_clients(X_train, y_train, num_clients=15, initial='client')\n",
    "# # print(clients)\n",
    "\n",
    "# for i in range(len(clients.keys())):\n",
    "#         print(i, len(clients[i]))\n",
    "\n",
    "# print(type(clients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76379dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender split\n",
    "\n",
    "dict_users = {i: np.array([]) for i in range(4)}\n",
    "data_out = []\n",
    "\n",
    "def create_hetero_clients( image_list, label_list, start_client = 0, num_clients=10, initial='clients'):\n",
    "    \n",
    "    selected_inds = []\n",
    "\n",
    "    max_y = np.argmax(label_list, axis=-1)\n",
    "    sorted_zip = sorted(zip(max_y, label_list, image_list), key=lambda x: x[0])\n",
    "    data = [(x,y) for _,y,x in sorted_zip]\n",
    "    \n",
    "    data_out = data\n",
    "    \n",
    "    num_shards, num_imgs = int(len(image_list)/30), 30\n",
    "    idx_shard = [i for i in range(num_shards)]\n",
    "\n",
    "    min_shard = 1\n",
    "    max_shard = 60  #953/15 = 63.53\n",
    "    \n",
    "    random_shard_size = np.random.randint(min_shard, max_shard+1,\n",
    "                                          size=(num_clients-start_client))\n",
    "    random_shard_size = np.around(random_shard_size /\n",
    "                                  sum(random_shard_size) * num_shards)\n",
    "    random_shard_size = random_shard_size.astype(int)\n",
    "\n",
    "\n",
    "    if sum(random_shard_size) > num_shards:\n",
    "        \n",
    "        for i in range(start_client, num_clients):\n",
    "            # First assign each client 1 shard to ensure every client has\n",
    "            # atleast one shard of data\n",
    "            rand_set = set(np.random.choice(idx_shard, 1, replace=False))\n",
    "            idx_shard = list(set(idx_shard) - rand_set)\n",
    "            for rand in rand_set:\n",
    "                ind1 = rand*num_imgs\n",
    "                ind2 = (rand+1)*num_imgs\n",
    "                if(len(dict_users[i]) == 0):\n",
    "                    dict_users[i] = data[ind1: ind2]\n",
    "                else:\n",
    "                    dict_users[i] = np.concatenate(\n",
    "                    (dict_users[i],data[ind1: ind2]),\n",
    "                    axis=0)\n",
    "                selected_inds.extend([[ind1, ind2]])\n",
    "\n",
    "        random_shard_size = random_shard_size-1\n",
    "\n",
    "        # Next, randomly assign the remaining shards\n",
    "        for i in range(start_client, num_clients):\n",
    "            if len(idx_shard) == 0:\n",
    "                continue\n",
    "#             print(random_shard_size)\n",
    "            shard_size = random_shard_size[i-start_client]\n",
    "            if shard_size > len(idx_shard):\n",
    "                shard_size = len(idx_shard)\n",
    "            rand_set = set(np.random.choice(idx_shard, shard_size,\n",
    "                                            replace=False))\n",
    "            idx_shard = list(set(idx_shard) - rand_set)\n",
    "            for rand in rand_set:\n",
    "                ind1 = rand*num_imgs\n",
    "                ind2 = (rand+1)*num_imgs\n",
    "                if(len(dict_users[i]) == 0):\n",
    "                    dict_users[i] = data[ind1: ind2]\n",
    "                else:\n",
    "                    dict_users[i] = np.concatenate(\n",
    "                    (dict_users[i],data[ind1: ind2]),\n",
    "                    axis=0)\n",
    "                selected_inds.extend([[ind1, ind2]])\n",
    "\n",
    "    else:\n",
    "\n",
    "        for i in range(start_client, num_clients):\n",
    "#             print(random_shard_size)\n",
    "            shard_size = random_shard_size[i-start_client]\n",
    "#             shard_size = random_shard_size[int(i/len(random_shard_size)) - 1]\n",
    "            rand_set = set(np.random.choice(idx_shard, shard_size,\n",
    "                                            replace=False))\n",
    "            idx_shard = list(set(idx_shard) - rand_set)\n",
    "            for rand in rand_set:\n",
    "                ind1 = rand*num_imgs\n",
    "                ind2 = (rand+1)*num_imgs\n",
    "                if(len(dict_users[i]) == 0):\n",
    "                    dict_users[i] = data[ind1: ind2]\n",
    "                else:\n",
    "                    dict_users[i] = np.concatenate(\n",
    "                    (dict_users[i],data[ind1: ind2]),\n",
    "                    axis=0)\n",
    "                selected_inds.extend([[ind1, ind2]])\n",
    "\n",
    "        if len(idx_shard) > 0:\n",
    "            # Add the leftover shards to the client with minimum images:\n",
    "            shard_size = len(idx_shard)\n",
    "            # Add the remaining shard to the client with lowest data\n",
    "            k = min(dict_users, key=lambda x: len(dict_users.get(x)))\n",
    "            rand_set = set(np.random.choice(idx_shard, shard_size,\n",
    "                                            replace=False))\n",
    "            idx_shard = list(set(idx_shard) - rand_set)\n",
    "            for rand in rand_set:\n",
    "                ind1 = rand*num_imgs\n",
    "                ind2 = (rand+1)*num_imgs\n",
    "                if(len(dict_users[k]) == 0):\n",
    "                    dict_users[k] = data[ind1: ind2]\n",
    "                else:\n",
    "                    dict_users[k] = np.concatenate(\n",
    "                    (dict_users[k],data[ind1: ind2]),\n",
    "                    axis=0)\n",
    "                selected_inds.extend([[ind1, ind2]])\n",
    "                \n",
    "                \n",
    "    return dict_users, selected_inds, data_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cdec0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_users = {i: np.array([]) for i in range(4)}\n",
    "\n",
    "def create_client_iid(image_list, label_list, client_num):    \n",
    "    max_y = np.argmax(label_list, axis=-1)\n",
    "    sorted_zip = sorted(zip(max_y, label_list, image_list), key=lambda x: x[0])\n",
    "    data = [(x,y) for _,y,x in sorted_zip]\n",
    "    \n",
    "    dict_users[client_num] = data\n",
    "    \n",
    "    return dict_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdd4dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hetero_clients():\n",
    "    \n",
    "    female_features =  feature_set1[feature_set1['gender_Female']==1]\n",
    "    x_female = female_features[cols].copy().values\n",
    "    y_female = female_features[['income']].copy().values\n",
    "\n",
    "    X_train_female = sc.fit_transform(x_female)\n",
    "    y_train_female = y_female\n",
    "\n",
    "    male_features = feature_set1[feature_set1['gender_Male']==1] \n",
    "    x_male = male_features[cols].copy().values\n",
    "    y_male = male_features[['income']].copy().values\n",
    "\n",
    "    X_train_male = sc.fit_transform(x_male)\n",
    "    y_train_male = y_male\n",
    "\n",
    "    # test\n",
    "\n",
    "    female_features2 =  feature_set2[feature_set2['gender_Female']==1]\n",
    "    x_female2 = female_features2[cols].copy().values\n",
    "    y_female2 = female_features2[['income']].copy().values\n",
    "\n",
    "    X_test_female = sc.fit_transform(x_female2)\n",
    "    y_test_female = y_female2 \n",
    "\n",
    "    male_features2 = feature_set2[feature_set2['gender_Male']==1] \n",
    "    x_male2 = male_features2[cols].copy().values\n",
    "    y_male2 = male_features2[['income']].copy().values\n",
    "\n",
    "    X_test_male = sc.fit_transform(x_male2)\n",
    "    y_test_male = y_male2\n",
    "\n",
    "#     shuffling male and female datalists\n",
    "#     print(X_train_male.shape)\n",
    "    data = list(zip(X_train_male, y_train_male))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    X_train_male, y_train_male = list(zip(*data))[0], list(zip(*data))[1]\n",
    "    data.clear()\n",
    "    \n",
    "    data = list(zip(X_train_female, y_train_female))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    X_train_female, y_train_female = list(zip(*data))[0], list(zip(*data))[1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 1 all male\n",
    "    clients, inds, data_out1 = create_hetero_clients(X_train_male[:5230], y_train_male[:5230], start_client = 0, num_clients=1, initial='client') \n",
    "    # 1 all female\n",
    "    clients2, inds2, data_out2 = create_hetero_clients(X_train_female[:2584], y_train_female[:2584], start_client = 1, num_clients=2, initial='client')\n",
    "    clients = {**clients, **clients2}\n",
    "\n",
    "    used_x = []\n",
    "    used_y = []\n",
    "    used_data = []\n",
    "  \n",
    "    for i,j in list(inds):\n",
    "        for x in range(i,j):\n",
    "            used_data.insert(len(used_data)-1,(data_out1[x]))  \n",
    "  \n",
    "    for x in used_data:\n",
    "        used_x.insert(len(used_x)-1,x[0])\n",
    "        used_y.insert(len(used_y)-1,x[1])  \n",
    "   \n",
    "    used_data.clear()\n",
    "\n",
    "    for i,j in list(inds2):\n",
    "        for x in range(i,j):\n",
    "            used_data.insert(len(used_data)-1,(data_out2[x]))  \n",
    "\n",
    "    for x in used_data:\n",
    "        used_x.insert(len(used_x)-1,x[0])\n",
    "        used_y.insert(len(used_y)-1,x[1])  \n",
    "\n",
    "    # 3 mix\n",
    "    X_train_mix = np.setdiff1d(X_train, np.array(used_x))#53834, 64278\n",
    "    y_train_mix = np.setdiff1d(y_train, np.array(used_y))\n",
    "\n",
    "#     print(X_train_mix.shape, X_train.shape)\n",
    "#     print(y_train_mix.shape, y_train.shape)\n",
    "\n",
    "    clients3, inds3 , data_out= create_hetero_clients(X_train_mix, y_train_mix, start_client = 2, num_clients=5, initial='client')\n",
    "    clients = {**clients, **clients3}\n",
    "    \n",
    "    return clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e891872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializer():\n",
    "    \n",
    "    female_features =  feature_set1[feature_set1['gender_Female']==1]\n",
    "    x_female = female_features[cols].copy().values\n",
    "    y_female = female_features[['income']].copy().values\n",
    "\n",
    "    X_train_female = sc.fit_transform(x_female)\n",
    "    y_train_female = y_female\n",
    "\n",
    "    male_features = feature_set1[feature_set1['gender_Male']==1] \n",
    "    x_male = male_features[cols].copy().values\n",
    "    y_male = male_features[['income']].copy().values\n",
    "\n",
    "    X_train_male = sc.fit_transform(x_male)\n",
    "    y_train_male = y_male\n",
    "\n",
    "    # test\n",
    "\n",
    "    female_features2 =  feature_set2[feature_set2['gender_Female']==1]\n",
    "    x_female2 = female_features2[cols].copy().values\n",
    "    y_female2 = female_features2[['income']].copy().values\n",
    "\n",
    "    X_test_female = sc.fit_transform(x_female2)\n",
    "    y_test_female = y_female2 \n",
    "\n",
    "    male_features2 = feature_set2[feature_set2['gender_Male']==1] \n",
    "    x_male2 = male_features2[cols].copy().values\n",
    "    y_male2 = male_features2[['income']].copy().values\n",
    "\n",
    "    X_test_male = sc.fit_transform(x_male2)\n",
    "    y_test_male = y_male2\n",
    "    \n",
    "#   train-- with age\n",
    "    female_features_above30 = female_features[female_features['age']>30]\n",
    "    x_female_age = female_features_above30[cols].copy().values\n",
    "    y_female_age = female_features_above30[['income']].copy().values\n",
    "\n",
    "    X_train_female_age = sc.fit_transform(x_female_age)\n",
    "    y_train_female_age = y_female_age\n",
    "\n",
    "    male_features_above30 = male_features[male_features['age']>30]\n",
    "    x_male_age = male_features_above30[cols].copy().values\n",
    "    y_male_age = male_features_above30[['income']].copy().values\n",
    "\n",
    "    X_train_male_age = sc.fit_transform(x_male_age)\n",
    "    y_train_male_age = y_male_age\n",
    "\n",
    "    # test\n",
    "\n",
    "    female_features_above30_2 =  female_features2[female_features2['age']>30]\n",
    "    x_female_age2 = female_features_above30_2[cols].copy().values\n",
    "    y_female_age2 = female_features_above30_2[['income']].copy().values\n",
    "\n",
    "    X_test_female_age = sc.fit_transform(x_female_age2)\n",
    "    y_test_female_age = y_female_age2 \n",
    "\n",
    "    male_features_above30_2 = male_features2[male_features2['age']>30]\n",
    "    x_male_age2 = male_features_above30_2[cols].copy().values\n",
    "    y_male_age2 = male_features_above30_2[['income']].copy().values\n",
    "\n",
    "    X_test_male_age = sc.fit_transform(x_male_age2)\n",
    "    y_test_male_age = y_male_age2\n",
    "    \n",
    "    return X_train_male_age, y_train_male_age,  X_train_female_age, y_train_female_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb1235d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializer_income():\n",
    "    \n",
    "    female_features =  feature_set1[feature_set1['gender_Female']==1]\n",
    "    female_features_above30 = female_features[female_features['income']==1]\n",
    "    x_female_age = female_features_above30[cols].copy().values\n",
    "    y_female_age = female_features_above30[['income']].copy().values\n",
    "    \n",
    "    female_features_below = female_features[female_features['income']==0]\n",
    "    x_female_less = female_features_below[cols].copy().values\n",
    "    y_female_less = female_features_below[['income']].copy().values\n",
    "\n",
    "    X_train_female_age = sc.fit_transform(x_female_age)\n",
    "    y_train_female_age = y_female_age\n",
    "    \n",
    "    X_train_female_less = sc.fit_transform(x_female_less)\n",
    "    y_train_female_less = y_female_less\n",
    "\n",
    "\n",
    "    male_features = feature_set1[feature_set1['gender_Male']==1] \n",
    "    male_features_above30 = male_features[male_features['income']==1]\n",
    "    x_male_age = male_features_above30[cols].copy().values\n",
    "    y_male_age = male_features_above30[['income']].copy().values\n",
    "    \n",
    "    male_features_below = male_features[male_features['income']==0]\n",
    "    x_male_less = male_features_below[cols].copy().values\n",
    "    y_male_less = male_features_below[['income']].copy().values\n",
    "\n",
    "    X_train_male_age = sc.fit_transform(x_male_age)\n",
    "    y_train_male_age = y_male_age\n",
    "    \n",
    "    X_train_male_less = sc.fit_transform(x_male_less)\n",
    "    y_train_male_less = y_male_less\n",
    "\n",
    "\n",
    "    # test\n",
    "\n",
    "    female_features2 =  feature_set2[feature_set2['gender_Female']==1]\n",
    "    female_features_above30_2 =  female_features2[female_features2['income']==1]\n",
    "    x_female_age2 = female_features_above30_2[cols].copy().values\n",
    "    y_female_age2 = female_features_above30_2[['income']].copy().values\n",
    "\n",
    "    X_test_female_age = sc.fit_transform(x_female_age2)\n",
    "    y_test_female_age = y_female_age2 \n",
    "\n",
    "\n",
    "    male_features2 = feature_set2[feature_set2['gender_Male']==1]\n",
    "    male_features_above30_2 = male_features2[male_features2['income']==1]\n",
    "    x_male_age2 = male_features_above30_2[cols].copy().values\n",
    "    y_male_age2 = male_features_above30_2[['income']].copy().values\n",
    "\n",
    "    X_test_male_age = sc.fit_transform(x_male_age2)\n",
    "    y_test_male_age = y_male_age2\n",
    "\n",
    "    \n",
    "    return [X_train_male_age, y_train_male_age,  X_train_female_age, y_train_female_age, X_train_male_less, y_train_male_less,  X_train_female_less, y_train_female_less]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4278841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hetero_clients_gender(train_sets):\n",
    "    \n",
    "    data = list(zip(train_sets[0], train_sets[1]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "#     print(type(train_sets), type(train_sets[0]),type(list(list(zip(*data))[0]) ), type(data))\n",
    "    \n",
    "    train_sets[0] = list(list(zip(*data))[0])\n",
    "    train_sets[1] = list(list(zip(*data))[1])\n",
    "    data.clear()\n",
    "    \n",
    "    data = list(zip(train_sets[2], train_sets[3]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    train_sets[2], train_sets[3] = list(zip(*data))[0], list(zip(*data))[1]\n",
    "    data.clear()\n",
    "    \n",
    "    data = list(zip(train_sets[4], train_sets[5]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    train_sets[4], train_sets[5] = list(zip(*data))[0], list(zip(*data))[1]\n",
    "    data.clear()\n",
    "    \n",
    "    data = list(zip(train_sets[6], train_sets[7]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    train_sets[6], train_sets[7] = list(zip(*data))[0], list(zip(*data))[1]\n",
    "    \n",
    "#     NON_IID\n",
    "#     clients, inds, data_out1 = create_hetero_clients(train_sets[0], train_sets[1], start_client = 0, num_clients=1, initial='client') \n",
    "    \n",
    "#     clients2, inds2, data_out2 = create_hetero_clients(train_sets[2], train_sets[3], start_client = 1, num_clients=2, initial='client')\n",
    "#     clients = {**clients, **clients2}\n",
    "    \n",
    "#     clients3, inds3, data_out3 = create_hetero_clients(train_sets[4], train_sets[5], start_client = 2, num_clients=3, initial='client')\n",
    "#     clients = {**clients, **clients3}\n",
    "    \n",
    "#     clients4, inds4, data_out4 = create_hetero_clients(train_sets[6], train_sets[7], start_client = 3, num_clients=4, initial='client')\n",
    "#     clients = {**clients, **clients4}\n",
    "\n",
    "#     IID\n",
    "    clients = create_client_iid(train_sets[0], train_sets[1], 0)\n",
    "    \n",
    "    clients2 = create_client_iid(train_sets[2], train_sets[3], 1)\n",
    "    clients = {**clients, **clients2}\n",
    "    \n",
    "    clients3 = create_client_iid(train_sets[4], train_sets[5], 2)\n",
    "    clients = {**clients, **clients3}\n",
    "    \n",
    "    clients4 = create_client_iid(train_sets[6], train_sets[7], 3)\n",
    "    clients = {**clients, **clients4}\n",
    "    \n",
    "    \n",
    "#     ________________________________________________________\n",
    "#     used_x = []\n",
    "#     used_y = []\n",
    "#     used_data = []\n",
    "  \n",
    "#     for i,j in list(inds):\n",
    "#         for x in range(i,j):\n",
    "#             used_data.insert(len(used_data)-1,(data_out1[x]))  \n",
    "  \n",
    "#     for x in used_data:\n",
    "#         used_x.insert(len(used_x)-1,x[0])\n",
    "#         used_y.insert(len(used_y)-1,x[1])  \n",
    "   \n",
    "#     used_data.clear()\n",
    "\n",
    "#     for i,j in list(inds2):\n",
    "#         for x in range(i,j):\n",
    "#             used_data.insert(len(used_data)-1,(data_out2[x]))  \n",
    "\n",
    "#     for x in used_data:\n",
    "#         used_x.insert(len(used_x)-1,x[0])\n",
    "#         used_y.insert(len(used_y)-1,x[1])  \n",
    "\n",
    "#     # 3 mix\n",
    "#     X_train_mix = np.setdiff1d(X_train, np.array(used_x))#53834, 64278\n",
    "#     y_train_mix = np.setdiff1d(y_train, np.array(used_y))\n",
    "\n",
    "#     print(X_train_mix.shape, X_train.shape)\n",
    "#     print(type(X_train_mix), type(X_train))\n",
    "#     print(type(data_out))\n",
    "#     print(y_train_mix.shape, y_train.shape)\n",
    "\n",
    "#     clients3, inds3 , data_out= create_hetero_clients(X_train, y_train, start_client = 2, num_clients=5, initial='client')\n",
    "#     clients = {**clients, **clients3}\n",
    "    \n",
    "    return clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa04e453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializer_income_race_gender():\n",
    "    \n",
    "    female_features =  feature_set1[feature_set1['gender_Female']==1]\n",
    "    female_features_above50 = female_features[female_features['income']==1]\n",
    "    female_features_above50_white = female_features_above50[female_features_above50['race_White']==1]\n",
    "    female_features_above50_black = female_features_above50[female_features_above50['race_Black']==1]\n",
    "    \n",
    "#     white, female, >50k\n",
    "    x_female_white_more = female_features_above50_white[cols].copy().values\n",
    "    y_female_white_more = female_features_above50_white[['income']].copy().values\n",
    "    X_train_female_white_more = sc.fit_transform(x_female_white_more)\n",
    "    y_train_female_white_more = y_female_white_more\n",
    "    \n",
    "#     black, female, >50k\n",
    "    x_female_black_more = female_features_above50_black[cols].copy().values\n",
    "    y_female_black_more = female_features_above50_black[['income']].copy().values\n",
    "    X_train_female_black_more = sc.fit_transform(x_female_black_more)\n",
    "    y_train_female_black_more = y_female_black_more\n",
    "    \n",
    "    female_features_below = female_features[female_features['income']==0]\n",
    "    female_features_below_white = female_features_below[female_features_below['race_White']==1]\n",
    "    female_features_below_black = female_features_below[female_features_below['race_Black']==1]\n",
    "    \n",
    "#    white, female, <=50k\n",
    "    x_female_white_less = female_features_below_white[cols].copy().values\n",
    "    y_female_white_less = female_features_below_white[['income']].copy().values\n",
    "    X_train_female_white_less = sc.fit_transform(x_female_white_less)\n",
    "    y_train_female_white_less = y_female_white_less\n",
    "    \n",
    "#    black, female, <=50k\n",
    "    x_female_black_less = female_features_below_black[cols].copy().values\n",
    "    y_female_black_less = female_features_below_black[['income']].copy().values\n",
    "    X_train_female_black_less = sc.fit_transform(x_female_black_less)\n",
    "    y_train_female_black_less = y_female_black_less\n",
    "    \n",
    "\n",
    "\n",
    "    male_features = feature_set1[feature_set1['gender_Male']==1] \n",
    "    male_features_above50 = male_features[male_features['income']==1]\n",
    "    male_features_above50_white = male_features_above50[male_features_above50['race_White']==1]\n",
    "    male_features_above50_black = male_features_above50[male_features_above50['race_Black']==1]\n",
    "    \n",
    "#     white, male, >50k\n",
    "    x_male_white_more = male_features_above50_white[cols].copy().values\n",
    "    y_male_white_more = male_features_above50_white[['income']].copy().values\n",
    "    X_train_male_white_more = sc.fit_transform(x_male_white_more)\n",
    "    y_train_male_white_more = y_male_white_more\n",
    "    \n",
    "#     black, male, >50k\n",
    "    x_male_black_more = male_features_above50_black[cols].copy().values\n",
    "    y_male_black_more = male_features_above50_black[['income']].copy().values\n",
    "    X_train_male_black_more = sc.fit_transform(x_male_black_more)\n",
    "    y_train_male_black_more = y_male_black_more\n",
    "    \n",
    "    male_features_below = male_features[male_features['income']==0]\n",
    "    male_features_below_white = male_features_below[male_features_below['race_White']==1]\n",
    "    male_features_below_black = male_features_below[male_features_below['race_Black']==1]\n",
    "    \n",
    "#    white, male, <=50k\n",
    "    x_male_white_less = male_features_below_white[cols].copy().values\n",
    "    y_male_white_less = male_features_below_white[['income']].copy().values\n",
    "    X_train_male_white_less = sc.fit_transform(x_male_white_less)\n",
    "    y_train_male_white_less = y_male_white_less\n",
    "    \n",
    "#    black, male, <=50k\n",
    "    x_male_black_less = male_features_below_black[cols].copy().values\n",
    "    y_male_black_less = male_features_below_black[['income']].copy().values\n",
    "    X_train_male_black_less = sc.fit_transform(x_male_black_less)\n",
    "    y_train_male_black_less = y_male_black_less\n",
    "    \n",
    "#     print(\"fwm: \", X_train_female_white_more.shape, y_train_female_white_more.shape,\n",
    "#           \"fbm: \", X_train_female_black_more.shape, y_train_female_black_more.shape, \n",
    "#             \"fwl: \", X_train_female_white_less.shape, y_train_female_white_less.shape, \n",
    "#             \"fbl: \", X_train_female_black_less.shape,  y_train_female_black_less.shape,\n",
    "#             \"mwm: \", X_train_male_white_more.shape, y_train_male_white_more.shape,\n",
    "#             \"mbm: \", X_train_male_black_more.shape, y_train_male_black_more.shape,\n",
    "#             \"mwl: \", X_train_male_white_less.shape, y_train_male_white_less.shape,\n",
    "#             \"mbl: \", X_train_male_black_less.shape, y_train_male_black_less.shape)\n",
    "\n",
    "    \n",
    "    return [X_train_female_white_more, y_train_female_white_more, \n",
    "            X_train_female_black_more, y_train_female_black_more, \n",
    "            X_train_female_white_less, y_train_female_white_less, \n",
    "            X_train_female_black_less, y_train_female_black_less,\n",
    "            X_train_male_white_more, y_train_male_white_more,\n",
    "            X_train_male_black_more, y_train_male_black_more,\n",
    "            X_train_male_white_less, y_train_male_white_less,\n",
    "            X_train_male_black_less, y_train_male_black_less]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9784339c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.63527959,  1.82817485, -0.71117516, ...,  0.24181517,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.96356361, -1.04308228,  0.18764645, ...,  0.24181517,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.30410003,  1.82817485,  0.07554836, ...,  0.24181517,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.28929067,  0.62409928, -0.01914642, ...,  0.24181517,\n",
       "          0.        ,  0.        ],\n",
       "        [ 1.33253927,  2.01341724,  1.56784985, ...,  0.24181517,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.21293351,  2.47652323, -0.20536085, ...,  0.24181517,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]], dtype=int64),\n",
       " array([[-0.51750424,  0.48583798, -0.07896002, ...,  0.25131234,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.95890653,  0.59838302, -0.43961139, ...,  0.25131234,\n",
       "          0.        ,  0.        ],\n",
       "        [ 1.43146628,  1.72383338, -1.26538864, ...,  0.25131234,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [-0.00413418,  1.1611082 ,  0.10983161, ...,  0.25131234,\n",
       "          0.        ,  0.        ],\n",
       "        [-1.70493759,  0.03565783, -0.84209192, ...,  0.25131234,\n",
       "          0.        ,  0.        ],\n",
       "        [ 1.2392741 ,  0.03565783, -0.01260146, ...,  0.25131234,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]], dtype=int64),\n",
       " array([[ 1.03998496, -0.75476544, -0.03990554, ...,  0.28463561,\n",
       "         -0.01043764, -0.01476186],\n",
       "        [ 0.40887646, -0.95838243,  0.03957433, ...,  0.28463561,\n",
       "         -0.01043764, -0.01476186],\n",
       "        [-0.14068391, -0.68689311,  0.44037212, ...,  0.28463561,\n",
       "         -0.01043764, -0.01476186],\n",
       "        ...,\n",
       "        [-1.16508779, -1.02625476,  0.27492001, ...,  0.28463561,\n",
       "         -0.01043764, -0.01476186],\n",
       "        [ 1.20372165, -1.22987174,  0.06349097, ...,  0.28463561,\n",
       "         -0.01043764, -0.01476186],\n",
       "        [ 0.11150331, -1.29774407, -0.25819036, ...,  0.28463561,\n",
       "         -0.01043764, -0.01476186]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]], dtype=int64),\n",
       " array([[ 0.43522858,  0.17354279, -0.15565516, ...,  0.29138576,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.38464995,  0.02181379,  1.31766811, ...,  0.29138576,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.19276112, -1.04028917,  0.29680757, ...,  0.29138576,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [-1.24647561, -0.05405071, -1.39245685, ...,  0.29138576,\n",
       "          0.        ,  0.        ],\n",
       "        [-1.53592907,  1.61496824,  0.07745244, ...,  0.29138576,\n",
       "          0.        ,  0.        ],\n",
       "        [ 1.29957368,  1.69083273, -0.19811496, ...,  0.29138576,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]], dtype=int64),\n",
       " array([[ 0.33644682, -1.59382874,  2.11595877, ...,  0.24439715,\n",
       "          0.        , -0.02883749],\n",
       "        [ 0.73691106,  0.87688019, -1.40786775, ...,  0.24439715,\n",
       "          0.        , -0.02883749],\n",
       "        [-0.50185643,  0.59179839, -0.34685994, ...,  0.24439715,\n",
       "          0.        , -0.02883749],\n",
       "        ...,\n",
       "        [ 0.62642101, -0.35847428,  0.17246861, ...,  0.24439715,\n",
       "          0.        , -0.02883749],\n",
       "        [-0.11190829, -0.07339248, -0.83267246, ...,  0.24439715,\n",
       "          0.        , -0.02883749],\n",
       "        [-0.14793301,  0.59179839,  1.48644749, ...,  0.24439715,\n",
       "          0.        , -0.02883749]]),\n",
       " array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]], dtype=int64),\n",
       " array([[ 1.57723652, -2.24138225, -0.24101057, ...,  0.32947326,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.87536326, -0.35871525,  1.20457728, ...,  0.32947326,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.29031602,  0.23581117,  1.06711994, ...,  0.32947326,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [-0.44704363, -1.05232941, -0.40722072, ...,  0.32947326,\n",
       "          0.        ,  0.        ],\n",
       "        [-1.39102278, -0.16053978, -0.64609335, ...,  0.32947326,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.98460797, -0.85415393, -0.14987942, ...,  0.32947326,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]], dtype=int64),\n",
       " array([[-1.35741425, -0.455085  , -0.28641469, ..., -3.17445095,\n",
       "         -0.00795683, -0.02639818],\n",
       "        [ 0.92646522, -1.45261017, -1.57259929, ...,  0.3150151 ,\n",
       "         -0.00795683, -0.02639818],\n",
       "        [ 0.62084072,  0.89869916,  0.41167357, ...,  0.3150151 ,\n",
       "         -0.00795683, -0.02639818],\n",
       "        ...,\n",
       "        [-1.46139471, -0.3838332 , -0.37440246, ...,  0.3150151 ,\n",
       "         -0.00795683, -0.02639818],\n",
       "        [-0.42109322,  1.89622433, -0.10205524, ...,  0.3150151 ,\n",
       "         -0.00795683, -0.02639818],\n",
       "        [ 0.23409017,  0.82744736,  0.03749696, ...,  0.3150151 ,\n",
       "         -0.00795683, -0.02639818]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]], dtype=int64),\n",
       " array([[ 0.27680715,  0.65505222,  0.54687701, ..., -2.91391645,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.81883069,  0.95863665,  1.20814312, ...,  0.34318074,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.26219969, -1.24235044, -1.54472843, ...,  0.34318074,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 1.16827662,  1.03453275, -0.24362311, ...,  0.34318074,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.80815196, -1.16645434,  0.56646168, ...,  0.34318074,\n",
       "          0.        ,  0.        ],\n",
       "        [-1.54240233, -0.17980495,  2.65274511, ...,  0.34318074,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]], dtype=int64)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializer_income_race_gender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f8d5607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hetero_clients_gender_race(train_sets):\n",
    "    data = list(zip(train_sets[0], train_sets[1]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "#     print(type(train_sets), type(train_sets[0]),type(list(list(zip(*data))[0]) ), type(data))\n",
    "    \n",
    "    train_sets[0] = list(list(zip(*data))[0])\n",
    "    train_sets[1] = list(list(zip(*data))[1])\n",
    "    data.clear()\n",
    "    \n",
    "    data = list(zip(train_sets[2], train_sets[3]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    train_sets[2], train_sets[3] = list(zip(*data))[0], list(zip(*data))[1]\n",
    "    data.clear()\n",
    "    data = list(zip(train_sets[4], train_sets[5]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    train_sets[4], train_sets[5] = list(zip(*data))[0], list(zip(*data))[1]\n",
    "    data.clear()\n",
    "    \n",
    "    data = list(zip(train_sets[6], train_sets[7]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    train_sets[6], train_sets[7] = list(zip(*data))[0], list(zip(*data))[1]\n",
    "    data.clear()\n",
    "    \n",
    "    data = list(zip(train_sets[8], train_sets[9]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    train_sets[8], train_sets[9] = list(zip(*data))[0], list(zip(*data))[1]\n",
    "    data.clear()\n",
    "    \n",
    "    data = list(zip(train_sets[10], train_sets[11]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    train_sets[10], train_sets[11] = list(zip(*data))[0], list(zip(*data))[1]\n",
    "    \n",
    "    data = list(zip(train_sets[12], train_sets[13]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    train_sets[14], train_sets[15] = list(zip(*data))[0], list(zip(*data))[1]\n",
    "    data.clear()\n",
    "    \n",
    "    data = list(zip(train_sets[14], train_sets[15]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    train_sets[14], train_sets[15] = list(zip(*data))[0], list(zip(*data))[1]\n",
    "    \n",
    "#     for i in range(7):\n",
    "\n",
    "#         data = list(zip(train_sets[i], train_sets[i+1]))\n",
    "#         random.shuffle(data)\n",
    "\n",
    "# #         print(type(train_sets), type(train_sets[0]),type(list(list(zip(*data))[0]) ), type(data))\n",
    "\n",
    "#         train_sets[i], train_sets[i+1] = list(zip(*data))[0], list(zip(*data))[1]\n",
    "#         data.clear()\n",
    "    \n",
    "    # 1 all male\n",
    "    clients, inds, data_out1 = create_hetero_clients(train_sets[0], train_sets[1], start_client = 0, num_clients=1, initial='client') \n",
    "    # 1 all female\n",
    "    clients2, inds2, data_out2 = create_hetero_clients(train_sets[2], train_sets[3], start_client = 1, num_clients=2, initial='client')\n",
    "    clients = {**clients, **clients2}\n",
    "    \n",
    "    clients3, inds3, data_out3 = create_hetero_clients(train_sets[4], train_sets[5], start_client = 2, num_clients=3, initial='client')\n",
    "    clients = {**clients, **clients3}\n",
    "    \n",
    "    clients4, inds4, data_out4 = create_hetero_clients(train_sets[6], train_sets[7], start_client = 3, num_clients=4, initial='client')\n",
    "    clients = {**clients, **clients4}\n",
    "    \n",
    "    clients5, inds5, data_out5 = create_hetero_clients(train_sets[2], train_sets[3], start_client = 4, num_clients=5, initial='client')\n",
    "    clients = {**clients, **clients5}\n",
    "    \n",
    "    clients6, inds6, data_out6 = create_hetero_clients(train_sets[4], train_sets[5], start_client = 5, num_clients=6, initial='client')\n",
    "    clients = {**clients, **clients6}\n",
    "    \n",
    "    clients7, inds7, data_out7 = create_hetero_clients(train_sets[6], train_sets[7], start_client = 6, num_clients=7, initial='client')\n",
    "    clients = {**clients, **clients7}\n",
    "    \n",
    "    clients8, inds8, data_out8 = create_hetero_clients(train_sets[6], train_sets[7], start_client = 7, num_clients= 8, initial='client')\n",
    "    clients = {**clients, **clients8}\n",
    "    \n",
    "    return clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "715ed657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:52.579114Z",
     "start_time": "2021-07-15T23:59:52.576244Z"
    }
   },
   "outputs": [],
   "source": [
    "# take bs = 128 for 5 clients and 10 rounds\n",
    "def batch_data(data_shard, bs=64):\n",
    "    '''Takes in a clients data shard and create a tfds object off it\n",
    "    args:\n",
    "        shard: a data, label constituting a client's data shard\n",
    "        bs:batch size\n",
    "    return:\n",
    "        tfds object'''\n",
    "    data = []\n",
    "    label = []\n",
    "    for x in data_shard:\n",
    "        data.append(x[0])\n",
    "        label.append(x[1])\n",
    "    #seperate shard into data and labels lists\n",
    "#     data, label = zip(*data_shard)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
    "#     print( label[0])\n",
    "    return dataset.shuffle(len(label)).batch(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dfd80728",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:54.563066Z",
     "start_time": "2021-07-15T23:59:52.773340Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#process and batch the training data for each client\n",
    "def batch_clients(clients):\n",
    "    clients_batched = dict()\n",
    "    for (client_name, data) in clients.items():\n",
    "#         print(\"data \",len(data))\n",
    "#         clients_batched[client_name] = batch_data(data)#non-IID\n",
    "        clients_batched[client_name] = batch_data(data,1) #IID\n",
    "    \n",
    "\n",
    "    #process and batch the test set  \n",
    "    test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))\n",
    "    \n",
    "#     test_batched\n",
    "    return clients_batched, test_batched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f54f92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client batched 0:  7895\n",
      "test (9768, 94)\n",
      "(7895, 94)\n",
      "(7895, 1)\n",
      "(1435, 94)\n",
      "(1435, 1)\n",
      "(18259, 94)\n",
      "(18259, 1)\n",
      "(11484, 94)\n",
      "(11484, 1)\n",
      "0   7895\n",
      "1   1435\n",
      "2   18259\n",
      "3   11484\n"
     ]
    }
   ],
   "source": [
    "clients = get_hetero_clients_gender(list(train_sets) )\n",
    "# print(\"client0: \", clients[0])\n",
    "\n",
    "clients_batched, test_batched = batch_clients(clients)\n",
    "print(\"client batched 0: \", len(clients_batched[0]))\n",
    "print(\"test\" ,X_test.shape)\n",
    "train_list = initializer_income()\n",
    "for i in train_list:\n",
    "    print(i.shape)\n",
    "    \n",
    "client_names= list(clients_batched.keys())\n",
    "\n",
    "for client in client_names:\n",
    "    print(client,\" \", len(clients_batched[client]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9dcf2ff7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:54.568193Z",
     "start_time": "2021-07-15T23:59:54.564443Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleMLP:\n",
    "    @staticmethod\n",
    "    def build(shape, classes=2 , learning_rate = 0.001, metric = \"accuracy\"):\n",
    "\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128, input_shape = (shape,)))\n",
    "#         model.add(Dense(128, Activation(\"relu\")))\n",
    "#         model.add(Dense(64, Activation(\"relu\")))\n",
    "#         model.add(Dense(32, Activation(\"relu\")))\n",
    "#         model.add(Dense(1))\n",
    "        \n",
    "        model.add(Dense(128, Activation(\"tanh\")))\n",
    "        model.add(Dense(64, Activation(\"tanh\")))\n",
    "        model.add(Dense(32, Activation(\"tanh\")))\n",
    "        model.add(Dense(1,Activation('sigmoid')))\n",
    "        \n",
    "\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f71dc14a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:00:30.156165Z",
     "start_time": "2021-07-16T00:00:30.152576Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.005\n",
    "comms_round = 10\n",
    "loss=tf.keras.losses.BinaryCrossentropy(from_logits = False)\n",
    "\n",
    "metrics = ['binary_accuracy']\n",
    "\n",
    "optimizer = SGD(learning_rate=lr, \n",
    "                decay=lr / comms_round, \n",
    "                momentum=0.5\n",
    "               )     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eebf9376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:00:30.412962Z",
     "start_time": "2021-07-16T00:00:30.399142Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def weight_scalling_factor(clients_trn_data, client_name):\n",
    "    client_names = list(clients_trn_data.keys())\n",
    "    #get the bs\n",
    "    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
    "    #first calculate the total training data points across clinets\n",
    "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n",
    "    # get the total number of data points held by a client\n",
    "    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n",
    "    return local_count/global_count\n",
    "\n",
    "\n",
    "def scale_model_weights(weight, scalar):\n",
    "    '''function for scaling a models weights'''\n",
    "    weight_final = []\n",
    "    steps = len(weight)\n",
    "    for i in range(steps):\n",
    "        weight_final.append(scalar * weight[i])\n",
    "    return weight_final\n",
    "\n",
    "\n",
    "\n",
    "def sum_scaled_weights(scaled_weight_list):\n",
    "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
    "    avg_grad = list()\n",
    "    #get the average grad accross all client gradients\n",
    "#     print(len(scaled_weight_list))\n",
    "    for grad_list_tuple in zip(*scaled_weight_list):\n",
    "#         print(len(grad_list_tuple))\n",
    "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
    "        avg_grad.append(layer_mean)\n",
    "        \n",
    "    return avg_grad\n",
    "\n",
    "\n",
    "def test_model(X_test, Y_test,  model, comm_round):\n",
    "    \n",
    "#     cce = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "#     cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    logits = model.predict(X_test)\n",
    "\n",
    "    score = global_model.evaluate(X_test, y_test, verbose=0)\n",
    "    acc = score[1] ; loss = score[0]\n",
    "    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n",
    "\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4aef41d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:01:47.756094Z",
     "start_time": "2021-07-16T00:00:30.586083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client0:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client batched 0:  <BatchDataset shapes: ((None, 94), (None, 1)), types: (tf.float64, tf.int32)>\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.4985 - binary_accuracy: 0.8172\n",
      "client 3 loss --> [0.4984782636165619] freq-> [180] accuracy-> [0.8172239661216736]\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.7036 - binary_accuracy: 0.5143\n",
      "client 1 loss --> [0.7035624980926514] freq-> [23] accuracy-> [0.5142857432365417]\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4256 - binary_accuracy: 0.8730\n",
      "client 2 loss --> [0.4256325364112854] freq-> [286] accuracy-> [0.8730489015579224]\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 0.5636 - binary_accuracy: 0.7672\n",
      "client 0 loss --> [0.5636196136474609] freq-> [124] accuracy-> [0.7671944499015808]\n",
      "comm_round: 0 | global_acc: 72.840% | global_loss: 0.5900071263313293\n",
      "global_loss_list:  [0.5900071263313293]\n",
      "global_acc_list:  [0.728398859500885]\n",
      "global_freq_list:  [613]\n",
      "client0:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client batched 0:  <BatchDataset shapes: ((None, 94), (None, 1)), types: (tf.float64, tf.int32)>\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.0825 - binary_accuracy: 0.0857\n",
      "client 1 loss --> [0.7035625  1.08253276] freq-> [23 23] accuracy-> [0.51428574 0.08571429]\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.2641 - binary_accuracy: 0.9814\n",
      "client 2 loss --> [0.42563254 0.26406497] freq-> [286 286] accuracy-> [0.8730489  0.98143381]\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.3080 - binary_accuracy: 0.9755\n",
      "client 3 loss --> [0.49847826 0.30796084] freq-> [180 180] accuracy-> [0.81722397 0.97553116]\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 0.8402 - binary_accuracy: 0.3515\n",
      "client 0 loss --> [0.56361961 0.84024435] freq-> [124 124] accuracy-> [0.76719445 0.35148829]\n",
      "comm_round: 1 | global_acc: 75.072% | global_loss: 0.5668806433677673\n",
      "global_loss_list:  [0.5900071263313293, 0.5668806433677673]\n",
      "global_acc_list:  [0.728398859500885, 0.7507166266441345]\n",
      "global_freq_list:  [613, 613]\n",
      "client0:  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m     clients \u001b[38;5;241m=\u001b[39m get_hetero_clients_gender(\u001b[38;5;28mlist\u001b[39m(train_sets) )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#     clients = get_hetero_clients_gender_race(list(train_sets) )\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclient0: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclients\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     clients_batched, test_batched \u001b[38;5;241m=\u001b[39m batch_clients(clients)\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient batched 0: \u001b[39m\u001b[38;5;124m\"\u001b[39m, clients_batched[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\arrayprint.py:1488\u001b[0m, in \u001b[0;36m_array_repr_implementation\u001b[1;34m(arr, max_line_width, precision, suppress_small, array2string)\u001b[0m\n\u001b[0;32m   1486\u001b[0m     lst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrepr\u001b[39m(arr\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (\u001b[38;5;241m0\u001b[39m,):\n\u001b[1;32m-> 1488\u001b[0m     lst \u001b[38;5;241m=\u001b[39m \u001b[43marray2string\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_line_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuppress_small\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# show zero-length shape unless it is (0,)\u001b[39;00m\n\u001b[0;32m   1491\u001b[0m     lst \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[], shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mrepr\u001b[39m(arr\u001b[38;5;241m.\u001b[39mshape),)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\arrayprint.py:736\u001b[0m, in \u001b[0;36marray2string\u001b[1;34m(a, max_line_width, precision, suppress_small, separator, prefix, style, formatter, threshold, edgeitems, sign, floatmode, suffix, legacy)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 736\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array2string\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseparator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\arrayprint.py:513\u001b[0m, in \u001b[0;36m_recursive_guard.<locals>.decorating_function.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    511\u001b[0m repr_running\u001b[38;5;241m.\u001b[39madd(key)\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    515\u001b[0m     repr_running\u001b[38;5;241m.\u001b[39mdiscard(key)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\arrayprint.py:539\u001b[0m, in \u001b[0;36m_array2string\u001b[1;34m(a, options, separator, prefix)\u001b[0m\n\u001b[0;32m    536\u001b[0m     summary_insert \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;66;03m# find the right formatting function for the array\u001b[39;00m\n\u001b[1;32m--> 539\u001b[0m format_function \u001b[38;5;241m=\u001b[39m \u001b[43m_get_format_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;66;03m# skip over \"[\"\u001b[39;00m\n\u001b[0;32m    542\u001b[0m next_line_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\arrayprint.py:472\u001b[0m, in \u001b[0;36m_get_format_function\u001b[1;34m(data, **options)\u001b[0m\n\u001b[0;32m    470\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m formatdict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongfloat\u001b[39m\u001b[38;5;124m'\u001b[39m]()\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 472\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatdict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(dtypeobj, _nt\u001b[38;5;241m.\u001b[39mcomplexfloating):\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(dtypeobj, _nt\u001b[38;5;241m.\u001b[39mclongfloat):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\arrayprint.py:411\u001b[0m, in \u001b[0;36m_get_formatdict.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_formatdict\u001b[39m(data, \u001b[38;5;241m*\u001b[39m, precision, floatmode, suppress, sign, legacy,\n\u001b[0;32m    404\u001b[0m                     formatter, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# note: extra arguments in kwargs are ignored\u001b[39;00m\n\u001b[0;32m    406\u001b[0m \n\u001b[0;32m    407\u001b[0m     \u001b[38;5;66;03m# wrapped in lambdas to avoid taking a code path with the wrong type of data\u001b[39;00m\n\u001b[0;32m    408\u001b[0m     formatdict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: BoolFormat(data),\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: IntegerFormat(data),\n\u001b[1;32m--> 411\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mFloatingFormat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfloatmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuppress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msign\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlegacy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlegacy\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    413\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongfloat\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: FloatingFormat(\n\u001b[0;32m    414\u001b[0m             data, precision, floatmode, suppress, sign, legacy\u001b[38;5;241m=\u001b[39mlegacy),\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplexfloat\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: ComplexFloatingFormat(\n\u001b[0;32m    416\u001b[0m             data, precision, floatmode, suppress, sign, legacy\u001b[38;5;241m=\u001b[39mlegacy),\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongcomplexfloat\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: ComplexFloatingFormat(\n\u001b[0;32m    418\u001b[0m             data, precision, floatmode, suppress, sign, legacy\u001b[38;5;241m=\u001b[39mlegacy),\n\u001b[0;32m    419\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: DatetimeFormat(data, legacy\u001b[38;5;241m=\u001b[39mlegacy),\n\u001b[0;32m    420\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimedelta\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: TimedeltaFormat(data),\n\u001b[0;32m    421\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: _object_format,\n\u001b[0;32m    422\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvoid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: str_format,\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpystr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: repr_format}\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;66;03m# we need to wrap values in `formatter` in a lambda, so that the interface\u001b[39;00m\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;66;03m# is the same as the above values.\u001b[39;00m\n\u001b[0;32m    427\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mindirect\u001b[39m(x):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\arrayprint.py:932\u001b[0m, in \u001b[0;36mFloatingFormat.__init__\u001b[1;34m(self, data, precision, floatmode, suppress_small, sign, legacy)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexp_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlarge_exponent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 932\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillFormat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\arrayprint.py:989\u001b[0m, in \u001b[0;36mFloatingFormat.fillFormat\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    983\u001b[0m     trim, unique \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    984\u001b[0m strs \u001b[38;5;241m=\u001b[39m (dragon4_positional(x, precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision,\n\u001b[0;32m    985\u001b[0m                            fractional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    986\u001b[0m                            unique\u001b[38;5;241m=\u001b[39munique, trim\u001b[38;5;241m=\u001b[39mtrim,\n\u001b[0;32m    987\u001b[0m                            sign\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msign \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    988\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m finite_vals)\n\u001b[1;32m--> 989\u001b[0m int_part, frac_part \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstrs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_legacy \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m113\u001b[39m:\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(s\u001b[38;5;241m.\u001b[39mlstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-+\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m int_part)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\arrayprint.py:989\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    983\u001b[0m     trim, unique \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    984\u001b[0m strs \u001b[38;5;241m=\u001b[39m (dragon4_positional(x, precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision,\n\u001b[0;32m    985\u001b[0m                            fractional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    986\u001b[0m                            unique\u001b[38;5;241m=\u001b[39munique, trim\u001b[38;5;241m=\u001b[39mtrim,\n\u001b[0;32m    987\u001b[0m                            sign\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msign \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    988\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m finite_vals)\n\u001b[1;32m--> 989\u001b[0m int_part, frac_part \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strs))\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_legacy \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m113\u001b[39m:\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(s\u001b[38;5;241m.\u001b[39mlstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-+\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m int_part)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#initialize global model\n",
    "smlp_global = SimpleMLP()\n",
    "global_model = smlp_global.build(X_train.shape[1] ,classes=2)\n",
    "global_model.compile(optimizer=optimizer, loss=loss, metrics=metrics) \n",
    "# clients_batched, test_batched = batch_clients(clients)\n",
    "# client_names= list(clients_batched.keys())\n",
    "# client_names = [0, 1, 2, 3,4, 5, 6, 7, 8]\n",
    "client_names = [0, 1, 2, 3]\n",
    "# print(client_names, \"asugdefbh\")\n",
    "# print(clients_batched)\n",
    "global_loss_list = []\n",
    "global_freq_list = []\n",
    "global_acc_list = []\n",
    "client_loss = {i: np.array([]) for i in range(len(client_names))}\n",
    "client_accuracy = {i: np.array([]) for i in range(len(client_names))}\n",
    "client_frequency = {i: np.array([]) for i in range(len(client_names))}\n",
    "\n",
    "train_sets = initializer_income()\n",
    "# train_sets = initializer_income_race_gender()\n",
    "\n",
    "# print(len(train_sets))\n",
    "#commence global training loop\n",
    "for comm_round in range(comms_round):\n",
    "    epoch_freq = 0\n",
    "#     clients = create_clients(X_train, y_train, num_clients=15, initial='client')\n",
    "#     clients = get_hetero_clients()\n",
    "    clients = get_hetero_clients_gender(list(train_sets) )\n",
    "#     clients = get_hetero_clients_gender_race(list(train_sets) )\n",
    "    print(\"client0: \", clients[0])\n",
    "\n",
    "    clients_batched, test_batched = batch_clients(clients)\n",
    "    print(\"client batched 0: \", clients_batched[1])\n",
    "    # get the global model's weights - will serve as the initial weights for all local models\n",
    "    global_weights = global_model.get_weights()\n",
    "    \n",
    "    #initial list to collect local model weights after scalling\n",
    "    scaled_local_weight_list = list()\n",
    "\n",
    "    #randomize client data - using keys\n",
    "    client_names= list(clients_batched.keys())\n",
    "#     print(client_names)\n",
    "    random.shuffle(client_names)\n",
    "    \n",
    "    #loop through each client and create new local model\n",
    "    for client in client_names:\n",
    "        smlp_local = SimpleMLP()\n",
    "        local_model = smlp_local.build(X_train.shape[1],classes=2)\n",
    "        local_model.compile(loss=loss, \n",
    "                      optimizer=optimizer, \n",
    "                      metrics=metrics)\n",
    "        \n",
    "        #set local model weight to the weight of the global model\n",
    "        local_model.set_weights(global_weights)\n",
    "        \n",
    "        #fit local model with client's data\n",
    "        history = local_model.fit(clients_batched[client], epochs=1, verbose=1)\n",
    "        \n",
    "#         get client acc, loss\n",
    "#         print(client)\n",
    "        if(len(client_loss[client])== 0):\n",
    "            client_loss[client] = [history.history['loss'][0]]\n",
    "            client_accuracy[client] = [history.history['binary_accuracy'][0]]\n",
    "            client_frequency[client] = [len(clients_batched[client])]\n",
    "        \n",
    "        else:\n",
    "            client_loss[client] = np.append(client_loss[client], (history.history['loss'][0]))\n",
    "            client_frequency[client] = np.append(client_frequency[client], len(clients_batched[client]))\n",
    "            client_accuracy[client] = np.append(client_accuracy[client], (history.history['binary_accuracy'][0]))\n",
    "        \n",
    "        epoch_freq += len(clients_batched[client])\n",
    "        \n",
    "        print(\"client\", client, \"loss -->\" ,client_loss[client], \"freq->\", client_frequency[client], \"accuracy->\", client_accuracy[client])\n",
    "        \n",
    "        #scale the model weights and add to list\n",
    "        scaling_factor = weight_scalling_factor(clients_batched, client)\n",
    "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "        scaled_local_weight_list.append(scaled_weights)\n",
    "        \n",
    "        #clear session to free memory after each communication round\n",
    "        K.clear_session()\n",
    "        \n",
    "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "    \n",
    "    #update global model \n",
    "    global_model.set_weights(average_weights)\n",
    "    \n",
    "    global_freq_list.append(epoch_freq)\n",
    "    epoch_freq = 0\n",
    "    \n",
    "\n",
    "#     test global model and print out metrics after each communications round\n",
    "    for(X_test, Y_test) in test_batched:\n",
    "        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)\n",
    "        global_loss_list.append(global_loss)\n",
    "        global_acc_list.append(global_acc)\n",
    "        \n",
    "        print(\"global_loss_list: \", global_loss_list )\n",
    "        print(\"global_acc_list: \", global_acc_list )\n",
    "        print(\"global_freq_list: \", global_freq_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2208b3c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_ 0  loss:  [0.31740108 0.62890333 0.68469411 0.72550732 0.71944571 0.66454792\n",
      " 0.66659778 0.65000135 0.63362646 0.6244179 ] freq:  [124 124 124 124 124 124 124 124 124 124] acc [0.92362255 0.66852438 0.65028501 0.64407855 0.64939833 0.68499053\n",
      " 0.6866371  0.70094997 0.70525646 0.71462953]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riash\\anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:406: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return m3 / np.power(m2, 1.5)\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Optimization converged to parameters that are outside the range allowed by the distribution.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 63\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient_\u001b[39m\u001b[38;5;124m\"\u001b[39m,i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m loss: \u001b[39m\u001b[38;5;124m\"\u001b[39m, client_loss[i],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfreq: \u001b[39m\u001b[38;5;124m\"\u001b[39m, client_frequency[i], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m\"\u001b[39m, client_accuracy[i])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#     mean, std = stats.norm.fit(client_loss[i])\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#     pdf =  stats.norm.pdf(client_loss[i], mean, std)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m#  gamma\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m     shape, loc, scale \u001b[38;5;241m=\u001b[39m \u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_frequency\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     pdf \u001b[38;5;241m=\u001b[39m stats\u001b[38;5;241m.\u001b[39mgamma\u001b[38;5;241m.\u001b[39mpdf(client_frequency[i], shape, loc\u001b[38;5;241m=\u001b[39mloc, scale\u001b[38;5;241m=\u001b[39mscale)\n\u001b[0;32m     66\u001b[0m     pdfs\u001b[38;5;241m.\u001b[39mappend(pdf)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\_continuous_distns.py:2706\u001b[0m, in \u001b[0;36mgamma_gen.fit\u001b[1;34m(self, data, *args, **kwds)\u001b[0m\n\u001b[0;32m   2702\u001b[0m method \u001b[38;5;241m=\u001b[39m kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmle\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m floc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmm\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   2705\u001b[0m     \u001b[38;5;66;03m# loc is not fixed.  Use the default fit method.\u001b[39;00m\n\u001b[1;32m-> 2706\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2708\u001b[0m \u001b[38;5;66;03m# We already have this value, so just pop it from kwds.\u001b[39;00m\n\u001b[0;32m   2709\u001b[0m kwds\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:2505\u001b[0m, in \u001b[0;36mrv_continuous.fit\u001b[1;34m(self, data, *args, **kwds)\u001b[0m\n\u001b[0;32m   2503\u001b[0m loc, scale, shapes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unpack_loc_scale(vals)\n\u001b[0;32m   2504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mall(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_argcheck(\u001b[38;5;241m*\u001b[39mshapes)) \u001b[38;5;129;01mand\u001b[39;00m scale \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m-> 2505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimization converged to parameters that are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2506\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutside the range allowed by the distribution.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmm\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   2509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(obj):\n",
      "\u001b[1;31mException\u001b[0m: Optimization converged to parameters that are outside the range allowed by the distribution."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats \n",
    "\n",
    "# 4 clients---> gender, income\n",
    "# pdfs.clear()\n",
    "pdfs = []\n",
    "for i in list(client_accuracy.keys()):\n",
    "#     if(i== len(list(client_loss.keys()))-1):\n",
    "#         continue\n",
    "    print(\"client_\",i, \" loss: \", client_loss[i],\"freq: \", client_frequency[i], \"acc\", client_accuracy[i])\n",
    "    \n",
    "#     mean, std = stats.norm.fit(client_loss[i])\n",
    "#     pdf =  stats.norm.pdf(client_loss[i], mean, std)\n",
    "\n",
    "#     mean, std = stats.norm.fit(client_accuracy[i])\n",
    "#     pdf = stats.norm.pdf(client_accuracy[i],mean, std )\n",
    "    \n",
    "#     mean, std  = stats.norm.fit(client_frequency[i])\n",
    "#     pdf = stats.norm.pdf(client_frequency[i], mean, std )\n",
    "    \n",
    "    \n",
    "#     df_mean = np.mean(client_loss[i])\n",
    "#     df_std = np.std(client_loss[i])\n",
    "#     pdf = stats.norm.pdf(client_loss[i], df_mean, df_std)\n",
    "#     print(pdf)\n",
    "#     norm\n",
    "#     df_mean = np.mean(client_frequency[i])\n",
    "#     df_std = np.std(client_frequency[i])\n",
    "#     pdf = stats.norm.pdf(client_frequency[i], df_mean, df_std)\n",
    "#     print(pdf)\n",
    "    \n",
    "#     df_mean = np.mean(client_accuracy[i])\n",
    "#     df_std = np.std(client_accuracy[i])\n",
    "#     pdf = stats.norm.pdf(client_accuracy[i], df_mean, df_std)\n",
    "    \n",
    "#     lognorm\n",
    "#     shape, loc, scale = stats.lognorm.fit(client_loss[i])\n",
    "#     pdf = stats.lognorm.pdf(client_loss[i], shape, loc, scale)\n",
    "\n",
    "#     shape, loc, scale = stats.lognorm.fit(client_accuracy[i])\n",
    "#     pdf = stats.lognorm.pdf(client_accuracy[i], shape, loc, scale)\n",
    "    \n",
    "#     shape, loc, scale = stats.lognorm.fit(client_frequency[i])\n",
    "#     pdf = stats.lognorm.pdf(client_frequency[i], shape, loc, scale)\n",
    "    \n",
    "#     beta\n",
    "#     beta_params = stats.beta.fit(client_loss[i])\n",
    "#     pdf = stats.beta.pdf(client_loss[i], beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "\n",
    "#     beta_params = stats.beta.fit(client_accuracy[i])\n",
    "#     pdf = stats.beta.pdf(client_accuracy[i], beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "\n",
    "#     beta_params = stats.beta.fit(client_frequency[i])\n",
    "#     pdf = stats.beta.pdf(client_frequency[i], beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "\n",
    "#     burr\n",
    "#     burr_params = stats.burr.fit(client_loss[i])\n",
    "#     pdf = stats.burr.pdf(client_loss[i], burr_params[0], burr_params[1], burr_params[2], burr_params[3])\n",
    "\n",
    "    \n",
    "#  gamma\n",
    "    shape, loc, scale = stats.gamma.fit(client_frequency[i])\n",
    "    pdf = stats.gamma.pdf(client_frequency[i], shape, loc=loc, scale=scale)\n",
    "    \n",
    "    pdfs.append(pdf)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    ax = sns.displot( x = pdf, kind = \"kde\", height=10, aspect=2,\n",
    "                linewidth = 5 )\n",
    "#     ax.fig.suptitle('Original distribution', size = 20)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "#     plt.xlabel(\"Loss\")\n",
    "    plt.xlabel(\"Accuracy\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8c29d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_ 0  loss:  [0.31740108 0.62890333 0.68469411 0.72550732 0.71944571 0.66454792\n",
      " 0.66659778 0.65000135 0.63362646 0.6244179 ] freq:  [124 124 124 124 124 124 124 124 124 124] acc [0.92362255 0.66852438 0.65028501 0.64407855 0.64939833 0.68499053\n",
      " 0.6866371  0.70094997 0.70525646 0.71462953]\n",
      "client_ 1  loss:  [0.58489197 1.46422434 1.74906683 1.74952173 1.80269027 1.79261982\n",
      " 1.73943698 1.70472002 1.73115325 1.6768502 ] freq:  [23 23 23 23 23 23 23 23 23 23] acc [0.73519164 0.01045296 0.00278746 0.0195122  0.02020906 0.03554007\n",
      " 0.04181185 0.06829268 0.05226481 0.08780488]\n",
      "client_ 2  loss:  [0.17342669 0.06710181 0.05402871 0.0493838  0.04662018 0.04644888\n",
      " 0.04686099 0.04753332 0.047577   0.04744302] freq:  [286 286 286 286 286 286 286 286 286 286] acc [0.96615368 0.99939758 0.99983567 1.         0.99994522 0.99994522\n",
      " 0.99989045 1.         0.99994522 1.        ]\n",
      "client_ 3  loss:  [0.26368538 0.09146153 0.06407247 0.05886336 0.05748813 0.05671354\n",
      " 0.05750791 0.05567247 0.05570462 0.05545577] freq:  [180 180 180 180 180 180 180 180 180 180] acc [0.93930686 0.99773598 0.99921632 0.99982584 0.99991292 1.\n",
      " 1.         1.         1.         1.        ]\n",
      "ACCURACY\n",
      "0  and  1 2.6256203206875712\n",
      "0  and  2 29.370044270313375\n",
      "0  and  3 14.537960715572124\n",
      "1  and  2 31.99566459100095\n",
      "1  and  3 17.163581036259696\n",
      "2  and  3 14.832083554741251\n",
      "0  and global:  401.21956854423735\n",
      "1  and global:  403.8451888649249\n",
      "2  and global:  371.8495242739239\n",
      "3  and global:  386.6816078286652\n",
      "LOSS\n",
      "0  and  1 2.040987981225177\n",
      "0  and  2 5.99703505633477\n",
      "0  and  3 2.4684129405559494\n",
      "1  and  2 8.038023037559947\n",
      "1  and  3 4.509400921781127\n",
      "2  and  3 3.5286221157788202\n",
      "0  and global:  16.89477662895178\n",
      "1  and global:  18.935764610176957\n",
      "2  and global:  10.897741572617006\n",
      "3  and global:  14.42636368839583\n",
      "FREQUENCY\n",
      "0  and  1 nan\n",
      "0  and  2 nan\n",
      "0  and  3 nan\n",
      "1  and  2 nan\n",
      "1  and  3 nan\n",
      "2  and  3 nan\n",
      "0  and global:  nan\n",
      "1  and global:  nan\n",
      "2  and global:  nan\n",
      "3  and global:  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riash\\anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1870: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n"
     ]
    }
   ],
   "source": [
    "# NORM\n",
    "\n",
    "pdfs_loss_norm = []\n",
    "pdfs_acc_norm = []\n",
    "pdfs_freq_norm = []\n",
    "for i in list(client_accuracy.keys()):\n",
    "    print(\"client_\",i, \" loss: \", client_loss[i],\"freq: \", client_frequency[i], \"acc\", client_accuracy[i])\n",
    "    \n",
    "    mean, std = stats.norm.fit(client_loss[i])\n",
    "    pdf_loss_norm =  stats.norm.pdf(client_loss[i], mean, std)\n",
    "    pdfs_loss_norm.append(pdf_loss_norm)\n",
    "\n",
    "    mean, std = stats.norm.fit(client_accuracy[i])\n",
    "    pdf_acc_norm = stats.norm.pdf(client_accuracy[i],mean, std )\n",
    "    pdfs_acc_norm.append(pdf_acc_norm)\n",
    "    \n",
    "    mean, std  = stats.norm.fit(client_frequency[i])\n",
    "    pdf_freq_norm = stats.norm.pdf(client_frequency[i], mean, std )\n",
    "    pdfs_freq_norm.append(pdf_freq_norm)\n",
    "    \n",
    "    \n",
    "print(\"ACCURACY\")\n",
    "for i in range(len(pdfs_acc_norm)):\n",
    "    for j in range(i+1,len(pdfs_acc_norm)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_acc_norm[i], pdfs_acc_norm[j]))\n",
    "        \n",
    "        \n",
    "mean, std = stats.norm.fit(global_acc_list)\n",
    "pdf_global_acc_norm =  stats.norm.pdf(global_acc_list, mean, std)\n",
    "\n",
    "for i in range(len(pdfs_acc_norm)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_acc_norm[i], pdf_global_acc_norm))\n",
    "    \n",
    "print(\"LOSS\")\n",
    "for i in range(len(pdfs_loss_norm)):\n",
    "    for j in range(i+1,len(pdfs_loss_norm)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_loss_norm[i], pdfs_loss_norm[j]))\n",
    "        \n",
    "        \n",
    "mean, std = stats.norm.fit(global_loss_list)\n",
    "pdf_global_loss_norm =  stats.norm.pdf(global_loss_list, mean, std)\n",
    "\n",
    "for i in range(len(pdfs_loss_norm)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_loss_norm[i], pdf_global_loss_norm))\n",
    "    \n",
    "print(\"FREQUENCY\")\n",
    "for i in range(len(pdfs_freq_norm)):\n",
    "    for j in range(i+1,len(pdfs_freq_norm)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_freq_norm[i], pdfs_freq_norm[j]))\n",
    "        \n",
    "        \n",
    "mean, std = stats.norm.fit(global_freq_list)\n",
    "pdf_global_freq_norm =  stats.norm.pdf(global_freq_list, mean, std)\n",
    "\n",
    "for i in range(len(pdfs_freq_norm)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_freq_norm[i], pdf_global_freq_norm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd01c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(client_loss.keys()):\n",
    "#     if(i== len(list(client_loss.keys()))-1):\n",
    "#         continue\n",
    "    print(\"client_\",i, \"loss: \", client_loss[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "650336b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_ 0 freq:  [124 124 124 124 124 124 124 124 124 124]\n",
      "client_ 1 freq:  [23 23 23 23 23 23 23 23 23 23]\n",
      "client_ 2 freq:  [286 286 286 286 286 286 286 286 286 286]\n",
      "client_ 3 freq:  [180 180 180 180 180 180 180 180 180 180]\n"
     ]
    }
   ],
   "source": [
    "for i in list(client_loss.keys()):\n",
    "#     if(i== len(list(client_loss.keys()))-1):\n",
    "#         continue\n",
    "    print(\"client_\",i, \"freq: \", client_frequency[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a70793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdfs)):\n",
    "    for j in range(i+1,len(pdfs)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs[i], pdfs[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2620a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gamma\n",
    "shape, loc, scale = stats.gamma.fit(global_freq_list)\n",
    "pdf_global = stats.gamma.pdf(global_freq_list, shape, loc=loc, scale=scale)\n",
    "\n",
    "# df_mean = np.mean(global_loss_list)\n",
    "# df_std = np.std(global_loss_list)\n",
    "# pdf_global = stats.norm.pdf(global_loss_list, df_mean, df_std)\n",
    "\n",
    "# mean, std = stats.norm.fit(global_freq_list)\n",
    "# pdf_global =  stats.norm.pdf(global_freq_list, mean, std)\n",
    "\n",
    "# lognorm\n",
    "# shape, loc, scale = stats.lognorm.fit(global_loss_list)\n",
    "# pdf_global = stats.lognorm.pdf(global_loss_list, shape, loc, scale)\n",
    "\n",
    "# global_acc_list\n",
    "# global_freq_list\n",
    "\n",
    "# burr\n",
    "# burr_params = stats.beta.fit(global_freq_list)\n",
    "# pdf_global = stats.beta.pdf(global_freq_list, burr_params[0], burr_params[1], burr_params[2], burr_params[3])\n",
    "\n",
    "for i in range(len(pdfs)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs[i], pdf_global))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de13219",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8879a3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fitter import Fitter, get_common_distributions, get_distributions\n",
    "\n",
    "# for i in list(client_loss.keys()):\n",
    "#     height = client_loss[i]\n",
    "\n",
    "#     f = Fitter(height,\n",
    "#                distributions=['gamma',\n",
    "#                               'lognorm',\n",
    "#                               \"beta\",\n",
    "#                               \"burr\",\n",
    "#                               \"norm\"])\n",
    "#     f.fit()\n",
    "#     f.summary()\n",
    "\n",
    "#     sns.set_style('white')\n",
    "#     sns.set_context(\"paper\", font_scale = 2)\n",
    "#     sns.displot(data=dataset, x=\"Height\", kind=\"hist\", bins = 100, aspect = 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93def9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 clients---> gender, race, income\n",
    "pdfs = []\n",
    "for i in list(client_loss.keys()):\n",
    "    if(i== len(list(client_loss.keys()))-1):\n",
    "        continue\n",
    "    print(\"client_\",i, \" loss: \", client_loss[i],\"freq: \", client_frequency[i])\n",
    "\n",
    "#     shape, loc, scale = stats.gamma.fit(client_loss[i])\n",
    "    \n",
    "#     # Printing the estimated parameters\n",
    "#     print(\"Shape:\", shape)\n",
    "#     print(\"Location:\", loc)\n",
    "#     print(\"Scale:\", scale)\n",
    "#     pdf = stats.gamma.pdf(client_loss[i], shape, loc=loc, scale=scale)\n",
    "    \n",
    "    \n",
    "    df_mean = np.mean(client_loss[i])\n",
    "    df_std = np.std(client_loss[i])\n",
    "    pdf = stats.norm.pdf(client_loss[i], df_mean, df_std)\n",
    "    pdfs.append(pdf)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    ax = sns.displot( x = pdf, kind = \"kde\", height=10, aspect=2,\n",
    "                linewidth = 5 )\n",
    "    ax.fig.suptitle('Original distribution', size = 20)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xlabel(\"Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c9992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdfs)):\n",
    "    for j in range(i+1,len(pdfs)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs[i], pdfs[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bbbe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape, loc, scale = stats.gamma.fit(global_loss_list)\n",
    "pdf_global = stats.gamma.pdf(global_loss_list, shape, loc=loc, scale=scale)\n",
    "\n",
    "for i in range(len(pdfs)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs[i], pdf_global))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d36ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment plotter\n",
    "\n",
    "# for i in list(client_loss.keys()):\n",
    "#     if(i== len(list(client_loss.keys()))-1):\n",
    "#         continue\n",
    "#     print(\"client_\",i, \" loss: \", client_loss[i],\"freq: \", client_frequency[i])\n",
    "    \n",
    "# #     df_mean = np.mean(client_loss[i])\n",
    "# #     df_std = np.std(client_loss[i])\n",
    "# #     pdf = stats.norm.pdf(client_loss[i], df_mean, df_std)\n",
    "\n",
    "#     shape, loc, scale = stats.gamma.fit(client_loss[i])\n",
    "    \n",
    "#     # Printing the estimated parameters\n",
    "# #     print(\"Shape:\", shape)\n",
    "# #     print(\"Location:\", loc)\n",
    "# #     print(\"Scale:\", scale)\n",
    "#     pdf = stats.gamma.pdf(client_loss[i], shape, loc=loc, scale=scale)\n",
    "\n",
    "# #     plt.plot(client_loss[i], pdf, \"-o\", label = i)\n",
    "\n",
    "# #     client_loss[i] = stats.gamma.rvs(1, size=5000)+5\n",
    "#     sns.set_style(\"whitegrid\")\n",
    "\n",
    "#     ax = sns.displot( x = pdf, kind = \"kde\", height=10, aspect=2,\n",
    "#                 linewidth = 5 )\n",
    "#     ax.fig.suptitle('Original distribution', size = 20)\n",
    "# #     plt.plot(client_loss[i], client_frequency[i], \"-o\", label = i)\n",
    "# #     plt.legend()\n",
    "#     plt.ylabel(\"Frequency\")\n",
    "#     plt.xlabel(\"Loss\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670d1d42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:03:08.033027Z",
     "start_time": "2021-07-16T00:03:07.867893Z"
    }
   },
   "outputs": [],
   "source": [
    "score = global_model.evaluate(X_test, y_test, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcaa73e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:03:08.653744Z",
     "start_time": "2021-07-16T00:03:08.484057Z"
    }
   },
   "outputs": [],
   "source": [
    "nn_preds = global_model.predict(X_test)\n",
    "nn_preds = (nn_preds > 0.5)\n",
    "\n",
    "nn_precision =precision_score(y_test, nn_preds)\n",
    "nn_recall = recall_score(y_test, nn_preds)\n",
    "nn_accuracy = accuracy_score(y_test, nn_preds)\n",
    "nn_f1 = f1_score(y_test, nn_preds)\n",
    "\n",
    "\n",
    "print(\"Precision = {}\".format(nn_precision))\n",
    "print(\"Recall = {}\".format(nn_recall))\n",
    "print(\"Accuracy = {}\".format(nn_accuracy))\n",
    "print(\"f1 = {}\".format(nn_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6360dd5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:03:09.275052Z",
     "start_time": "2021-07-16T00:03:09.268152Z"
    }
   },
   "outputs": [],
   "source": [
    "arr = nn_preds > 0.5\n",
    "\n",
    "unique, counts = np.unique(arr, return_counts=True)\n",
    "\n",
    "np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a5ee99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T19:56:25.650336Z",
     "start_time": "2021-07-14T19:56:25.620Z"
    }
   },
   "outputs": [],
   "source": [
    "# pdf for client losses\n",
    "# x-loss\n",
    "# y- frequency\n",
    "# each client has one pdf for all rounds\n",
    "# using histogram\n",
    "\n",
    "\n",
    "# drop client\n",
    "# non iid\n",
    "# fedavg\n",
    "\n",
    "\n",
    "# gender dist\n",
    "# kernel density\n",
    "\n",
    "\n",
    "# non-iid, loss to accuracy\n",
    "# 4client"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
