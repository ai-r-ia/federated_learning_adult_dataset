{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cb54a96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T12:48:49.512456Z",
     "start_time": "2021-07-15T12:48:46.946937Z"
    }
   },
   "source": [
    "# Federated Learning Implementation with tensorflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b29fd2ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:57:57.329013Z",
     "start_time": "2021-07-15T23:57:57.321303Z"
    }
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Adult Dataset Salary Prediction \n",
    "# This is part of a study to investigate Differetinal privacy in Machine learning, Naturally we wish to compare it with federated learning.\n",
    "\n",
    "\n",
    "\n",
    "# Refrences:\n",
    "\n",
    "# [1] Federated Learning with Non-IID Data, Yue Zhao et al, arXiv: 1806.00582v1, 2 Jun 2018\n",
    "# [2] Communication-Efficient Learning of Deep Networks from Decentralized Data, H. Brendan McMahan et al, arXiv:1602.05629v3 [cs.LG] 28 Feb 2017\n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09b7dd46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:57:57.590963Z",
     "start_time": "2021-07-15T23:57:57.572204Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riash\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\riash\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\riash\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.metrics import precision_score,recall_score, accuracy_score,confusion_matrix,f1_score\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00b9bf6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:52.574848Z",
     "start_time": "2021-07-15T23:59:52.208912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9768, 94), (9768, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Train/Test Data seperation\n",
    "\n",
    "file_out = pd.read_csv('Data/adult_processed.csv')\n",
    "cols = []\n",
    "for i in list(file_out.columns):\n",
    "    if  i != 'income':\n",
    "        cols.append(i)\n",
    "\n",
    "feature_set1 = pd.read_csv('Data/train.csv')\n",
    "feature_set2 = pd.read_csv('Data/test.csv')\n",
    "\n",
    "x = feature_set1[cols].copy().values\n",
    "y = feature_set1[['income']].copy().values\n",
    "        \n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(x)\n",
    "y_train = y\n",
    "\n",
    "x2 = feature_set2[cols].copy().values\n",
    "y2 = feature_set2[['income']].copy().values\n",
    "        \n",
    "X_test = sc.transform(x2)\n",
    "y_test = y2\n",
    "\n",
    "\n",
    "X_test.shape, y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "066207c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:51.783759Z",
     "start_time": "2021-07-15T23:59:51.727576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1189\n",
      "1 4223\n",
      "2 2337\n",
      "3 820\n",
      "4 1722\n",
      "5 3649\n",
      "6 3526\n",
      "7 779\n",
      "8 3239\n",
      "9 2337\n",
      "10 2050\n",
      "11 3936\n",
      "12 4223\n",
      "13 2009\n",
      "14 3649\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_clients(image_list, label_list, num_clients=10, initial='clients'):\n",
    "    \n",
    "    ''' return: a dictionary with keys clients' names and value as \n",
    "                data shards - tuple of images and label lists.\n",
    "        args: \n",
    "            image_list: a list of numpy arrays of training images\n",
    "            label_list:a list of binarized labels for each image\n",
    "            num_client: number of fedrated members (clients)\n",
    "            initials: the clients'name prefix, e.g, clients_1 \n",
    "            \n",
    "    '''\n",
    "\n",
    "    #create a list of client names\n",
    "    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n",
    "\n",
    "#     iid\n",
    "#     #randomize the data\n",
    "#     data = list(zip(image_list, label_list))\n",
    "#     random.shuffle(data)\n",
    "    \n",
    "   \n",
    "    \n",
    "#     non-iid //////////////////////////////////////\n",
    "    max_y = np.argmax(label_list, axis=-1)\n",
    "    sorted_zip = sorted(zip(max_y, label_list, image_list), key=lambda x: x[0])\n",
    "    data = [(x,y) for _,y,x in sorted_zip]\n",
    "\n",
    "# LOGIC:\n",
    "#    image_list length-->total data items\n",
    "#    taking 50 images in each shard--> num_shards = image_list/41 gives 953 shards\n",
    "#    num_shard = num_shards + 1 if(image_list%50 >0) \n",
    "\n",
    "    num_shards, num_imgs = 953, 41\n",
    "    idx_shard = [i for i in range(num_shards)]\n",
    "    dict_users = {i: np.array([]) for i in range(num_clients)}\n",
    "#     dict_users = [i for i in range(num_clients)]\n",
    "#     idxs = np.arange(num_shards*num_imgs)\n",
    "#     labels = dataset.train_labels.numpy()\n",
    "\n",
    "    max_y = np.argmax(label_list, axis=-1)\n",
    "#     image_list = np.argmax(image_list, axis=-1)\n",
    "#     print(idxs.shape, label_list.shape)\n",
    "    \n",
    "#     idxs_labels = np.vstack((idxs, max_y))\n",
    "#     idxs_labels = idxs_labels[:, idxs_labels[1, :].argsort()]\n",
    "#     idxs = idxs_labels[0, :]\n",
    "\n",
    "    min_shard = 1\n",
    "    max_shard = 60  #953/15 = 63.53\n",
    "    \n",
    "    random_shard_size = np.random.randint(min_shard, max_shard+1,\n",
    "                                          size=num_clients)\n",
    "    random_shard_size = np.around(random_shard_size /\n",
    "                                  sum(random_shard_size) * num_shards)\n",
    "    random_shard_size = random_shard_size.astype(int)\n",
    "\n",
    "\n",
    "    if sum(random_shard_size) > num_shards:\n",
    "\n",
    "        for i in range(num_clients):\n",
    "            # First assign each client 1 shard to ensure every client has\n",
    "            # atleast one shard of data\n",
    "            rand_set = set(np.random.choice(idx_shard, 1, replace=False))\n",
    "            idx_shard = list(set(idx_shard) - rand_set)\n",
    "            for rand in rand_set:\n",
    "                ind1 = rand*num_imgs\n",
    "                ind2 = (rand+1)*num_imgs\n",
    "                if(len(dict_users[i]) == 0):\n",
    "                    dict_users[i] = data[ind1: ind2]\n",
    "                dict_users[i] = np.concatenate(\n",
    "                    (dict_users[i],data[ind1: ind2]),\n",
    "                    axis=0)\n",
    "\n",
    "        random_shard_size = random_shard_size-1\n",
    "\n",
    "        # Next, randomly assign the remaining shards\n",
    "        for i in range(num_clients):\n",
    "            if len(idx_shard) == 0:\n",
    "                continue\n",
    "            shard_size = random_shard_size[i]\n",
    "            if shard_size > len(idx_shard):\n",
    "                shard_size = len(idx_shard)\n",
    "            rand_set = set(np.random.choice(idx_shard, shard_size,\n",
    "                                            replace=False))\n",
    "            idx_shard = list(set(idx_shard) - rand_set)\n",
    "            for rand in rand_set:\n",
    "                ind1 = rand*num_imgs\n",
    "                ind2 = (rand+1)*num_imgs\n",
    "                if(len(dict_users[i]) == 0):\n",
    "                    dict_users[i] = data[ind1: ind2]\n",
    "                dict_users[i] = np.concatenate(\n",
    "                    (dict_users[i],data[ind1: ind2]),\n",
    "                    axis=0)\n",
    "\n",
    "    else:\n",
    "\n",
    "        for i in range(num_clients):\n",
    "            shard_size = random_shard_size[i]\n",
    "            rand_set = set(np.random.choice(idx_shard, shard_size,\n",
    "                                            replace=False))\n",
    "            idx_shard = list(set(idx_shard) - rand_set)\n",
    "            for rand in rand_set:\n",
    "                ind1 = rand*num_imgs\n",
    "                ind2 = (rand+1)*num_imgs\n",
    "#                 print(dict_users[i])\n",
    "#                 print((list(zip(image_list[ind1: ind2], idxs[ind1: ind2]))))\n",
    "                if(len(dict_users[i]) == 0):\n",
    "                    dict_users[i] = data[ind1: ind2]\n",
    "                dict_users[i] = np.concatenate(\n",
    "                    (dict_users[i],data[ind1: ind2]),\n",
    "                    axis=0)\n",
    "\n",
    "        if len(idx_shard) > 0:\n",
    "            # Add the leftover shards to the client with minimum images:\n",
    "            shard_size = len(idx_shard)\n",
    "            # Add the remaining shard to the client with lowest data\n",
    "            k = min(dict_users, key=lambda x: len(dict_users.get(x)))\n",
    "            rand_set = set(np.random.choice(idx_shard, shard_size,\n",
    "                                            replace=False))\n",
    "            idx_shard = list(set(idx_shard) - rand_set)\n",
    "            for rand in rand_set:\n",
    "                ind1 = rand*num_imgs\n",
    "                ind2 = (rand+1)*num_imgs\n",
    "                if(len(dict_users[k]) == 0):\n",
    "                    dict_users[k] = data[ind1: ind2]\n",
    "                dict_users[k] = np.concatenate(\n",
    "                    (dict_users[k],data[ind1: ind2]),\n",
    "                    axis=0)\n",
    "#     print(dict_users[0])\n",
    "\n",
    "#     data = dict_users[0]\n",
    "# #     print(len(data))\n",
    "# #     print(len(data[0]))\n",
    "#     for k in dict_users:\n",
    "#         data = np.append(data, dict_users[k])\n",
    "                \n",
    "    return dict_users\n",
    "\n",
    "#   ////////////////////////////////////////////////////  \n",
    "    #shard data and place at each client\n",
    "#     size = len(data)//num_clients\n",
    "#     shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n",
    "\n",
    "#     #number of clients must equal number of shards\n",
    "#     assert(len(shards) == len(client_names))\n",
    "\n",
    "#     print(len(image_list))\n",
    "#     for i in range(len(client_names)):\n",
    "#         print(client_names[i], len(shards[i]))\n",
    "              \n",
    "#     return {client_names[i] : shards[i] for i in range(len(client_names))} \n",
    "\n",
    "\n",
    "clients = create_clients(X_train, y_train, num_clients=15, initial='client')\n",
    "# print(clients)\n",
    "\n",
    "for i in range(len(clients.keys())):\n",
    "        print(i, len(clients[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "715ed657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:52.579114Z",
     "start_time": "2021-07-15T23:59:52.576244Z"
    }
   },
   "outputs": [],
   "source": [
    "# take bs = 128 for 5 clients and 10 rounds\n",
    "def batch_data(data_shard, bs=64):\n",
    "    '''Takes in a clients data shard and create a tfds object off it\n",
    "    args:\n",
    "        shard: a data, label constituting a client's data shard\n",
    "        bs:batch size\n",
    "    return:\n",
    "        tfds object'''\n",
    "    #seperate shard into data and labels lists\n",
    "    data, label = zip(*data_shard)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
    "    \n",
    "    return dataset.shuffle(len(label)).batch(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "dfd80728",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:54.563066Z",
     "start_time": "2021-07-15T23:59:52.773340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.53581756, -1.28463386,  0.34889424, -0.3363592 ,  1.13335883,\n",
      "        -0.14593585, -0.2175757 , -0.03492533, -0.39584132, -0.02771973,\n",
      "        -0.92136273, -0.11269381,  1.4253894 , -0.17891851, -0.179527  ,\n",
      "        -0.24508517, -0.36159104, -0.01678105, -0.37649823, -0.37618802,\n",
      "        -0.17815534,  4.73551053, -0.2554779 , -0.33653279, -0.07082154,\n",
      "        -0.38135638, -0.14300071, -0.35746063, -0.17351455, -0.22532901,\n",
      "        -0.82412796,  1.69528279, -0.17654328, -0.42836007, -0.34117932,\n",
      "        -0.22419805, -0.24449789, -0.1728875 , -0.26401111, -0.0159999 ,\n",
      "         0.66348609, -0.18939262, -0.29443044, -0.20406156, -0.02086318,\n",
      "        -0.09870466, -0.17792583, -0.32481669, -0.09115626,  0.41017233,\n",
      "        -0.70282207,  0.70282207, -0.13427492, -0.02426908, -0.0595346 ,\n",
      "        -0.04962853, -0.03986597, -0.05456777, -0.04501058, -0.02994265,\n",
      "        -0.05732963, -0.04831574, -0.02771973, -0.0639213 , -0.031609  ,\n",
      "        -0.04296634, -0.03888801,  0.        , -0.02086318, -0.02426908,\n",
      "        -0.02024   , -0.05456777, -0.03615183, -0.02771973, -0.04414598,\n",
      "        -0.04778062, -0.04206007, -0.02086318, -0.14055874, -0.03319212,\n",
      "        -0.02205688, -0.03078706, -0.07959772, -0.04206007, -0.03615183,\n",
      "        -0.06060742, -0.02086318, -0.04804892, -0.03720136, -0.02580434,\n",
      "        -0.02373533,  0.33695676, -0.04175364, -0.02205688])\n",
      " array([0], dtype=int64)]\n",
      "[array([ 1.25646332,  1.04598654, -0.37001588,  0.18074899, -0.42476157,\n",
      "        -0.14593585,  3.5064733 , -0.43721211, -0.39584132, -0.02771973,\n",
      "        -0.92136273, -0.11269381,  1.4253894 , -0.17891851, -0.179527  ,\n",
      "         4.08021423, -0.36159104, -0.01678105, -0.37649823, -0.37618802,\n",
      "        -0.17815534, -0.21117047, -0.2554779 , -0.33653279, -0.07082154,\n",
      "        -0.38135638, -0.14300071, -0.35746063, -0.17351455, -0.22532901,\n",
      "        -0.82412796,  1.69528279, -0.17654328, -0.42836007, -0.34117932,\n",
      "        -0.22419805,  4.09001484, -0.1728875 , -0.26401111, -0.0159999 ,\n",
      "        -1.50719061, -0.18939262, -0.29443044, -0.20406156, -0.02086318,\n",
      "        -0.09870466, -0.17792583, -0.32481669, -0.09115626,  0.41017233,\n",
      "        -0.70282207,  0.70282207, -0.13427492, -0.02426908, -0.0595346 ,\n",
      "        -0.04962853, -0.03986597, -0.05456777, -0.04501058, -0.02994265,\n",
      "        -0.05732963, -0.04831574, -0.02771973, -0.0639213 , -0.031609  ,\n",
      "        -0.04296634, -0.03888801,  0.        , -0.02086318, -0.02426908,\n",
      "        -0.02024   , -0.05456777, -0.03615183, -0.02771973, -0.04414598,\n",
      "        -0.04778062, -0.04206007, -0.02086318, -0.14055874, -0.03319212,\n",
      "        -0.02205688, -0.03078706, -0.07959772, -0.04206007, -0.03615183,\n",
      "        -0.06060742, -0.02086318, -0.04804892, -0.03720136, -0.02580434,\n",
      "        -0.02373533,  0.33695676, -0.04175364, -0.02205688])\n",
      " array([0], dtype=int64)]\n",
      "[array([ 1.4489849 ,  0.53616333, -0.07624053, -0.85346739,  0.74382873,\n",
      "        -0.14593585, -0.2175757 , -0.03492533, -0.39584132, -0.02771973,\n",
      "         1.08534887, -0.11269381, -0.70156267, -0.17891851, -0.179527  ,\n",
      "        -0.24508517, -0.36159104, -0.01678105, -0.37649823,  2.6582452 ,\n",
      "        -0.17815534, -0.21117047, -0.2554779 , -0.33653279, -0.07082154,\n",
      "        -0.38135638, -0.14300071, -0.35746063, -0.17351455, -0.22532901,\n",
      "         1.2134038 , -0.58987209, -0.17654328, -0.42836007, -0.34117932,\n",
      "        -0.22419805, -0.24449789, -0.1728875 , -0.26401111, -0.0159999 ,\n",
      "         0.66348609, -0.18939262, -0.29443044, -0.20406156, -0.02086318,\n",
      "        -0.09870466, -0.17792583, -0.32481669, -0.09115626,  0.41017233,\n",
      "        -0.70282207,  0.70282207, -0.13427492, -0.02426908, -0.0595346 ,\n",
      "        -0.04962853, -0.03986597, -0.05456777, -0.04501058, -0.02994265,\n",
      "        -0.05732963, -0.04831574, -0.02771973, -0.0639213 , -0.031609  ,\n",
      "        -0.04296634, -0.03888801,  0.        , -0.02086318, -0.02426908,\n",
      "        -0.02024   , -0.05456777, -0.03615183, -0.02771973, -0.04414598,\n",
      "        -0.04778062, -0.04206007, -0.02086318, -0.14055874, -0.03319212,\n",
      "        -0.02205688, -0.03078706, -0.07959772, -0.04206007, -0.03615183,\n",
      "        -0.06060742, -0.02086318, -0.04804892, -0.03720136, -0.02580434,\n",
      "        -0.02373533,  0.33695676, -0.04175364, -0.02205688])\n",
      " array([1], dtype=int64)]\n",
      "[array([ 0.55539818,  0.17200389,  0.61875588, -0.5949133 ,  0.35429863,\n",
      "        -0.14593585, -0.2175757 ,  3.18336894,  2.52626483, -0.02771973,\n",
      "        -0.92136273, -0.11269381, -0.70156267, -0.17891851, -0.179527  ,\n",
      "         4.08021423, -0.36159104, -0.01678105, -0.37649823, -0.37618802,\n",
      "        -0.17815534, -0.21117047, -0.2554779 , -0.33653279, -0.07082154,\n",
      "        -0.38135638, -0.14300071, -0.35746063, -0.17351455, -0.22532901,\n",
      "        -0.82412796,  1.69528279, -0.17654328, -0.42836007, -0.34117932,\n",
      "        -0.22419805,  4.09001484, -0.1728875 , -0.26401111, -0.0159999 ,\n",
      "        -1.50719061, -0.18939262, -0.29443044, -0.20406156, -0.02086318,\n",
      "        -0.09870466, -0.17792583, -0.32481669, -0.09115626,  0.41017233,\n",
      "        -0.70282207,  0.70282207, -0.13427492, -0.02426908, -0.0595346 ,\n",
      "        -0.04962853, -0.03986597, -0.05456777, -0.04501058, -0.02994265,\n",
      "        -0.05732963, -0.04831574, -0.02771973, -0.0639213 , -0.031609  ,\n",
      "        -0.04296634, -0.03888801,  0.        , -0.02086318, -0.02426908,\n",
      "        -0.02024   , -0.05456777, -0.03615183, -0.02771973, -0.04414598,\n",
      "        -0.04778062, -0.04206007, -0.02086318, -0.14055874, -0.03319212,\n",
      "        -0.02205688, -0.03078706, -0.07959772, -0.04206007, -0.03615183,\n",
      "        -0.06060742, -0.02086318, -0.04804892, -0.03720136, -0.02580434,\n",
      "        -0.02373533,  0.33695676, -0.04175364, -0.02205688])\n",
      " array([0], dtype=int64)]\n",
      "[array([-0.18858353, -0.55631498,  1.5153351 ,  1.21496536, -0.03523147,\n",
      "        -0.14593585, -0.2175757 ,  0.60873353, -0.39584132, -0.02771973,\n",
      "         1.08534887, -0.11269381, -0.70156267, -0.17891851, -0.179527  ,\n",
      "        -0.24508517, -0.36159104, -0.01678105, -0.37649823, -0.37618802,\n",
      "        -0.17815534, -0.21117047,  3.91423297, -0.33653279, -0.07082154,\n",
      "        -0.38135638, -0.14300071, -0.35746063, -0.17351455, -0.22532901,\n",
      "         1.2134038 , -0.58987209, -0.17654328, -0.42836007, -0.34117932,\n",
      "        -0.22419805, -0.24449789, -0.1728875 , -0.26401111, -0.0159999 ,\n",
      "        -1.50719061, -0.18939262,  3.3963879 , -0.20406156, -0.02086318,\n",
      "        -0.09870466, -0.17792583, -0.32481669, -0.09115626,  0.41017233,\n",
      "        -0.70282207,  0.70282207, -0.13427492, -0.02426908, -0.0595346 ,\n",
      "        -0.04962853, -0.03986597, -0.05456777, -0.04501058, -0.02994265,\n",
      "        -0.05732963, -0.04831574, -0.02771973, -0.0639213 , -0.031609  ,\n",
      "        -0.04296634, -0.03888801,  0.        , -0.02086318, -0.02426908,\n",
      "        -0.02024   , -0.05456777, -0.03615183, -0.02771973, -0.04414598,\n",
      "        -0.04778062, -0.04206007, -0.02086318, -0.14055874, -0.03319212,\n",
      "        -0.02205688, -0.03078706, -0.07959772, -0.04206007, -0.03615183,\n",
      "        -0.06060742, -0.02086318, -0.04804892, -0.03720136, -0.02580434,\n",
      "        -0.02373533,  0.33695676, -0.04175364, -0.02205688])\n",
      " array([0], dtype=int64)]\n",
      "[array([ 1.024572  , -0.99330631, -0.09903491, -2.40479196, -1.20382177,\n",
      "        -0.14593585, -0.2175757 , -0.03492533, -0.39584132, -0.02771973,\n",
      "        -0.92136273, -0.11269381,  1.4253894 , -0.17891851, -0.179527  ,\n",
      "         4.08021423, -0.36159104, -0.01678105, -0.37649823, -0.37618802,\n",
      "        -0.17815534, -0.21117047, -0.2554779 , -0.33653279, -0.07082154,\n",
      "        -0.38135638, -0.14300071, -0.35746063, -0.17351455, -0.22532901,\n",
      "        -0.82412796, -0.58987209, -0.17654328, -0.42836007,  2.93101004,\n",
      "        -0.22419805,  4.09001484, -0.1728875 , -0.26401111, -0.0159999 ,\n",
      "        -1.50719061, -0.18939262, -0.29443044, -0.20406156, -0.02086318,\n",
      "        -0.09870466, -0.17792583, -0.32481669, -0.09115626,  0.41017233,\n",
      "         1.42283523, -1.42283523, -0.13427492, -0.02426908, -0.0595346 ,\n",
      "        -0.04962853, -0.03986597, -0.05456777, -0.04501058, -0.02994265,\n",
      "        -0.05732963, -0.04831574, -0.02771973, -0.0639213 , -0.031609  ,\n",
      "        -0.04296634, -0.03888801,  0.        , -0.02086318, -0.02426908,\n",
      "        -0.02024   , -0.05456777, -0.03615183, -0.02771973, -0.04414598,\n",
      "        -0.04778062, -0.04206007, -0.02086318, -0.14055874, -0.03319212,\n",
      "        -0.02205688, -0.03078706, -0.07959772, -0.04206007, -0.03615183,\n",
      "        -0.06060742, -0.02086318, -0.04804892, -0.03720136, -0.02580434,\n",
      "        -0.02373533,  0.33695676, -0.04175364, -0.02205688])\n",
      " array([0], dtype=int64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-1.29022693, -0.33781932,  0.76918176, -0.3363592 ,  1.13335883,\n",
      "        -0.14593585, -0.2175757 , -0.03492533, -0.39584132, -0.02771973,\n",
      "        -0.92136273, -0.11269381,  1.4253894 , -0.17891851, -0.179527  ,\n",
      "        -0.24508517, -0.36159104, -0.01678105, -0.37649823, -0.37618802,\n",
      "        -0.17815534, -0.21117047, -0.2554779 , -0.33653279, -0.07082154,\n",
      "         2.62221911, -0.14300071, -0.35746063, -0.17351455, -0.22532901,\n",
      "        -0.82412796, -0.58987209, -0.17654328,  2.33448462, -0.34117932,\n",
      "        -0.22419805, -0.24449789, -0.1728875 , -0.26401111, -0.0159999 ,\n",
      "         0.66348609, -0.18939262, -0.29443044, -0.20406156, -0.02086318,\n",
      "        -0.09870466, -0.17792583, -0.32481669, -0.09115626,  0.41017233,\n",
      "         1.42283523, -1.42283523, -0.13427492, -0.02426908, -0.0595346 ,\n",
      "        -0.04962853, -0.03986597, -0.05456777, -0.04501058, -0.02994265,\n",
      "        -0.05732963, -0.04831574, -0.02771973, -0.0639213 , -0.031609  ,\n",
      "        -0.04296634, -0.03888801,  0.        , -0.02086318, -0.02426908,\n",
      "        -0.02024   , -0.05456777, -0.03615183, -0.02771973, -0.04414598,\n",
      "        -0.04778062, -0.04206007, -0.02086318, -0.14055874, -0.03319212,\n",
      "        -0.02205688, -0.03078706, -0.07959772, -0.04206007, -0.03615183,\n",
      "        -0.06060742, -0.02086318, -0.04804892, -0.03720136, -0.02580434,\n",
      "        -0.02373533,  0.33695676, -0.04175364, -0.02205688])\n",
      " array([0], dtype=int64)]\n",
      "[array([ 1.36946512,  1.11881843,  0.97091635, -0.3363592 ,  1.13335883,\n",
      "        -0.14593585, -0.2175757 ,  0.36736146, -0.39584132, -0.02771973,\n",
      "         1.08534887, -0.11269381, -0.70156267, -0.17891851, -0.179527  ,\n",
      "        -0.24508517, -0.36159104, -0.01678105, -0.37649823,  2.6582452 ,\n",
      "        -0.17815534, -0.21117047, -0.2554779 , -0.33653279, -0.07082154,\n",
      "        -0.38135638, -0.14300071, -0.35746063, -0.17351455, -0.22532901,\n",
      "         1.2134038 , -0.58987209, -0.17654328, -0.42836007, -0.34117932,\n",
      "        -0.22419805, -0.24449789, -0.1728875 , -0.26401111, -0.0159999 ,\n",
      "         0.66348609, -0.18939262, -0.29443044, -0.20406156, -0.02086318,\n",
      "        -0.09870466, -0.17792583, -0.32481669, -0.09115626,  0.41017233,\n",
      "        -0.70282207,  0.70282207, -0.13427492, -0.02426908, -0.0595346 ,\n",
      "        -0.04962853, -0.03986597, -0.05456777, -0.04501058, -0.02994265,\n",
      "        -0.05732963, -0.04831574, -0.02771973, -0.0639213 , -0.031609  ,\n",
      "        -0.04296634, -0.03888801,  0.        , -0.02086318, -0.02426908,\n",
      "        -0.02024   , -0.05456777, -0.03615183, -0.02771973, -0.04414598,\n",
      "        -0.04778062, -0.04206007, -0.02086318, -0.14055874, -0.03319212,\n",
      "        -0.02205688, -0.03078706, -0.07959772, -0.04206007, -0.03615183,\n",
      "        -0.06060742, -0.02086318, -0.04804892, -0.03720136, -0.02580434,\n",
      "        -0.02373533,  0.33695676, -0.04175364, -0.02205688])\n",
      " array([1], dtype=int64)]\n",
      "[array([-1.25000595,  1.33731409, -1.34909314, -1.62912968, -2.76194218,\n",
      "        -0.14593585, -0.2175757 , -0.03492533,  2.52626483, -0.02771973,\n",
      "        -0.92136273, -0.11269381, -0.70156267, -0.17891851, -0.179527  ,\n",
      "        -0.24508517, -0.36159104, -0.01678105, -0.37649823, -0.37618802,\n",
      "        -0.17815534, -0.21117047, -0.2554779 ,  2.97147868, -0.07082154,\n",
      "        -0.38135638, -0.14300071, -0.35746063, -0.17351455, -0.22532901,\n",
      "        -0.82412796,  1.69528279, -0.17654328, -0.42836007, -0.34117932,\n",
      "        -0.22419805, -0.24449789, -0.1728875 , -0.26401111, -0.0159999 ,\n",
      "         0.66348609, -0.18939262, -0.29443044, -0.20406156, -0.02086318,\n",
      "        -0.09870466, -0.17792583, -0.32481669, -0.09115626,  0.41017233,\n",
      "         1.42283523, -1.42283523, -0.13427492, -0.02426908, -0.0595346 ,\n",
      "        -0.04962853, -0.03986597, -0.05456777, -0.04501058, -0.02994265,\n",
      "        -0.05732963, -0.04831574, -0.02771973, -0.0639213 , -0.031609  ,\n",
      "        -0.04296634, -0.03888801,  0.        , -0.02086318, -0.02426908,\n",
      "        -0.02024   , -0.05456777, -0.03615183, -0.02771973, -0.04414598,\n",
      "        -0.04778062, -0.04206007, -0.02086318, -0.14055874, -0.03319212,\n",
      "        -0.02205688, -0.03078706, -0.07959772, -0.04206007, -0.03615183,\n",
      "        -0.06060742, -0.02086318, -0.04804892, -0.03720136, -0.02580434,\n",
      "        -0.02373533,  0.33695676, -0.04175364, -0.02205688])\n",
      " array([0], dtype=int64)]\n",
      "[array([-0.28633399,  0.60899522, -0.1275113 , -0.3363592 ,  1.13335883,\n",
      "         0.29485523, -0.2175757 ,  1.57422181, -0.39584132, -0.02771973,\n",
      "        -0.92136273, -0.11269381,  1.4253894 , -0.17891851, -0.179527  ,\n",
      "        -0.24508517, -0.36159104, -0.01678105, -0.37649823, -0.37618802,\n",
      "        -0.17815534, -0.21117047, -0.2554779 , -0.33653279, -0.07082154,\n",
      "        -0.38135638, -0.14300071,  2.79751091, -0.17351455, -0.22532901,\n",
      "        -0.82412796,  1.69528279, -0.17654328, -0.42836007, -0.34117932,\n",
      "        -0.22419805, -0.24449789, -0.1728875 , -0.26401111, -0.0159999 ,\n",
      "        -1.50719061,  5.28003673, -0.29443044, -0.20406156, -0.02086318,\n",
      "        -0.09870466, -0.17792583, -0.32481669, -0.09115626,  0.41017233,\n",
      "        -0.70282207,  0.70282207, -0.13427492, -0.02426908, -0.0595346 ,\n",
      "        -0.04962853, -0.03986597, -0.05456777, -0.04501058, -0.02994265,\n",
      "        -0.05732963, -0.04831574, -0.02771973, -0.0639213 , -0.031609  ,\n",
      "        -0.04296634, -0.03888801,  0.        , -0.02086318, -0.02426908,\n",
      "        -0.02024   , -0.05456777, -0.03615183, -0.02771973, -0.04414598,\n",
      "        -0.04778062, -0.04206007, -0.02086318, -0.14055874, -0.03319212,\n",
      "        -0.02205688, -0.03078706, -0.07959772, -0.04206007, -0.03615183,\n",
      "        -0.06060742, -0.02086318, -0.04804892, -0.03720136, -0.02580434,\n",
      "        -0.02373533,  0.33695676, -0.04175364, -0.02205688])\n",
      " array([0], dtype=int64)]\n",
      "[array([-1.53949769, -0.04649177,  0.2465519 , -0.5949133 ,  0.35429863,\n",
      "         0.82155085, -0.2175757 ,  0.36736146, -0.39584132, -0.02771973,\n",
      "         1.08534887, -0.11269381, -0.70156267, -0.17891851, -0.179527  ,\n",
      "        -0.24508517, -0.36159104, -0.01678105, -0.37649823, -0.37618802,\n",
      "        -0.17815534, -0.21117047, -0.2554779 , -0.33653279, -0.07082154,\n",
      "         2.62221911, -0.14300071, -0.35746063, -0.17351455, -0.22532901,\n",
      "        -0.82412796, -0.58987209, -0.17654328, -0.42836007, -0.34117932,\n",
      "         4.46034218, -0.24449789, -0.1728875 , -0.26401111, -0.0159999 ,\n",
      "         0.66348609, -0.18939262, -0.29443044, -0.20406156, -0.02086318,\n",
      "        -0.09870466, -0.17792583, -0.32481669, -0.09115626,  0.41017233,\n",
      "         1.42283523, -1.42283523, -0.13427492, -0.02426908, -0.0595346 ,\n",
      "        -0.04962853, -0.03986597, -0.05456777, -0.04501058, -0.02994265,\n",
      "        -0.05732963, -0.04831574, -0.02771973, -0.0639213 , -0.031609  ,\n",
      "        -0.04296634, -0.03888801,  0.        , -0.02086318, -0.02426908,\n",
      "        -0.02024   , -0.05456777, -0.03615183, -0.02771973, -0.04414598,\n",
      "        -0.04778062, -0.04206007, -0.02086318, -0.14055874, -0.03319212,\n",
      "        -0.02205688, -0.03078706, -0.07959772, -0.04206007, -0.03615183,\n",
      "        -0.06060742, -0.02086318, -0.04804892, -0.03720136, -0.02580434,\n",
      "        -0.02373533,  0.33695676, -0.04175364, -0.02205688])\n",
      " array([1], dtype=int64)]\n",
      "[array([-1.56950381e+00, -3.37819320e-01,  3.20730885e-01, -3.36359204e-01,\n",
      "         1.13335883e+00, -1.45935846e-01, -2.17575700e-01,  3.67361458e-01,\n",
      "        -3.95841318e-01, -2.77197326e-02,  1.08534887e+00, -1.12693805e-01,\n",
      "        -7.01562674e-01, -1.78918509e-01, -1.79526996e-01, -2.45085171e-01,\n",
      "        -3.61591044e-01, -1.67810490e-02, -3.76498234e-01, -3.76188020e-01,\n",
      "        -1.78155341e-01, -2.11170473e-01, -2.55477895e-01, -3.36532787e-01,\n",
      "        -7.08215370e-02,  2.62221911e+00, -1.43000711e-01, -3.57460625e-01,\n",
      "        -1.73514553e-01, -2.25329007e-01,  1.21340380e+00, -5.89872088e-01,\n",
      "        -1.76543277e-01, -4.28360073e-01, -3.41179316e-01, -2.24198045e-01,\n",
      "        -2.44497890e-01, -1.72887497e-01, -2.64011107e-01, -1.59998976e-02,\n",
      "         6.63486085e-01, -1.89392622e-01, -2.94430445e-01, -2.04061556e-01,\n",
      "        -2.08631836e-02, -9.87046557e-02, -1.77925832e-01, -3.24816694e-01,\n",
      "        -9.11562559e-02,  4.10172335e-01, -7.02822068e-01,  7.02822068e-01,\n",
      "        -1.34274921e-01, -2.42690848e-02, -5.95346019e-02, -4.96285300e-02,\n",
      "        -3.98659670e-02, -5.45677745e-02, -4.50105844e-02, -2.99426506e-02,\n",
      "        -5.73296289e-02, -4.83157402e-02, -2.77197326e-02, -6.39213038e-02,\n",
      "        -3.16090013e-02, -4.29663416e-02, -3.88880141e-02,  0.00000000e+00,\n",
      "        -2.08631836e-02, -2.42690848e-02, -2.02400020e-02, -5.45677745e-02,\n",
      "        -3.61518333e-02, -2.77197326e-02, -4.41459835e-02, -4.77806226e-02,\n",
      "        -4.20600681e-02, -2.08631836e-02, -1.40558741e-01, -3.31921170e-02,\n",
      "        -2.20568779e-02,  3.24811796e+01, -7.95977214e-02, -4.20600681e-02,\n",
      "        -3.61518333e-02, -6.06074228e-02, -2.08631836e-02, -4.80489195e-02,\n",
      "        -3.72013596e-02, -2.58043449e-02, -2.37353293e-02, -2.96773987e+00,\n",
      "        -4.17536374e-02, -2.20568779e-02])\n",
      " array([0], dtype=int64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.48609325, -0.62914687,  0.15183614,  0.18074899, -0.42476157,\n",
      "        -0.14593585, -0.2175757 , -0.03492533, -0.39584132, -0.02771973,\n",
      "        -0.92136273, -0.11269381,  1.4253894 , -0.17891851, -0.179527  ,\n",
      "        -0.24508517,  2.76555523, -0.01678105, -0.37649823, -0.37618802,\n",
      "        -0.17815534, -0.21117047, -0.2554779 , -0.33653279, -0.07082154,\n",
      "        -0.38135638, -0.14300071, -0.35746063, -0.17351455, -0.22532901,\n",
      "        -0.82412796, -0.58987209, -0.17654328, -0.42836007,  2.93101004,\n",
      "        -0.22419805, -0.24449789, -0.1728875 , -0.26401111, -0.0159999 ,\n",
      "         0.66348609, -0.18939262, -0.29443044, -0.20406156, -0.02086318,\n",
      "        -0.09870466, -0.17792583, -0.32481669, -0.09115626,  0.41017233,\n",
      "        -0.70282207,  0.70282207, -0.13427492, -0.02426908, -0.0595346 ,\n",
      "        -0.04962853, -0.03986597, -0.05456777, -0.04501058, -0.02994265,\n",
      "        -0.05732963, -0.04831574, -0.02771973, -0.0639213 , -0.031609  ,\n",
      "        -0.04296634, -0.03888801,  0.        , -0.02086318, -0.02426908,\n",
      "        -0.02024   , -0.05456777, -0.03615183, -0.02771973, -0.04414598,\n",
      "        -0.04778062, -0.04206007, -0.02086318, -0.14055874, -0.03319212,\n",
      "        -0.02205688, -0.03078706, -0.07959772, -0.04206007, -0.03615183,\n",
      "        -0.06060742, -0.02086318, -0.04804892, -0.03720136, -0.02580434,\n",
      "        -0.02373533,  0.33695676, -0.04175364, -0.02205688])\n",
      " array([0], dtype=int64)]\n",
      "[array([ 1.14537681,  1.19165032, -0.38538288, -2.66334606, -1.59335187,\n",
      "        -0.14593585, -0.2175757 , -0.03492533, -0.39584132, -0.02771973,\n",
      "         1.08534887, -0.11269381, -0.70156267, -0.17891851, -0.179527  ,\n",
      "        -0.24508517, -0.36159104, -0.01678105, -0.37649823, -0.37618802,\n",
      "        -0.17815534, -0.21117047,  3.91423297, -0.33653279, -0.07082154,\n",
      "        -0.38135638, -0.14300071, -0.35746063, -0.17351455, -0.22532901,\n",
      "         1.2134038 , -0.58987209, -0.17654328, -0.42836007, -0.34117932,\n",
      "        -0.22419805, -0.24449789, -0.1728875 , -0.26401111, -0.0159999 ,\n",
      "         0.66348609, -0.18939262, -0.29443044, -0.20406156, -0.02086318,\n",
      "        -0.09870466, -0.17792583, -0.32481669, -0.09115626,  0.41017233,\n",
      "        -0.70282207,  0.70282207, -0.13427492, -0.02426908, -0.0595346 ,\n",
      "        -0.04962853, -0.03986597, -0.05456777, -0.04501058, -0.02994265,\n",
      "        -0.05732963, -0.04831574, -0.02771973, -0.0639213 , -0.031609  ,\n",
      "        -0.04296634, -0.03888801,  0.        , -0.02086318, -0.02426908,\n",
      "        -0.02024   , -0.05456777, -0.03615183, -0.02771973, -0.04414598,\n",
      "        -0.04778062, -0.04206007, -0.02086318, -0.14055874, -0.03319212,\n",
      "        -0.02205688, -0.03078706, -0.07959772, -0.04206007, -0.03615183,\n",
      "        -0.06060742, -0.02086318, -0.04804892, -0.03720136, -0.02580434,\n",
      "        -0.02373533,  0.33695676, -0.04175364, -0.02205688])\n",
      " array([0], dtype=int64)]\n",
      "[array([-1.6264658 , -0.77481065, -0.53808535, -0.5949133 ,  0.35429863,\n",
      "        -0.14593585, -0.2175757 , -0.03492533, -0.39584132, -0.02771973,\n",
      "        -0.92136273, -0.11269381,  1.4253894 , -0.17891851, -0.179527  ,\n",
      "        -0.24508517, -0.36159104, -0.01678105, -0.37649823,  2.6582452 ,\n",
      "        -0.17815534, -0.21117047, -0.2554779 , -0.33653279, -0.07082154,\n",
      "        -0.38135638, -0.14300071, -0.35746063, -0.17351455, -0.22532901,\n",
      "        -0.82412796,  1.69528279, -0.17654328, -0.42836007, -0.34117932,\n",
      "        -0.22419805, -0.24449789, -0.1728875 , -0.26401111, -0.0159999 ,\n",
      "        -1.50719061, -0.18939262, -0.29443044,  4.90048209, -0.02086318,\n",
      "        -0.09870466, -0.17792583,  3.07865949, -0.09115626, -2.43799963,\n",
      "         1.42283523, -1.42283523, -0.13427492, -0.02426908, -0.0595346 ,\n",
      "        -0.04962853, -0.03986597, -0.05456777, -0.04501058, -0.02994265,\n",
      "        -0.05732963, -0.04831574, -0.02771973, 15.64423659, -0.031609  ,\n",
      "        -0.04296634, -0.03888801,  0.        , -0.02086318, -0.02426908,\n",
      "        -0.02024   , -0.05456777, -0.03615183, -0.02771973, -0.04414598,\n",
      "        -0.04778062, -0.04206007, -0.02086318, -0.14055874, -0.03319212,\n",
      "        -0.02205688, -0.03078706, -0.07959772, -0.04206007, -0.03615183,\n",
      "        -0.06060742, -0.02086318, -0.04804892, -0.03720136, -0.02580434,\n",
      "        -0.02373533, -2.96773987, -0.04175364, -0.02205688])\n",
      " array([0], dtype=int64)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 94), (None, 1)), types: (tf.float64, tf.int64)>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#process and batch the training data for each client\n",
    "clients_batched = dict()\n",
    "for (client_name, data) in clients.items():\n",
    "    print(data[0])\n",
    "    clients_batched[client_name] = batch_data(data)\n",
    "    \n",
    "#process and batch the test set  \n",
    "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))\n",
    "test_batched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9dcf2ff7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:54.568193Z",
     "start_time": "2021-07-15T23:59:54.564443Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleMLP:\n",
    "    @staticmethod\n",
    "    def build(shape, classes=2 , learning_rate = 0.001, metric = \"accuracy\"):\n",
    "\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128, input_shape = (shape,)))\n",
    "#         model.add(Dense(128, Activation(\"relu\")))\n",
    "#         model.add(Dense(64, Activation(\"relu\")))\n",
    "#         model.add(Dense(32, Activation(\"relu\")))\n",
    "#         model.add(Dense(1))\n",
    "        \n",
    "        model.add(Dense(128, Activation(\"tanh\")))\n",
    "        model.add(Dense(64, Activation(\"tanh\")))\n",
    "        model.add(Dense(32, Activation(\"tanh\")))\n",
    "        model.add(Dense(1,Activation('sigmoid')))\n",
    "        \n",
    "\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f71dc14a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:00:30.156165Z",
     "start_time": "2021-07-16T00:00:30.152576Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.005\n",
    "comms_round = 3\n",
    "loss=tf.keras.losses.BinaryCrossentropy(from_logits = False)\n",
    "\n",
    "metrics = ['binary_accuracy']\n",
    "\n",
    "optimizer = SGD(learning_rate=lr, \n",
    "                decay=lr / comms_round, \n",
    "                momentum=0.5\n",
    "               )     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "eebf9376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:00:30.412962Z",
     "start_time": "2021-07-16T00:00:30.399142Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def weight_scalling_factor(clients_trn_data, client_name):\n",
    "    client_names = list(clients_trn_data.keys())\n",
    "    #get the bs\n",
    "    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
    "    #first calculate the total training data points across clinets\n",
    "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n",
    "    # get the total number of data points held by a client\n",
    "    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n",
    "    return local_count/global_count\n",
    "\n",
    "\n",
    "def scale_model_weights(weight, scalar):\n",
    "    '''function for scaling a models weights'''\n",
    "    weight_final = []\n",
    "    steps = len(weight)\n",
    "    for i in range(steps):\n",
    "        weight_final.append(scalar * weight[i])\n",
    "    return weight_final\n",
    "\n",
    "\n",
    "\n",
    "def sum_scaled_weights(scaled_weight_list):\n",
    "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
    "    avg_grad = list()\n",
    "    #get the average grad accross all client gradients\n",
    "#     print(len(scaled_weight_list))\n",
    "    for grad_list_tuple in zip(*scaled_weight_list):\n",
    "#         print(len(grad_list_tuple))\n",
    "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
    "        avg_grad.append(layer_mean)\n",
    "        \n",
    "    return avg_grad\n",
    "\n",
    "\n",
    "def test_model(X_test, Y_test,  model, comm_round):\n",
    "    \n",
    "#     cce = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "#     cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    logits = model.predict(X_test)\n",
    "\n",
    "    score = global_model.evaluate(X_test, y_test, verbose=0)\n",
    "    acc = score[1] ; loss = score[0]\n",
    "    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n",
    "\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4aef41d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:01:47.756094Z",
     "start_time": "2021-07-16T00:00:30.586083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 2ms/step - loss: 0.5894 - binary_accuracy: 0.6855\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6728 - binary_accuracy: 0.6166\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.6084 - binary_accuracy: 0.6619\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6228 - binary_accuracy: 0.6565\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6558 - binary_accuracy: 0.6317\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.6572 - binary_accuracy: 0.6281\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.6694 - binary_accuracy: 0.6081\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8118 - binary_accuracy: 0.4583\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8439 - binary_accuracy: 0.4305\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7368 - binary_accuracy: 0.5510\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.7380 - binary_accuracy: 0.5488\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.6743 - binary_accuracy: 0.6070\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.7718 - binary_accuracy: 0.5134\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7366 - binary_accuracy: 0.5379\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.8507 - binary_accuracy: 0.4531WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0154s). Check your callbacks.\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7833 - binary_accuracy: 0.5181\n",
      "comm_round: 0 | global_acc: 72.819% | global_loss: 0.5451096296310425\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5276 - binary_accuracy: 0.7416\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5013 - binary_accuracy: 0.7665\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.5079 - binary_accuracy: 0.7505\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5465 - binary_accuracy: 0.7060\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.5025 - binary_accuracy: 0.7601\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5151 - binary_accuracy: 0.7451\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.5144 - binary_accuracy: 0.7544\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5173 - binary_accuracy: 0.7561\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.5053 - binary_accuracy: 0.7573\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5267 - binary_accuracy: 0.7338\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5200 - binary_accuracy: 0.7498\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5072 - binary_accuracy: 0.7564\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5505 - binary_accuracy: 0.7183\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5204 - binary_accuracy: 0.7540\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.5249 - binary_accuracy: 0.7561\n",
      "comm_round: 1 | global_acc: 77.181% | global_loss: 0.48599666357040405\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4693 - binary_accuracy: 0.7737\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.4652 - binary_accuracy: 0.7904\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4648 - binary_accuracy: 0.7866\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4795 - binary_accuracy: 0.7749\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.4776 - binary_accuracy: 0.7767\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.5003 - binary_accuracy: 0.7188WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0105s). Check your callbacks.\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4658 - binary_accuracy: 0.7948\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4699 - binary_accuracy: 0.7843\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4748 - binary_accuracy: 0.7845\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4808 - binary_accuracy: 0.7869\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.4679 - binary_accuracy: 0.7855\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4674 - binary_accuracy: 0.7760\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4932 - binary_accuracy: 0.7535\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.4688 - binary_accuracy: 0.7843\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4910 - binary_accuracy: 0.7756\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.4747 - binary_accuracy: 0.7888\n",
      "comm_round: 2 | global_acc: 79.156% | global_loss: 0.4589189887046814\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#initialize global model\n",
    "smlp_global = SimpleMLP()\n",
    "global_model = smlp_global.build(X_train.shape[1] ,classes=2)\n",
    "global_model.compile(optimizer=optimizer, loss=loss, metrics=metrics) \n",
    "\n",
    "        \n",
    "#commence global training loop\n",
    "for comm_round in range(comms_round):\n",
    "            \n",
    "    # get the global model's weights - will serve as the initial weights for all local models\n",
    "    global_weights = global_model.get_weights()\n",
    "    \n",
    "    #initial list to collect local model weights after scalling\n",
    "    scaled_local_weight_list = list()\n",
    "\n",
    "    #randomize client data - using keys\n",
    "    client_names= list(clients_batched.keys())\n",
    "    random.shuffle(client_names)\n",
    "    \n",
    "    #loop through each client and create new local model\n",
    "    for client in client_names:\n",
    "        smlp_local = SimpleMLP()\n",
    "        local_model = smlp_local.build(X_train.shape[1],classes=2)\n",
    "        local_model.compile(loss=loss, \n",
    "                      optimizer=optimizer, \n",
    "                      metrics=metrics)\n",
    "        \n",
    "        #set local model weight to the weight of the global model\n",
    "        local_model.set_weights(global_weights)\n",
    "        \n",
    "        #fit local model with client's data\n",
    "        local_model.fit(clients_batched[client], epochs=1, verbose=1)\n",
    "        \n",
    "#         get client acc, loss\n",
    "#         client_score = local_model.evaluate()\n",
    "#         print(metrics)\n",
    "        \n",
    "        #scale the model weights and add to list\n",
    "        scaling_factor = weight_scalling_factor(clients_batched, client)\n",
    "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "        scaled_local_weight_list.append(scaled_weights)\n",
    "        \n",
    "        #clear session to free memory after each communication round\n",
    "        K.clear_session()\n",
    "        \n",
    "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "    \n",
    "    #update global model \n",
    "    global_model.set_weights(average_weights)\n",
    "\n",
    "#     test global model and print out metrics after each communications round\n",
    "    for(X_test, Y_test) in test_batched:\n",
    "        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670d1d42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:03:08.033027Z",
     "start_time": "2021-07-16T00:03:07.867893Z"
    }
   },
   "outputs": [],
   "source": [
    "score = global_model.evaluate(X_test, y_test, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcaa73e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:03:08.653744Z",
     "start_time": "2021-07-16T00:03:08.484057Z"
    }
   },
   "outputs": [],
   "source": [
    "nn_preds = global_model.predict(X_test)\n",
    "nn_preds = (nn_preds > 0.5)\n",
    "\n",
    "nn_precision =precision_score(y_test, nn_preds)\n",
    "nn_recall = recall_score(y_test, nn_preds)\n",
    "nn_accuracy = accuracy_score(y_test, nn_preds)\n",
    "nn_f1 = f1_score(y_test, nn_preds)\n",
    "\n",
    "\n",
    "print(\"Precision = {}\".format(nn_precision))\n",
    "print(\"Recall = {}\".format(nn_recall))\n",
    "print(\"Accuracy = {}\".format(nn_accuracy))\n",
    "print(\"f1 = {}\".format(nn_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6360dd5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:03:09.275052Z",
     "start_time": "2021-07-16T00:03:09.268152Z"
    }
   },
   "outputs": [],
   "source": [
    "arr = nn_preds > 0.5\n",
    "\n",
    "unique, counts = np.unique(arr, return_counts=True)\n",
    "\n",
    "np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a5ee99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T19:56:25.650336Z",
     "start_time": "2021-07-14T19:56:25.620Z"
    }
   },
   "outputs": [],
   "source": [
    "# pdf for client losses\n",
    "# x-loss\n",
    "# y- frequency\n",
    "# each client has one pdf for all rounds\n",
    "# using histogram\n",
    "\n",
    "\n",
    "# drop client\n",
    "# non iid\n",
    "# fedavg\n",
    "\n",
    "\n",
    "# gender dist"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
