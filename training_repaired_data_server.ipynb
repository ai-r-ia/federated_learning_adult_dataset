{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cb54a96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T12:48:49.512456Z",
     "start_time": "2021-07-15T12:48:46.946937Z"
    }
   },
   "source": [
    "Using repaired data to calculate new losses and accuracies for each client.\n",
    "\n",
    "The new training data is taken from 'Data/train_data_repaired.csv'. This has been saved in the file 'data_repairing.ipynb'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09b7dd46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:57:57.590963Z",
     "start_time": "2021-07-15T23:57:57.572204Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.metrics import precision_score,recall_score, accuracy_score,confusion_matrix,f1_score\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import History\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00b9bf6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:52.574848Z",
     "start_time": "2021-07-15T23:59:52.208912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "### Train/Test Data seperation\n",
    "\n",
    "file_out = pd.read_csv('Data/adult_processed.csv')\n",
    "file_out_repaired = pd.read_csv('Data/train_data_repaired.csv')\n",
    "cols = []\n",
    "cols_train = []\n",
    "for i in list(file_out.columns):\n",
    "    if  i != 'income':\n",
    "        cols.append(i)\n",
    "        \n",
    "for i in list(file_out_repaired.columns):\n",
    "    if  i != 'income':\n",
    "        cols_train.append(i)\n",
    "\n",
    "feature_set1 = pd.read_csv('Data/train_data_repaired.csv')\n",
    "feature_set2 = pd.read_csv('Data/test.csv')\n",
    "\n",
    "x = feature_set1[cols_train].copy().values\n",
    "y = feature_set1[['income']].copy().values\n",
    "        \n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(x)\n",
    "y_train = y\n",
    "\n",
    "x2 = feature_set2[cols].copy().values\n",
    "y2 = feature_set2[['income']].copy().values\n",
    "        \n",
    "X_test = sc.fit_transform(x2)\n",
    "y_test = y2\n",
    "\n",
    "\n",
    "# X_test.shape, y_test.shape \n",
    "if cols == cols_train:\n",
    "    print(\"yes\")\n",
    "# diff = np.setdiff1d(cols_train,cols)\n",
    "# diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f5af00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 10 # enter NUMBER OF CLIENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76379dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender split\n",
    "\n",
    "dict_users = {i: np.array([]) for i in range(num_clients)} \n",
    "data_out = []\n",
    "\n",
    "def create_hetero_clients( image_list, label_list, start_client = 0, num_clients=10, initial='clients'):\n",
    "    \n",
    "    selected_inds = []\n",
    "\n",
    "    max_y = np.argmax(label_list, axis=-1)\n",
    "    sorted_zip = sorted(zip(max_y, label_list, image_list), key=lambda x: x[0])\n",
    "    data = [(x,y) for _,y,x in sorted_zip]\n",
    "    \n",
    "    data_out = data\n",
    "    \n",
    "    num_shards, num_imgs = int(len(image_list)/30), 30\n",
    "    idx_shard = [i for i in range(num_shards)]\n",
    "\n",
    "    min_shard = 1\n",
    "    max_shard = 60  #953/15 = 63.53\n",
    "    \n",
    "    random_shard_size = np.random.randint(min_shard, max_shard+1,\n",
    "                                          size=(num_clients-start_client))\n",
    "    random_shard_size = np.around(random_shard_size /\n",
    "                                  sum(random_shard_size) * num_shards)\n",
    "    random_shard_size = random_shard_size.astype(int)\n",
    "\n",
    "\n",
    "    if sum(random_shard_size) > num_shards:\n",
    "        \n",
    "        for i in range(start_client, num_clients):\n",
    "            # First assign each client 1 shard to ensure every client has\n",
    "            # atleast one shard of data\n",
    "            rand_set = set(np.random.choice(idx_shard, 1, replace=False))\n",
    "            idx_shard = list(set(idx_shard) - rand_set)\n",
    "            for rand in rand_set:\n",
    "                ind1 = rand*num_imgs\n",
    "                ind2 = (rand+1)*num_imgs\n",
    "                if(len(dict_users[i]) == 0):\n",
    "                    dict_users[i] = data[ind1: ind2]\n",
    "                else:\n",
    "                    dict_users[i] = np.concatenate(\n",
    "                    (dict_users[i],data[ind1: ind2]),\n",
    "                    axis=0)\n",
    "                selected_inds.extend([[ind1, ind2]])\n",
    "\n",
    "        random_shard_size = random_shard_size-1\n",
    "\n",
    "        # Next, randomly assign the remaining shards\n",
    "        for i in range(start_client, num_clients):\n",
    "            if len(idx_shard) == 0:\n",
    "                continue\n",
    "#             print(random_shard_size)\n",
    "            shard_size = random_shard_size[i-start_client]\n",
    "            if shard_size > len(idx_shard):\n",
    "                shard_size = len(idx_shard)\n",
    "            rand_set = set(np.random.choice(idx_shard, shard_size,\n",
    "                                            replace=False))\n",
    "            idx_shard = list(set(idx_shard) - rand_set)\n",
    "            for rand in rand_set:\n",
    "                ind1 = rand*num_imgs\n",
    "                ind2 = (rand+1)*num_imgs\n",
    "                if(len(dict_users[i]) == 0):\n",
    "                    dict_users[i] = data[ind1: ind2]\n",
    "                else:\n",
    "                    dict_users[i] = np.concatenate(\n",
    "                    (dict_users[i],data[ind1: ind2]),\n",
    "                    axis=0)\n",
    "                selected_inds.extend([[ind1, ind2]])\n",
    "\n",
    "    else:\n",
    "\n",
    "        for i in range(start_client, num_clients):\n",
    "#             print(random_shard_size)\n",
    "            shard_size = random_shard_size[i-start_client]\n",
    "#             shard_size = random_shard_size[int(i/len(random_shard_size)) - 1]\n",
    "            rand_set = set(np.random.choice(idx_shard, shard_size,\n",
    "                                            replace=False))\n",
    "            idx_shard = list(set(idx_shard) - rand_set)\n",
    "            for rand in rand_set:\n",
    "                ind1 = rand*num_imgs\n",
    "                ind2 = (rand+1)*num_imgs\n",
    "                if(len(dict_users[i]) == 0):\n",
    "                    dict_users[i] = data[ind1: ind2]\n",
    "                else:\n",
    "                    dict_users[i] = np.concatenate(\n",
    "                    (dict_users[i],data[ind1: ind2]),\n",
    "                    axis=0)\n",
    "                selected_inds.extend([[ind1, ind2]])\n",
    "\n",
    "        if len(idx_shard) > 0:\n",
    "            # Add the leftover shards to the client with minimum images:\n",
    "            shard_size = len(idx_shard)\n",
    "            # Add the remaining shard to the client with lowest data\n",
    "            k = min(dict_users, key=lambda x: len(dict_users.get(x)))\n",
    "            rand_set = set(np.random.choice(idx_shard, shard_size,\n",
    "                                            replace=False))\n",
    "            idx_shard = list(set(idx_shard) - rand_set)\n",
    "            for rand in rand_set:\n",
    "                ind1 = rand*num_imgs\n",
    "                ind2 = (rand+1)*num_imgs\n",
    "                if(len(dict_users[k]) == 0):\n",
    "                    dict_users[k] = data[ind1: ind2]\n",
    "                else:\n",
    "                    dict_users[k] = np.concatenate(\n",
    "                    (dict_users[k],data[ind1: ind2]),\n",
    "                    axis=0)\n",
    "                selected_inds.extend([[ind1, ind2]])\n",
    "                \n",
    "                \n",
    "    return dict_users, selected_inds, data_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cdec0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_users = {i: np.array([]) for i in range(4)}\n",
    "\n",
    "def create_client_iid(image_list, label_list, client_num):    \n",
    "    max_y = np.argmax(label_list, axis=-1)\n",
    "    sorted_zip = sorted(zip(max_y, label_list, image_list), key=lambda x: x[0])\n",
    "    data = [(x,y) for _,y,x in sorted_zip]\n",
    "    \n",
    "    dict_users[client_num] = data\n",
    "    \n",
    "    return dict_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb1235d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializer_income():\n",
    "    \n",
    "    x_feats = feature_set1[cols_train].copy().values\n",
    "    y_feats = feature_set1[['income']].copy().values\n",
    "\n",
    "    X_train_new = sc.fit_transform(x_feats)\n",
    "    y_train_new = y_feats\n",
    "\n",
    "    \n",
    "    return [X_train_new, y_train_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4278841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hetero_clients_gender(train_sets):\n",
    "    \n",
    "    data = list(zip(train_sets[0], train_sets[1]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "#     print(type(train_sets), type(train_sets[0]),type(list(list(zip(*data))[0]) ), type(data))\n",
    "    \n",
    "    train_sets[0] = list(list(zip(*data))[0])\n",
    "    train_sets[1] = list(list(zip(*data))[1])\n",
    "    \n",
    "    \n",
    "    # NON_IID\n",
    "    clients, inds, data_out1 = create_hetero_clients(train_sets[0], train_sets[1], start_client = 0, num_clients=10, initial='client') \n",
    "    \n",
    "    \n",
    "\n",
    "# #     IID\n",
    "#     clients = create_client_iid(train_sets[0], train_sets[1], 0)\n",
    "    \n",
    "#     clients2 = create_client_iid(train_sets[2], train_sets[3], 1)\n",
    "#     clients = {**clients, **clients2}\n",
    "    \n",
    "#     clients3 = create_client_iid(train_sets[4], train_sets[5], 2)\n",
    "#     clients = {**clients, **clients3}\n",
    "    \n",
    "#     clients4 = create_client_iid(train_sets[6], train_sets[7], 3)\n",
    "#     clients = {**clients, **clients4}\n",
    "    \n",
    "\n",
    "    \n",
    "    return clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "715ed657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:52.579114Z",
     "start_time": "2021-07-15T23:59:52.576244Z"
    }
   },
   "outputs": [],
   "source": [
    "# take bs = 128 for 5 clients and 10 rounds\n",
    "def batch_data(data_shard, bs=64):\n",
    "    '''Takes in a clients data shard and create a tfds object off it\n",
    "    args:\n",
    "        shard: a data, label constituting a client's data shard\n",
    "        bs:batch size\n",
    "    return:\n",
    "        tfds object'''\n",
    "    data = []\n",
    "    label = []\n",
    "    for x in data_shard:\n",
    "        data.append(x[0])\n",
    "        label.append(x[1])\n",
    "    #seperate shard into data and labels lists\n",
    "#     data, label = zip(*data_shard)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
    "#     print( label[0])\n",
    "    return dataset.shuffle(len(label)).batch(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfd80728",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:54.563066Z",
     "start_time": "2021-07-15T23:59:52.773340Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#process and batch the training data for each client\n",
    "def batch_clients(clients):\n",
    "    clients_batched = dict()\n",
    "    for (client_name, data) in clients.items():\n",
    "#         print(\"data \",len(data))\n",
    "        clients_batched[client_name] = batch_data(data,126)#non-IID\n",
    "#         clients_batched[client_name] = batch_data(data,1) #IID\n",
    "    \n",
    "\n",
    "    #process and batch the test set  \n",
    "    test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))\n",
    "    \n",
    "#     test_batched\n",
    "    return clients_batched, test_batched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9dcf2ff7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:54.568193Z",
     "start_time": "2021-07-15T23:59:54.564443Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleMLP:\n",
    "    @staticmethod\n",
    "    def build(shape, classes=2 , learning_rate = 0.001, metric = \"accuracy\"):\n",
    "\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128, input_shape = (shape,)))\n",
    "#         model.add(Dense(128, Activation(\"relu\")))\n",
    "#         model.add(Dense(64, Activation(\"relu\")))\n",
    "#         model.add(Dense(32, Activation(\"relu\")))\n",
    "#         model.add(Dense(1))\n",
    "        \n",
    "        model.add(Dense(128, Activation(\"tanh\")))\n",
    "        model.add(Dense(64, Activation(\"tanh\")))\n",
    "        model.add(Dense(32, Activation(\"tanh\")))\n",
    "        model.add(Dense(1,Activation('sigmoid')))\n",
    "        \n",
    "\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f71dc14a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:00:30.156165Z",
     "start_time": "2021-07-16T00:00:30.152576Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.005\n",
    "comms_round = 10\n",
    "loss=tf.keras.losses.BinaryCrossentropy(from_logits = False)\n",
    "\n",
    "metrics = ['binary_accuracy']\n",
    "\n",
    "optimizer = SGD(learning_rate=lr, \n",
    "                decay=lr / comms_round, \n",
    "                momentum=0.5\n",
    "               )     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eebf9376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:00:30.412962Z",
     "start_time": "2021-07-16T00:00:30.399142Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def weight_scalling_factor(clients_trn_data, client_name):\n",
    "    client_names = list(clients_trn_data.keys())\n",
    "    #get the bs\n",
    "    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
    "    #first calculate the total training data points across clinets\n",
    "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n",
    "    # get the total number of data points held by a client\n",
    "    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n",
    "    return local_count/global_count\n",
    "\n",
    "\n",
    "def scale_model_weights(weight, scalar):\n",
    "    '''function for scaling a models weights'''\n",
    "    weight_final = []\n",
    "    steps = len(weight)\n",
    "    for i in range(steps):\n",
    "        weight_final.append(scalar * weight[i])\n",
    "    return weight_final\n",
    "\n",
    "\n",
    "\n",
    "def sum_scaled_weights(scaled_weight_list):\n",
    "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
    "    avg_grad = list()\n",
    "    #get the average grad accross all client gradients\n",
    "#     print(len(scaled_weight_list))\n",
    "    for grad_list_tuple in zip(*scaled_weight_list):\n",
    "#         print(len(grad_list_tuple))\n",
    "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
    "        avg_grad.append(layer_mean)\n",
    "        \n",
    "    return avg_grad\n",
    "\n",
    "\n",
    "def test_model(X_test, Y_test,  model, comm_round):\n",
    "    \n",
    "#     cce = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "#     cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    logits = model.predict(X_test)\n",
    "\n",
    "    score = global_model.evaluate(X_test, y_test, verbose=0)\n",
    "    acc = score[1] ; loss = score[0]\n",
    "    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n",
    "\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4aef41d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:01:47.756094Z",
     "start_time": "2021-07-16T00:00:30.586083Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6203 - binary_accuracy: 0.6683\n",
      "client 4 loss --> [0.6202557682991028] freq-> [40] accuracy-> [0.6682634949684143]\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6351 - binary_accuracy: 0.6442\n",
      "client 3 loss --> [0.635094940662384] freq-> [27] accuracy-> [0.6442477703094482]\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.6237 - binary_accuracy: 0.6683\n",
      "client 9 loss --> [0.6237065196037292] freq-> [35] accuracy-> [0.6682758331298828]\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6539 - binary_accuracy: 0.6157\n",
      "client 0 loss --> [0.6539333462715149] freq-> [25] accuracy-> [0.615686297416687]\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.6265 - binary_accuracy: 0.6600\n",
      "client 5 loss --> [0.6264776587486267] freq-> [35] accuracy-> [0.6600000262260437]\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6559 - binary_accuracy: 0.6102\n",
      "client 7 loss --> [0.6558573246002197] freq-> [24] accuracy-> [0.6102041006088257]\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6375 - binary_accuracy: 0.6460\n",
      "client 6 loss --> [0.6375010013580322] freq-> [28] accuracy-> [0.6459770202636719]\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6063 - binary_accuracy: 0.6815\n",
      "client 2 loss --> [0.6063247919082642] freq-> [50] accuracy-> [0.6814814805984497]\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6773\n",
      "client 8 loss --> [0.6151722073554993] freq-> [42] accuracy-> [0.6773333549499512]\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6939 - binary_accuracy: 0.5216\n",
      "client 1 loss --> [0.6939122080802917] freq-> [9] accuracy-> [0.5215686559677124]\n",
      "comm_round: 0 | global_acc: 75.491% | global_loss: 0.5701592564582825\n",
      "global_loss_list:  [0.5701592564582825]\n",
      "global_acc_list:  [0.7549139857292175]\n",
      "global_freq_list:  [315]\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5050 - binary_accuracy: 0.7859\n",
      "client 7 loss --> [0.65585732 0.50503105] freq-> [24 66] accuracy-> [0.6102041  0.78588808]\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5219 - binary_accuracy: 0.7974\n",
      "client 6 loss --> [0.637501   0.52189416] freq-> [28 31] accuracy-> [0.64597702 0.79741603]\n",
      "82/82 [==============================] - 0s 3ms/step - loss: 0.4896 - binary_accuracy: 0.8010\n",
      "client 8 loss --> [0.61517221 0.48960963] freq-> [42 82] accuracy-> [0.67733335 0.80097753]\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.4911 - binary_accuracy: 0.7972\n",
      "client 4 loss --> [0.62025577 0.49111667] freq-> [40 84] accuracy-> [0.66826349 0.79723018]\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5066 - binary_accuracy: 0.7943\n",
      "client 3 loss --> [0.63509494 0.50661135] freq-> [27 55] accuracy-> [0.64424777 0.79427314]\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.5029 - binary_accuracy: 0.7902\n",
      "client 9 loss --> [0.62370652 0.50292283] freq-> [35 67] accuracy-> [0.66827583 0.79016787]\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5431 - binary_accuracy: 0.7728\n",
      "client 1 loss --> [0.69391221 0.54309642] freq-> [ 9 20] accuracy-> [0.52156866 0.77283949]\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.4959 - binary_accuracy: 0.7894\n",
      "client 5 loss --> [0.62647766 0.49592587] freq-> [35 81] accuracy-> [0.66000003 0.78941178]\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.5119 - binary_accuracy: 0.7874\n",
      "client 0 loss --> [0.65393335 0.51186442] freq-> [25 60] accuracy-> [0.6156863  0.78736562]\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.5004 - binary_accuracy: 0.7957\n",
      "client 2 loss --> [0.60632479 0.50043565] freq-> [50 81] accuracy-> [0.68148148 0.7957468 ]\n",
      "comm_round: 1 | global_acc: 80.467% | global_loss: 0.46940603852272034\n",
      "global_loss_list:  [0.5701592564582825, 0.46940603852272034]\n",
      "global_acc_list:  [0.7549139857292175, 0.8046683073043823]\n",
      "global_freq_list:  [315, 627]\n",
      "82/82 [==============================] - 0s 3ms/step - loss: 0.4299 - binary_accuracy: 0.8180\n",
      "client 5 loss --> [0.62647766 0.49592587 0.42992544] freq-> [35 81 82] accuracy-> [0.66000003 0.78941178 0.81802326]\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 0.4228 - binary_accuracy: 0.8219\n",
      "client 8 loss --> [0.61517221 0.48960963 0.42281955] freq-> [ 42  82 119] accuracy-> [0.67733335 0.80097753 0.8219316 ]\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.4348 - binary_accuracy: 0.8225\n",
      "client 3 loss --> [0.63509494 0.50661135 0.43480867] freq-> [27 55 67] accuracy-> [0.64424777 0.79427314 0.82253855]\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4308 - binary_accuracy: 0.8187\n",
      "client 0 loss --> [0.65393335 0.51186442 0.43077743] freq-> [25 60 98] accuracy-> [0.6156863  0.78736562 0.81866342]\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4406 - binary_accuracy: 0.8241\n",
      "client 6 loss --> [0.637501   0.52189416 0.44061247] freq-> [28 31 32] accuracy-> [0.64597702 0.79741603 0.82412934]\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4329 - binary_accuracy: 0.8227\n",
      "client 1 loss --> [0.69391221 0.54309642 0.43285936] freq-> [ 9 20 66] accuracy-> [0.52156866 0.77283949 0.82274365]\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.4218 - binary_accuracy: 0.8241\n",
      "client 9 loss --> [0.62370652 0.50292283 0.42179424] freq-> [ 35  67 120] accuracy-> [0.66827583 0.79016787 0.82408518]\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.4310 - binary_accuracy: 0.8148\n",
      "client 7 loss --> [0.65585732 0.50503105 0.43097213] freq-> [ 24  66 124] accuracy-> [0.6102041  0.78588808 0.8148362 ]\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.4253 - binary_accuracy: 0.8211\n",
      "client 4 loss --> [0.62025577 0.49111667 0.42532605] freq-> [ 40  84 140] accuracy-> [0.66826349 0.79723018 0.82108259]\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.4365 - binary_accuracy: 0.8165\n",
      "client 2 loss --> [0.60632479 0.50043565 0.43652692] freq-> [50 81 86] accuracy-> [0.68148148 0.7957468  0.81652737]\n",
      "comm_round: 2 | global_acc: 82.166% | global_loss: 0.4193616211414337\n",
      "global_loss_list:  [0.5701592564582825, 0.46940603852272034, 0.4193616211414337]\n",
      "global_acc_list:  [0.7549139857292175, 0.8046683073043823, 0.8216625452041626]\n",
      "global_freq_list:  [315, 627, 934]\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3980 - binary_accuracy: 0.8221\n",
      "client 7 loss --> [0.65585732 0.50503105 0.43097213 0.39798313] freq-> [ 24  66 124 125] accuracy-> [0.6102041  0.78588808 0.8148362  0.82211602]\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.3897 - binary_accuracy: 0.8292\n",
      "client 5 loss --> [0.62647766 0.49592587 0.42992544 0.38967666] freq-> [ 35  81  82 118] accuracy-> [0.66000003 0.78941178 0.81802326 0.82921726]\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3960 - binary_accuracy: 0.8276\n",
      "client 0 loss --> [0.65393335 0.51186442 0.43077743 0.39603257] freq-> [ 25  60  98 107] accuracy-> [0.6156863  0.78736562 0.81866342 0.82760417]\n",
      "177/177 [==============================] - 1s 3ms/step - loss: 0.3878 - binary_accuracy: 0.8305\n",
      "client 9 loss --> [0.62370652 0.50292283 0.42179424 0.38782564] freq-> [ 35  67 120 177] accuracy-> [0.66827583 0.79016787 0.82408518 0.83049935]\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.3898 - binary_accuracy: 0.8327\n",
      "client 1 loss --> [0.69391221 0.54309642 0.43285936 0.38982385] freq-> [  9  20  66 128] accuracy-> [0.52156866 0.77283949 0.82274365 0.83271027]\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3947 - binary_accuracy: 0.8361\n",
      "client 6 loss --> [0.637501   0.52189416 0.44061247 0.39473754] freq-> [28 31 32 35] accuracy-> [0.64597702 0.79741603 0.82412934 0.83605444]\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 0.3900 - binary_accuracy: 0.8293\n",
      "client 8 loss --> [0.61517221 0.48960963 0.42281955 0.39003098] freq-> [ 42  82 119 158] accuracy-> [0.67733335 0.80097753 0.8219316  0.82929295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173 [==============================] - 0s 3ms/step - loss: 0.3925 - binary_accuracy: 0.8287\n",
      "client 4 loss --> [0.62025577 0.49111667 0.42532605 0.39254719] freq-> [ 40  84 140 173] accuracy-> [0.66826349 0.79723018 0.82108259 0.82867682]\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.3978 - binary_accuracy: 0.8278\n",
      "client 3 loss --> [0.63509494 0.50661135 0.43480867 0.39777032] freq-> [27 55 67 84] accuracy-> [0.64424777 0.79427314 0.82253855 0.82780951]\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3936 - binary_accuracy: 0.8278\n",
      "client 2 loss --> [0.60632479 0.50043565 0.43652692 0.39356032] freq-> [ 50  81  86 140] accuracy-> [0.68148148 0.7957468  0.81652737 0.82776833]\n",
      "comm_round: 3 | global_acc: 82.463% | global_loss: 0.3947606086730957\n",
      "global_loss_list:  [0.5701592564582825, 0.46940603852272034, 0.4193616211414337, 0.3947606086730957]\n",
      "global_acc_list:  [0.7549139857292175, 0.8046683073043823, 0.8216625452041626, 0.8246314525604248]\n",
      "global_freq_list:  [315, 627, 934, 1245]\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.3697 - binary_accuracy: 0.8365\n",
      "client 1 loss --> [0.69391221 0.54309642 0.43285936 0.38982385 0.36973271] freq-> [  9  20  66 128 136] accuracy-> [0.52156866 0.77283949 0.82274365 0.83271027 0.8365497 ]\n",
      "184/184 [==============================] - 1s 4ms/step - loss: 0.3708 - binary_accuracy: 0.8356\n",
      "client 9 loss --> [0.62370652 0.50292283 0.42179424 0.38782564 0.37084198] freq-> [ 35  67 120 177 184] accuracy-> [0.66827583 0.79016787 0.82408518 0.83049935 0.83557856]\n",
      "213/213 [==============================] - 1s 3ms/step - loss: 0.3699 - binary_accuracy: 0.8349\n",
      "client 8 loss --> [0.61517221 0.48960963 0.42281955 0.39003098 0.36989185] freq-> [ 42  82 119 158 213] accuracy-> [0.67733335 0.80097753 0.8219316  0.82929295 0.83486718]\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.3771 - binary_accuracy: 0.8316\n",
      "client 0 loss --> [0.65393335 0.51186442 0.43077743 0.39603257 0.37713614] freq-> [ 25  60  98 107 155] accuracy-> [0.6156863  0.78736562 0.81866342 0.82760417 0.83163577]\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.3798 - binary_accuracy: 0.8256\n",
      "client 7 loss --> [0.65585732 0.50503105 0.43097213 0.39798313 0.37979713] freq-> [ 24  66 124 125 175] accuracy-> [0.6102041  0.78588808 0.8148362  0.82211602 0.82558137]\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.3768 - binary_accuracy: 0.8332\n",
      "client 3 loss --> [0.63509494 0.50661135 0.43480867 0.39777032 0.37680316] freq-> [27 55 67 84 95] accuracy-> [0.64424777 0.79427314 0.82253855 0.82780951 0.83316499]\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.3688 - binary_accuracy: 0.8345\n",
      "client 5 loss --> [0.62647766 0.49592587 0.42992544 0.38967666 0.36884952] freq-> [ 35  81  82 118 169] accuracy-> [0.66000003 0.78941178 0.81802326 0.82921726 0.83451366]\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.3729 - binary_accuracy: 0.8322\n",
      "client 2 loss --> [0.60632479 0.50043565 0.43652692 0.39356032 0.37285164] freq-> [ 50  81  86 140 195] accuracy-> [0.68148148 0.7957468  0.81652737 0.82776833 0.83219236]\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 0.3756 - binary_accuracy: 0.8330\n",
      "client 4 loss --> [0.62025577 0.49111667 0.42532605 0.39254719 0.37559977] freq-> [ 40  84 140 173 191] accuracy-> [0.66826349 0.79723018 0.82108259 0.82867682 0.833     ]\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3694 - binary_accuracy: 0.8390\n",
      "client 6 loss --> [0.637501   0.52189416 0.44061247 0.39473754 0.36935103] freq-> [28 31 32 35 43] accuracy-> [0.64597702 0.79741603 0.82412934 0.83605444 0.83895129]\n",
      "comm_round: 4 | global_acc: 82.811% | global_loss: 0.381920725107193\n",
      "global_loss_list:  [0.5701592564582825, 0.46940603852272034, 0.4193616211414337, 0.3947606086730957, 0.381920725107193]\n",
      "global_acc_list:  [0.7549139857292175, 0.8046683073043823, 0.8216625452041626, 0.8246314525604248, 0.8281121850013733]\n",
      "global_freq_list:  [315, 627, 934, 1245, 1556]\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 0.3615 - binary_accuracy: 0.8361\n",
      "client 2 loss --> [0.60632479 0.50043565 0.43652692 0.39356032 0.37285164 0.36149007] freq-> [ 50  81  86 140 195 209] accuracy-> [0.68148148 0.7957468  0.81652737 0.82776833 0.83219236 0.83614916]\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.3634 - binary_accuracy: 0.8356\n",
      "client 9 loss --> [0.62370652 0.50292283 0.42179424 0.38782564 0.37084198 0.3634156 ] freq-> [ 35  67 120 177 184 238] accuracy-> [0.66827583 0.79016787 0.82408518 0.83049935 0.83557856 0.83564025]\n",
      "184/184 [==============================] - 1s 4ms/step - loss: 0.3688 - binary_accuracy: 0.8293\n",
      "client 7 loss --> [0.65585732 0.50503105 0.43097213 0.39798313 0.37979713 0.36877707] freq-> [ 24  66 124 125 175 184] accuracy-> [0.6102041  0.78588808 0.8148362  0.82211602 0.82558137 0.82926404]\n",
      "215/215 [==============================] - 1s 3ms/step - loss: 0.3643 - binary_accuracy: 0.8356\n",
      "client 4 loss --> [0.62025577 0.49111667 0.42532605 0.39254719 0.37559977 0.36427131] freq-> [ 40  84 140 173 191 215] accuracy-> [0.66826349 0.79723018 0.82108259 0.82867682 0.833      0.83559006]\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.3580 - binary_accuracy: 0.8382\n",
      "client 5 loss --> [0.62647766 0.49592587 0.42992544 0.38967666 0.36884952 0.35799193] freq-> [ 35  81  82 118 169 193] accuracy-> [0.66000003 0.78941178 0.81802326 0.82921726 0.83451366 0.83820736]\n",
      "195/195 [==============================] - 1s 3ms/step - loss: 0.3659 - binary_accuracy: 0.8337\n",
      "client 0 loss --> [0.65393335 0.51186442 0.43077743 0.39603257 0.37713614 0.3659268 ] freq-> [ 25  60  98 107 155 195] accuracy-> [0.6156863  0.78736562 0.81866342 0.82760417 0.83163577 0.83370143]\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.3631 - binary_accuracy: 0.8378\n",
      "client 3 loss --> [0.63509494 0.50661135 0.43480867 0.39777032 0.37680316 0.36311427] freq-> [ 27  55  67  84  95 140] accuracy-> [0.64424777 0.79427314 0.82253855 0.82780951 0.83316499 0.83782709]\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3560 - binary_accuracy: 0.8415\n",
      "client 6 loss --> [0.637501   0.52189416 0.44061247 0.39473754 0.36935103 0.35601559] freq-> [28 31 32 35 43 64] accuracy-> [0.64597702 0.79741603 0.82412934 0.83605444 0.83895129 0.8415423 ]\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.3610 - binary_accuracy: 0.8364\n",
      "client 8 loss --> [0.61517221 0.48960963 0.42281955 0.39003098 0.36989185 0.36100185] freq-> [ 42  82 119 158 213 264] accuracy-> [0.67733335 0.80097753 0.8219316  0.82929295 0.83486718 0.83644044]\n",
      "164/164 [==============================] - 0s 3ms/step - loss: 0.3571 - binary_accuracy: 0.8407\n",
      "client 1 loss --> [0.69391221 0.54309642 0.43285936 0.38982385 0.36973271 0.35706112] freq-> [  9  20  66 128 136 164] accuracy-> [0.52156866 0.77283949 0.82274365 0.83271027 0.8365497  0.84070837]\n",
      "comm_round: 5 | global_acc: 83.057% | global_loss: 0.3745959401130676\n",
      "global_loss_list:  [0.5701592564582825, 0.46940603852272034, 0.4193616211414337, 0.3947606086730957, 0.381920725107193, 0.3745959401130676]\n",
      "global_acc_list:  [0.7549139857292175, 0.8046683073043823, 0.8216625452041626, 0.8246314525604248, 0.8281121850013733, 0.8305692076683044]\n",
      "global_freq_list:  [315, 627, 934, 1245, 1556, 1866]\n",
      "263/263 [==============================] - 1s 2ms/step - loss: 0.3530 - binary_accuracy: 0.8394\n",
      "client 2 loss --> [0.60632479 0.50043565 0.43652692 0.39356032 0.37285164 0.36149007\n",
      " 0.35296601] freq-> [ 50  81  86 140 195 209 263] accuracy-> [0.68148148 0.7957468  0.81652737 0.82776833 0.83219236 0.83614916\n",
      " 0.83941317]\n",
      "229/229 [==============================] - 0s 2ms/step - loss: 0.3613 - binary_accuracy: 0.8341\n",
      "client 7 loss --> [0.65585732 0.50503105 0.43097213 0.39798313 0.37979713 0.36877707\n",
      " 0.36126065] freq-> [ 24  66 124 125 175 184 229] accuracy-> [0.6102041  0.78588808 0.8148362  0.82211602 0.82558137 0.82926404\n",
      " 0.83406323]\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 0.3551 - binary_accuracy: 0.8388\n",
      "client 8 loss --> [0.61517221 0.48960963 0.42281955 0.39003098 0.36989185 0.36100185\n",
      " 0.35512322] freq-> [ 42  82 119 158 213 264 294] accuracy-> [0.67733335 0.80097753 0.8219316  0.82929295 0.83486718 0.83644044\n",
      " 0.83883023]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 3ms/step - loss: 0.3502 - binary_accuracy: 0.8423\n",
      "client 1 loss --> [0.69391221 0.54309642 0.43285936 0.38982385 0.36973271 0.35706112\n",
      " 0.35023496] freq-> [  9  20  66 128 136 164 178] accuracy-> [0.52156866 0.77283949 0.82274365 0.83271027 0.8365497  0.84070837\n",
      " 0.84229392]\n",
      "233/233 [==============================] - 1s 2ms/step - loss: 0.3595 - binary_accuracy: 0.8366\n",
      "client 4 loss --> [0.62025577 0.49111667 0.42532605 0.39254719 0.37559977 0.36427131\n",
      " 0.35949349] freq-> [ 40  84 140 173 191 215 233] accuracy-> [0.66826349 0.79723018 0.82108259 0.82867682 0.833      0.83559006\n",
      " 0.83661205]\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3577 - binary_accuracy: 0.8364\n",
      "client 0 loss --> [0.65393335 0.51186442 0.43077743 0.39603257 0.37713614 0.3659268\n",
      " 0.35767558] freq-> [ 25  60  98 107 155 195 250] accuracy-> [0.6156863  0.78736562 0.81866342 0.82760417 0.83163577 0.83370143\n",
      " 0.83635497]\n",
      "238/238 [==============================] - 1s 2ms/step - loss: 0.3521 - binary_accuracy: 0.8403\n",
      "client 5 loss --> [0.62647766 0.49592587 0.42992544 0.38967666 0.36884952 0.35799193\n",
      " 0.35208023] freq-> [ 35  81  82 118 169 193 238] accuracy-> [0.66000003 0.78941178 0.81802326 0.82921726 0.83451366 0.83820736\n",
      " 0.84032798]\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3508 - binary_accuracy: 0.8407\n",
      "client 6 loss --> [0.637501   0.52189416 0.44061247 0.39473754 0.36935103 0.35601559\n",
      " 0.3508102 ] freq-> [28 31 32 35 43 64 79] accuracy-> [0.64597702 0.79741603 0.82412934 0.83605444 0.83895129 0.8415423\n",
      " 0.84068477]\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.3550 - binary_accuracy: 0.8391\n",
      "client 3 loss --> [0.63509494 0.50661135 0.43480867 0.39777032 0.37680316 0.36311427\n",
      " 0.35500965] freq-> [ 27  55  67  84  95 140 155] accuracy-> [0.64424777 0.79427314 0.82253855 0.82780951 0.83316499 0.83782709\n",
      " 0.83913714]\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 0.3571 - binary_accuracy: 0.8378\n",
      "client 9 loss --> [0.62370652 0.50292283 0.42179424 0.38782564 0.37084198 0.3634156\n",
      " 0.35714594] freq-> [ 35  67 120 177 184 238 257] accuracy-> [0.66827583 0.79016787 0.82408518 0.83049935 0.83557856 0.83564025\n",
      " 0.83778602]\n",
      "comm_round: 6 | global_acc: 83.139% | global_loss: 0.370044082403183\n",
      "global_loss_list:  [0.5701592564582825, 0.46940603852272034, 0.4193616211414337, 0.3947606086730957, 0.381920725107193, 0.3745959401130676, 0.370044082403183]\n",
      "global_acc_list:  [0.7549139857292175, 0.8046683073043823, 0.8216625452041626, 0.8246314525604248, 0.8281121850013733, 0.8305692076683044, 0.8313882350921631]\n",
      "global_freq_list:  [315, 627, 934, 1245, 1556, 1866, 2176]\n",
      "284/284 [==============================] - 1s 2ms/step - loss: 0.3532 - binary_accuracy: 0.8396\n",
      "client 4 loss --> [0.62025577 0.49111667 0.42532605 0.39254719 0.37559977 0.36427131\n",
      " 0.35949349 0.35322836] freq-> [ 40  84 140 173 191 215 233 284] accuracy-> [0.66826349 0.79723018 0.82108259 0.82867682 0.833      0.83559006\n",
      " 0.83661205 0.83963585]\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 0.3539 - binary_accuracy: 0.8385\n",
      "client 0 loss --> [0.65393335 0.51186442 0.43077743 0.39603257 0.37713614 0.3659268\n",
      " 0.35767558 0.35387027] freq-> [ 25  60  98 107 155 195 250 294] accuracy-> [0.6156863  0.78736562 0.81866342 0.82760417 0.83163577 0.83370143\n",
      " 0.83635497 0.8385011 ]\n",
      "345/345 [==============================] - 1s 2ms/step - loss: 0.3501 - binary_accuracy: 0.8408\n",
      "client 8 loss --> [0.61517221 0.48960963 0.42281955 0.39003098 0.36989185 0.36100185\n",
      " 0.35512322 0.35012013] freq-> [ 42  82 119 158 213 264 294 345] accuracy-> [0.67733335 0.80097753 0.8219316  0.82929295 0.83486718 0.83644044\n",
      " 0.83883023 0.84076124]\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3472 - binary_accuracy: 0.8436\n",
      "client 6 loss --> [0.637501   0.52189416 0.44061247 0.39473754 0.36935103 0.35601559\n",
      " 0.3508102  0.3472445 ] freq-> [ 28  31  32  35  43  64  79 128] accuracy-> [0.64597702 0.79741603 0.82412934 0.83605444 0.83895129 0.8415423\n",
      " 0.84068477 0.84357053]\n",
      "  1/286 [..............................] - ETA: 0s - loss: 0.2960 - binary_accuracy: 0.8651WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0015s). Check your callbacks.\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.3523 - binary_accuracy: 0.8399\n",
      "client 9 loss --> [0.62370652 0.50292283 0.42179424 0.38782564 0.37084198 0.3634156\n",
      " 0.35714594 0.35233003] freq-> [ 35  67 120 177 184 238 257 286] accuracy-> [0.66827583 0.79016787 0.82408518 0.83049935 0.83557856 0.83564025\n",
      " 0.83778602 0.83986109]\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.3509 - binary_accuracy: 0.8407\n",
      "client 3 loss --> [0.63509494 0.50661135 0.43480867 0.39777032 0.37680316 0.36311427\n",
      " 0.35500965 0.35086849] freq-> [ 27  55  67  84  95 140 155 207] accuracy-> [0.64424777 0.79427314 0.82253855 0.82780951 0.83316499 0.83782709\n",
      " 0.83913714 0.84067667]\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.3574 - binary_accuracy: 0.8358\n",
      "client 7 loss --> [0.65585732 0.50503105 0.43097213 0.39798313 0.37979713 0.36877707\n",
      " 0.36126065 0.35735792] freq-> [ 24  66 124 125 175 184 229 239] accuracy-> [0.6102041  0.78588808 0.8148362  0.82211602 0.82558137 0.82926404\n",
      " 0.83406323 0.8357926 ]\n",
      "279/279 [==============================] - 1s 2ms/step - loss: 0.3487 - binary_accuracy: 0.8417\n",
      "client 2 loss --> [0.60632479 0.50043565 0.43652692 0.39356032 0.37285164 0.36149007\n",
      " 0.35296601 0.34869009] freq-> [ 50  81  86 140 195 209 263 279] accuracy-> [0.68148148 0.7957468  0.81652737 0.82776833 0.83219236 0.83614916\n",
      " 0.83941317 0.84172374]\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 0.3475 - binary_accuracy: 0.8417\n",
      "client 5 loss --> [0.62647766 0.49592587 0.42992544 0.38967666 0.36884952 0.35799193\n",
      " 0.35208023 0.34746936] freq-> [ 35  81  82 118 169 193 238 245] accuracy-> [0.66000003 0.78941178 0.81802326 0.82921726 0.83451366 0.83820736\n",
      " 0.84032798 0.84169096]\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.3464 - binary_accuracy: 0.8431\n",
      "client 1 loss --> [0.69391221 0.54309642 0.43285936 0.38982385 0.36973271 0.35706112\n",
      " 0.35023496 0.34637165] freq-> [  9  20  66 128 136 164 178 179] accuracy-> [0.52156866 0.77283949 0.82274365 0.83271027 0.8365497  0.84070837\n",
      " 0.84229392 0.84309268]\n",
      "comm_round: 7 | global_acc: 83.221% | global_loss: 0.36716315150260925\n",
      "global_loss_list:  [0.5701592564582825, 0.46940603852272034, 0.4193616211414337, 0.3947606086730957, 0.381920725107193, 0.3745959401130676, 0.370044082403183, 0.36716315150260925]\n",
      "global_acc_list:  [0.7549139857292175, 0.8046683073043823, 0.8216625452041626, 0.8246314525604248, 0.8281121850013733, 0.8305692076683044, 0.8313882350921631, 0.832207202911377]\n",
      "global_freq_list:  [315, 627, 934, 1245, 1556, 1866, 2176, 2486]\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3430 - binary_accuracy: 0.8452\n",
      "client 6 loss --> [0.637501   0.52189416 0.44061247 0.39473754 0.36935103 0.35601559\n",
      " 0.3508102  0.3472445  0.3429971 ] freq-> [ 28  31  32  35  43  64  79 128 148] accuracy-> [0.64597702 0.79741603 0.82412934 0.83605444 0.83895129 0.8415423\n",
      " 0.84068477 0.84357053 0.84524959]\n",
      "258/258 [==============================] - 1s 3ms/step - loss: 0.3469 - binary_accuracy: 0.8422\n",
      "client 3 loss --> [0.63509494 0.50661135 0.43480867 0.39777032 0.37680316 0.36311427\n",
      " 0.35500965 0.35086849 0.34687805] freq-> [ 27  55  67  84  95 140 155 207 258] accuracy-> [0.64424777 0.79427314 0.82253855 0.82780951 0.83316499 0.83782709\n",
      " 0.83913714 0.84067667 0.84223658]\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.3444 - binary_accuracy: 0.8431\n",
      "client 1 loss --> [0.69391221 0.54309642 0.43285936 0.38982385 0.36973271 0.35706112\n",
      " 0.35023496 0.34637165 0.34437943] freq-> [  9  20  66 128 136 164 178 179 248] accuracy-> [0.52156866 0.77283949 0.82274365 0.83271027 0.8365497  0.84070837\n",
      " 0.84229392 0.84309268 0.84306359]\n",
      "287/287 [==============================] - 1s 3ms/step - loss: 0.3447 - binary_accuracy: 0.8426\n",
      "client 5 loss --> [0.62647766 0.49592587 0.42992544 0.38967666 0.36884952 0.35799193\n",
      " 0.35208023 0.34746936 0.34468782] freq-> [ 35  81  82 118 169 193 238 245 287] accuracy-> [0.66000003 0.78941178 0.81802326 0.82921726 0.83451366 0.83820736\n",
      " 0.84032798 0.84169096 0.84260798]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340/340 [==============================] - 1s 3ms/step - loss: 0.3503 - binary_accuracy: 0.8407\n",
      "client 9 loss --> [0.62370652 0.50292283 0.42179424 0.38782564 0.37084198 0.3634156\n",
      " 0.35714594 0.35233003 0.3502675 ] freq-> [ 35  67 120 177 184 238 257 286 340] accuracy-> [0.66827583 0.79016787 0.82408518 0.83049935 0.83557856 0.83564025\n",
      " 0.83778602 0.83986109 0.84072512]\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.3506 - binary_accuracy: 0.8406\n",
      "client 4 loss --> [0.62025577 0.49111667 0.42532605 0.39254719 0.37559977 0.36427131\n",
      " 0.35949349 0.35322836 0.35062614] freq-> [ 40  84 140 173 191 215 233 284 285] accuracy-> [0.66826349 0.79723018 0.82108259 0.82867682 0.833      0.83559006\n",
      " 0.83661205 0.83963585 0.84061366]\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.3460 - binary_accuracy: 0.8433\n",
      "client 8 loss --> [0.61517221 0.48960963 0.42281955 0.39003098 0.36989185 0.36100185\n",
      " 0.35512322 0.35012013 0.34602386] freq-> [ 42  82 119 158 213 264 294 345 377] accuracy-> [0.67733335 0.80097753 0.8219316  0.82929295 0.83486718 0.83644044\n",
      " 0.83883023 0.84076124 0.84331226]\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.3463 - binary_accuracy: 0.8430\n",
      "client 2 loss --> [0.60632479 0.50043565 0.43652692 0.39356032 0.37285164 0.36149007\n",
      " 0.35296601 0.34869009 0.34633812] freq-> [ 50  81  86 140 195 209 263 279 299] accuracy-> [0.68148148 0.7957468  0.81652737 0.82776833 0.83219236 0.83614916\n",
      " 0.83941317 0.84172374 0.84296358]\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.3543 - binary_accuracy: 0.8375\n",
      "client 7 loss --> [0.65585732 0.50503105 0.43097213 0.39798313 0.37979713 0.36877707\n",
      " 0.36126065 0.35735792 0.35429272] freq-> [ 24  66 124 125 175 184 229 239 248] accuracy-> [0.6102041  0.78588808 0.8148362  0.82211602 0.82558137 0.82926404\n",
      " 0.83406323 0.8357926  0.83754015]\n",
      "306/306 [==============================] - 0s 2ms/step - loss: 0.3506 - binary_accuracy: 0.8402\n",
      "client 0 loss --> [0.65393335 0.51186442 0.43077743 0.39603257 0.37713614 0.3659268\n",
      " 0.35767558 0.35387027 0.35062817] freq-> [ 25  60  98 107 155 195 250 294 306] accuracy-> [0.6156863  0.78736562 0.81866342 0.82760417 0.83163577 0.83370143\n",
      " 0.83635497 0.8385011  0.8402496 ]\n",
      "comm_round: 8 | global_acc: 83.446% | global_loss: 0.3651004433631897\n",
      "global_loss_list:  [0.5701592564582825, 0.46940603852272034, 0.4193616211414337, 0.3947606086730957, 0.381920725107193, 0.3745959401130676, 0.370044082403183, 0.36716315150260925, 0.3651004433631897]\n",
      "global_acc_list:  [0.7549139857292175, 0.8046683073043823, 0.8216625452041626, 0.8246314525604248, 0.8281121850013733, 0.8305692076683044, 0.8313882350921631, 0.832207202911377, 0.8344594836235046]\n",
      "global_freq_list:  [315, 627, 934, 1245, 1556, 1866, 2176, 2486, 2796]\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.3438 - binary_accuracy: 0.8441\n",
      "client 2 loss --> [0.60632479 0.50043565 0.43652692 0.39356032 0.37285164 0.36149007\n",
      " 0.35296601 0.34869009 0.34633812 0.34381357] freq-> [ 50  81  86 140 195 209 263 279 299 320] accuracy-> [0.68148148 0.7957468  0.81652737 0.82776833 0.83219236 0.83614916\n",
      " 0.83941317 0.84172374 0.84296358 0.8440972 ]\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.3493 - binary_accuracy: 0.8409\n",
      "client 9 loss --> [0.62370652 0.50292283 0.42179424 0.38782564 0.37084198 0.3634156\n",
      " 0.35714594 0.35233003 0.3502675  0.34934714] freq-> [ 35  67 120 177 184 238 257 286 340 379] accuracy-> [0.66827583 0.79016787 0.82408518 0.83049935 0.83557856 0.83564025\n",
      " 0.83778602 0.83986109 0.84072512 0.84090149]\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3504 - binary_accuracy: 0.8395\n",
      "client 7 loss --> [0.65585732 0.50503105 0.43097213 0.39798313 0.37979713 0.36877707\n",
      " 0.36126065 0.35735792 0.35429272 0.35036215] freq-> [ 24  66 124 125 175 184 229 239 248 300] accuracy-> [0.6102041  0.78588808 0.8148362  0.82211602 0.82558137 0.82926404\n",
      " 0.83406323 0.8357926  0.83754015 0.83950716]\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 0.3422 - binary_accuracy: 0.8435\n",
      "client 5 loss --> [0.62647766 0.49592587 0.42992544 0.38967666 0.36884952 0.35799193\n",
      " 0.35208023 0.34746936 0.34468782 0.34222478] freq-> [ 35  81  82 118 169 193 238 245 287 292] accuracy-> [0.66000003 0.78941178 0.81802326 0.82921726 0.83451366 0.83820736\n",
      " 0.84032798 0.84169096 0.84260798 0.84352684]\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.3436 - binary_accuracy: 0.8442\n",
      "client 3 loss --> [0.63509494 0.50661135 0.43480867 0.39777032 0.37680316 0.36311427\n",
      " 0.35500965 0.35086849 0.34687805 0.34358859] freq-> [ 27  55  67  84  95 140 155 207 258 291] accuracy-> [0.64424777 0.79427314 0.82253855 0.82780951 0.83316499 0.83782709\n",
      " 0.83913714 0.84067667 0.84223658 0.84416258]\n",
      "419/419 [==============================] - 2s 4ms/step - loss: 0.3444 - binary_accuracy: 0.8442\n",
      "client 8 loss --> [0.61517221 0.48960963 0.42281955 0.39003098 0.36989185 0.36100185\n",
      " 0.35512322 0.35012013 0.34602386 0.34442401] freq-> [ 42  82 119 158 213 264 294 345 377 419] accuracy-> [0.67733335 0.80097753 0.8219316  0.82929295 0.83486718 0.83644044\n",
      " 0.83883023 0.84076124 0.84331226 0.8442359 ]\n",
      "187/187 [==============================] - 0s 3ms/step - loss: 0.3406 - binary_accuracy: 0.8467\n",
      "client 6 loss --> [0.637501   0.52189416 0.44061247 0.39473754 0.36935103 0.35601559\n",
      " 0.3508102  0.3472445  0.3429971  0.34064648] freq-> [ 28  31  32  35  43  64  79 128 148 187] accuracy-> [0.64597702 0.79741603 0.82412934 0.83605444 0.83895129 0.8415423\n",
      " 0.84068477 0.84357053 0.84524959 0.84672618]\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.3481 - binary_accuracy: 0.8417\n",
      "client 0 loss --> [0.65393335 0.51186442 0.43077743 0.39603257 0.37713614 0.3659268\n",
      " 0.35767558 0.35387027 0.35062817 0.34808406] freq-> [ 25  60  98 107 155 195 250 294 306 315] accuracy-> [0.6156863  0.78736562 0.81866342 0.82760417 0.83163577 0.83370143\n",
      " 0.83635497 0.8385011  0.8402496  0.84171718]\n",
      "295/295 [==============================] - 1s 3ms/step - loss: 0.3418 - binary_accuracy: 0.8440\n",
      "client 1 loss --> [0.69391221 0.54309642 0.43285936 0.38982385 0.36973271 0.35706112\n",
      " 0.35023496 0.34637165 0.34437943 0.34180903] freq-> [  9  20  66 128 136 164 178 179 248 295] accuracy-> [0.52156866 0.77283949 0.82274365 0.83271027 0.8365497  0.84070837\n",
      " 0.84229392 0.84309268 0.84306359 0.84396017]\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 0.3485 - binary_accuracy: 0.8415\n",
      "client 4 loss --> [0.62025577 0.49111667 0.42532605 0.39254719 0.37559977 0.36427131\n",
      " 0.35949349 0.35322836 0.35062614 0.34854385] freq-> [ 40  84 140 173 191 215 233 284 285 306] accuracy-> [0.66826349 0.79723018 0.82108259 0.82867682 0.833      0.83559006\n",
      " 0.83661205 0.83963585 0.84061366 0.84149766]\n",
      "comm_round: 9 | global_acc: 83.466% | global_loss: 0.3636309504508972\n",
      "global_loss_list:  [0.5701592564582825, 0.46940603852272034, 0.4193616211414337, 0.3947606086730957, 0.381920725107193, 0.3745959401130676, 0.370044082403183, 0.36716315150260925, 0.3651004433631897, 0.3636309504508972]\n",
      "global_acc_list:  [0.7549139857292175, 0.8046683073043823, 0.8216625452041626, 0.8246314525604248, 0.8281121850013733, 0.8305692076683044, 0.8313882350921631, 0.832207202911377, 0.8344594836235046, 0.8346642255783081]\n",
      "global_freq_list:  [315, 627, 934, 1245, 1556, 1866, 2176, 2486, 2796, 3104]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#initialize global model\n",
    "smlp_global = SimpleMLP()\n",
    "global_model = smlp_global.build(X_train.shape[1] ,classes=2)\n",
    "global_model.compile(optimizer=optimizer, loss=loss, metrics=metrics) \n",
    "# clients_batched, test_batched = batch_clients(clients)\n",
    "# client_names= list(clients_batched.keys())\n",
    "# client_names = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "client_names = {i for i in range(num_clients)}\n",
    "# client_names = [0, 1,2,3,4,5,6,7,8,9]\n",
    "# print(client_names, \"asugdefbh\")\n",
    "# print(clients_batched)\n",
    "global_loss_list = []\n",
    "global_freq_list = []\n",
    "global_acc_list = []\n",
    "client_loss = {i: np.array([]) for i in range(len(client_names))}\n",
    "client_accuracy = {i: np.array([]) for i in range(len(client_names))}\n",
    "client_frequency = {i: np.array([]) for i in range(len(client_names))}\n",
    "\n",
    "train_sets = initializer_income()\n",
    "# train_sets = initializer_income_race_gender()\n",
    "\n",
    "# print(len(train_sets))\n",
    "#commence global training loop\n",
    "for comm_round in range(comms_round):\n",
    "    epoch_freq = 0\n",
    "#     clients = create_clients(X_train, y_train, num_clients=15, initial='client')\n",
    "#     clients = get_hetero_clients()\n",
    "    clients = get_hetero_clients_gender(list(train_sets) )\n",
    "#     clients = get_hetero_clients_gender_race(list(train_sets) )\n",
    "#     print(\"client0: \", clients[0])\n",
    "\n",
    "    clients_batched, test_batched = batch_clients(clients)\n",
    "#     print(\"client batched 0: \", clients_batched[1])\n",
    "    # get the global model's weights - will serve as the initial weights for all local models\n",
    "    global_weights = global_model.get_weights()\n",
    "    \n",
    "    #initial list to collect local model weights after scalling\n",
    "    scaled_local_weight_list = list()\n",
    "\n",
    "    #randomize client data - using keys\n",
    "    client_names= list(clients_batched.keys())\n",
    "#     print(client_names)\n",
    "    random.shuffle(client_names)\n",
    "    \n",
    "    #loop through each client and create new local model\n",
    "    for client in client_names:\n",
    "        smlp_local = SimpleMLP()\n",
    "        local_model = smlp_local.build(X_train.shape[1],classes=2)\n",
    "        local_model.compile(loss=loss, \n",
    "                      optimizer=optimizer, \n",
    "                      metrics=metrics)\n",
    "        \n",
    "        #set local model weight to the weight of the global model\n",
    "        local_model.set_weights(global_weights)\n",
    "        \n",
    "        #fit local model with client's data\n",
    "        history = local_model.fit(clients_batched[client], epochs=1, verbose=1)\n",
    "        \n",
    "#         get client acc, loss\n",
    "#         print(client)\n",
    "        if(len(client_loss[client])== 0):\n",
    "            client_loss[client] = [history.history['loss'][0]]\n",
    "            client_accuracy[client] = [history.history['binary_accuracy'][0]]\n",
    "            client_frequency[client] = [len(clients_batched[client])]\n",
    "        \n",
    "        else:\n",
    "            client_loss[client] = np.append(client_loss[client], (history.history['loss'][0]))\n",
    "            client_frequency[client] = np.append(client_frequency[client], len(clients_batched[client]))\n",
    "            client_accuracy[client] = np.append(client_accuracy[client], (history.history['binary_accuracy'][0]))\n",
    "        \n",
    "        epoch_freq += len(clients_batched[client])\n",
    "        \n",
    "        print(\"client\", client, \"loss -->\" ,client_loss[client], \"freq->\", client_frequency[client], \"accuracy->\", client_accuracy[client])\n",
    "        \n",
    "        #scale the model weights and add to list\n",
    "        scaling_factor = weight_scalling_factor(clients_batched, client)\n",
    "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "        scaled_local_weight_list.append(scaled_weights)\n",
    "        \n",
    "        #clear session to free memory after each communication round\n",
    "        K.clear_session()\n",
    "        \n",
    "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "    \n",
    "    #update global model \n",
    "    global_model.set_weights(average_weights)\n",
    "    \n",
    "    global_freq_list.append(epoch_freq)\n",
    "    epoch_freq = 0\n",
    "    \n",
    "\n",
    "#     test global model and print out metrics after each communications round\n",
    "    for(X_test, Y_test) in test_batched:\n",
    "        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)\n",
    "        global_loss_list.append(global_loss)\n",
    "        global_acc_list.append(global_acc)\n",
    "        \n",
    "        print(\"global_loss_list: \", global_loss_list )\n",
    "        print(\"global_acc_list: \", global_acc_list )\n",
    "        print(\"global_freq_list: \", global_freq_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2208b3c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'animation' from partially initialized module 'matplotlib' (most likely due to a circular import) (C:\\Users\\riash\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mstats\u001b[39;00m \n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:107\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook, docstring, rcsetup\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning, sanitize_sequence\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mplDeprecation  \u001b[38;5;66;03m# deprecated\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\rcsetup.py:24\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, animation, cbook\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'animation' from partially initialized module 'matplotlib' (most likely due to a circular import) (C:\\Users\\riash\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats \n",
    "\n",
    "pdfs = []\n",
    "for i in list(client_accuracy.keys()):\n",
    "    print(\"client_\",i, \" loss: \", client_loss[i],\"freq: \", client_frequency[i], \"acc\", client_accuracy[i])\n",
    "    \n",
    "#     norm\n",
    "#     mean, std = stats.norm.fit(client_loss[i])\n",
    "#     pdf =  stats.norm.pdf(client_loss[i], mean, std)\n",
    "\n",
    "#     df_mean = np.mean(client_frequency[i])\n",
    "#     df_std = np.std(client_frequency[i])\n",
    "#     pdf = stats.norm.pdf(client_frequency[i], df_mean, df_std)\n",
    "    \n",
    "#     lognorm\n",
    "#     shape, loc, scale = stats.lognorm.fit(client_loss[i])\n",
    "#     pdf = stats.lognorm.pdf(client_loss[i], shape, loc, scale)\n",
    "\n",
    "#     beta\n",
    "#     beta_params = stats.beta.fit(client_loss[i])\n",
    "#     pdf = stats.beta.pdf(client_loss[i], beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "\n",
    "#     burr\n",
    "#     burr_params = stats.burr.fit(client_loss[i])\n",
    "#     pdf = stats.burr.pdf(client_loss[i], burr_params[0], burr_params[1], burr_params[2], burr_params[3])\n",
    "\n",
    "    \n",
    "#  gamma\n",
    "    shape, loc, scale = stats.gamma.fit(client_loss[i])\n",
    "    pdf = stats.gamma.cdf(client_loss[i], shape, loc=loc, scale=scale)\n",
    "    \n",
    "    pdfs.append(pdf)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    ax = sns.displot( x = pdf, kind = \"kde\", height=10, aspect=2,\n",
    "                linewidth = 5 )\n",
    "    plt.ylabel(\"LOSS\")\n",
    "#     plt.xlabel(\"Loss\")\n",
    "    plt.xlabel(\"CDF\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "739fe197",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'animation' from partially initialized module 'matplotlib' (most likely due to a circular import) (C:\\Users\\riash\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mstats\u001b[39;00m \n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:107\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook, docstring, rcsetup\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning, sanitize_sequence\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mplDeprecation  \u001b[38;5;66;03m# deprecated\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\rcsetup.py:24\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, animation, cbook\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'animation' from partially initialized module 'matplotlib' (most likely due to a circular import) (C:\\Users\\riash\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats \n",
    "\n",
    "for i in list(client_accuracy.keys()):\n",
    "    print(\"client_\",i, \"\\nloss: \", client_loss[i],\"\\nfreq: \", client_frequency[i], \"\\nacc\", client_accuracy[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80cb1f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_GAMMA_\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m cdfs_freq_gamma \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(client_accuracy\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#     print(\"client_\",i, \"\\nloss: \", client_loss[i],\"\\nfreq: \", client_frequency[i], \"\\nacc\", client_accuracy[i])\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     shape, loc, scale \u001b[38;5;241m=\u001b[39m \u001b[43mstats\u001b[49m\u001b[38;5;241m.\u001b[39mgamma\u001b[38;5;241m.\u001b[39mfit(client_loss[i])\n\u001b[0;32m     10\u001b[0m     cdf_loss_gamma \u001b[38;5;241m=\u001b[39m  stats\u001b[38;5;241m.\u001b[39mgamma\u001b[38;5;241m.\u001b[39mcdf(client_loss[i], shape, loc, scale)\n\u001b[0;32m     11\u001b[0m     cdfs_loss_gamma\u001b[38;5;241m.\u001b[39mappend(cdf_loss_gamma)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stats' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"_GAMMA_\")\n",
    "\n",
    "cdfs_loss_gamma = []\n",
    "cdfs_acc_gamma = []\n",
    "cdfs_freq_gamma = []\n",
    "for i in list(client_accuracy.keys()):\n",
    "#     print(\"client_\",i, \"\\nloss: \", client_loss[i],\"\\nfreq: \", client_frequency[i], \"\\nacc\", client_accuracy[i])\n",
    "\n",
    "    shape, loc, scale = stats.gamma.fit(client_loss[i])\n",
    "    cdf_loss_gamma =  stats.gamma.cdf(client_loss[i], shape, loc, scale)\n",
    "    cdfs_loss_gamma.append(cdf_loss_gamma)\n",
    "\n",
    "    shape, loc, scale= stats.gamma.fit(client_accuracy[i])\n",
    "    cdf_acc_gamma = stats.gamma.cdf(client_accuracy[i],shape, loc, scale)\n",
    "    cdfs_acc_gamma.append(cdf_acc_gamma)\n",
    "\n",
    "    shape, loc, scale  = stats.gamma.fit(client_frequency[i])\n",
    "    cdf_freq_gamma = stats.gamma.cdf(client_frequency[i],shape, loc, scale )\n",
    "    cdfs_freq_gamma.append(cdf_freq_gamma)\n",
    "\n",
    "\n",
    "print(\"ACCURACY\")\n",
    "for i in range(len(cdfs_acc_gamma)):\n",
    "    for j in range(i+1,len(cdfs_acc_gamma)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(cdfs_acc_gamma[i], cdfs_acc_gamma[j]))\n",
    "\n",
    "\n",
    "shape, loc, scale = stats.gamma.fit(global_acc_list)\n",
    "cdf_global_acc_gamma =  stats.gamma.cdf(global_acc_list, shape, loc, scale)\n",
    "\n",
    "for i in range(len(cdfs_acc_gamma)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(cdfs_acc_gamma[i], cdf_global_acc_gamma))\n",
    "\n",
    "print(\"LOSS\")\n",
    "for i in range(len(cdfs_loss_gamma)):\n",
    "    for j in range(i+1,len(cdfs_loss_gamma)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(cdfs_loss_gamma[i], cdfs_loss_gamma[j]))\n",
    "\n",
    "\n",
    "shape, loc, scale = stats.gamma.fit(global_loss_list)\n",
    "cdf_global_loss_gamma =  stats.gamma.cdf(global_loss_list, shape, loc, scale)\n",
    "\n",
    "for i in range(len(cdfs_loss_gamma)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(cdfs_loss_gamma[i], cdf_global_loss_gamma))\n",
    "\n",
    "print(\"FREQUENCY\")\n",
    "for i in range(len(cdfs_freq_gamma)):\n",
    "    for j in range(i+1,len(cdfs_freq_gamma)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(cdfs_freq_gamma[i], cdfs_freq_gamma[j]))\n",
    "\n",
    "\n",
    "shape, loc, scale = stats.gamma.fit(global_freq_list)\n",
    "cdf_global_freq_gamma =  stats.gamma.cdf(global_freq_list,shape, loc, scale)\n",
    "\n",
    "for i in range(len(cdfs_freq_gamma)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(cdfs_freq_gamma[i], cdf_global_freq_gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30032e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in range(len(pdfs_loss_gamma)):\n",
    "#     print(i,\" and global: \" , stats.wasserstein_distance(pdfs_loss_gamma[i], pdf_global_loss_gamma))\n",
    "#     M = ot.dist(pdfs_loss_gamma[i], pdf_global_loss_gamma, metric='euclidean')\n",
    "#     W = ot.emd2(pdfs_loss_gamma[i], pdf_global_loss_gamma, M)\n",
    "#     print(\"actual \", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c29d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"_NORM_\")\n",
    "\n",
    "pdfs_loss_norm = []\n",
    "pdfs_acc_norm = []\n",
    "pdfs_freq_norm = []\n",
    "for i in list(client_accuracy.keys()):\n",
    "#     print(\"client_\",i, \" loss: \", client_loss[i],\"freq: \", client_frequency[i], \"acc\", client_accuracy[i])\n",
    "    \n",
    "    mean, std = stats.norm.fit(client_loss[i])\n",
    "    pdf_loss_norm =  stats.norm.pdf(client_loss[i], mean, std)\n",
    "    pdfs_loss_norm.append(pdf_loss_norm)\n",
    "\n",
    "    mean, std = stats.norm.fit(client_accuracy[i])\n",
    "    pdf_acc_norm = stats.norm.pdf(client_accuracy[i],mean, std )\n",
    "    pdfs_acc_norm.append(pdf_acc_norm)\n",
    "    \n",
    "    mean, std  = stats.norm.fit(client_frequency[i])\n",
    "    pdf_freq_norm = stats.norm.pdf(client_frequency[i], mean, std )\n",
    "    pdfs_freq_norm.append(pdf_freq_norm)\n",
    "    \n",
    "    \n",
    "print(\"ACCURACY\")\n",
    "for i in range(len(pdfs_acc_norm)):\n",
    "    for j in range(i+1,len(pdfs_acc_norm)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_acc_norm[i], pdfs_acc_norm[j]))\n",
    "        \n",
    "        \n",
    "mean, std = stats.norm.fit(global_acc_list)\n",
    "pdf_global_acc_norm =  stats.norm.pdf(global_acc_list, mean, std)\n",
    "\n",
    "for i in range(len(pdfs_acc_norm)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_acc_norm[i], pdf_global_acc_norm))\n",
    "    \n",
    "print(\"LOSS\")\n",
    "for i in range(len(pdfs_loss_norm)):\n",
    "    for j in range(i+1,len(pdfs_loss_norm)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_loss_norm[i], pdfs_loss_norm[j]))\n",
    "        \n",
    "        \n",
    "mean, std = stats.norm.fit(global_loss_list)\n",
    "pdf_global_loss_norm =  stats.norm.pdf(global_loss_list, mean, std)\n",
    "\n",
    "for i in range(len(pdfs_loss_norm)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_loss_norm[i], pdf_global_loss_norm))\n",
    "    \n",
    "print(\"FREQUENCY\")\n",
    "for i in range(len(pdfs_freq_norm)):\n",
    "    for j in range(i+1,len(pdfs_freq_norm)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_freq_norm[i], pdfs_freq_norm[j]))\n",
    "        \n",
    "        \n",
    "mean, std = stats.norm.fit(global_freq_list)\n",
    "pdf_global_freq_norm =  stats.norm.pdf(global_freq_list, mean, std)\n",
    "\n",
    "for i in range(len(pdfs_freq_norm)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_freq_norm[i], pdf_global_freq_norm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a177e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"_LOGNORM_\")\n",
    "\n",
    "pdfs_loss = []\n",
    "pdfs_acc = []\n",
    "pdfs_freq = []\n",
    "for i in list(client_accuracy.keys()):\n",
    "#     print(\"client_\",i, \"\\nloss: \", client_loss[i],\"\\nfreq: \", client_frequency[i], \"\\nacc\", client_accuracy[i])\n",
    "\n",
    "    shape, loc, scale = stats.lognorm.fit(client_loss[i])\n",
    "    pdf_loss =  stats.lognorm.pdf(client_loss[i], shape, loc, scale)\n",
    "    pdfs_loss.append(pdf_loss)\n",
    "\n",
    "    shape, loc, scale= stats.lognorm.fit(client_accuracy[i])\n",
    "    pdf_acc = stats.lognorm.pdf(client_accuracy[i],shape, loc, scale)\n",
    "    pdfs_acc.append(pdf_acc)\n",
    "\n",
    "    shape, loc, scale  = stats.lognorm.fit(client_frequency[i])\n",
    "    pdf_freq = stats.lognorm.pdf(client_frequency[i],shape, loc, scale )\n",
    "    pdfs_freq.append(pdf_freq)\n",
    "\n",
    "\n",
    "print(\"ACCURACY\")\n",
    "for i in range(len(pdfs_acc)):\n",
    "    for j in range(i+1,len(pdfs_acc)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_acc[i], pdfs_acc[j]))\n",
    "\n",
    "\n",
    "shape, loc, scale = stats.lognorm.fit(global_acc_list)\n",
    "pdf_global_acc =  stats.lognorm.pdf(global_acc_list, shape, loc, scale)\n",
    "\n",
    "for i in range(len(pdfs_acc)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_acc[i], pdf_global_acc))\n",
    "\n",
    "print(\"LOSS\")\n",
    "for i in range(len(pdfs_loss)):\n",
    "    for j in range(i+1,len(pdfs_loss)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_loss[i], pdfs_loss[j]))\n",
    "\n",
    "\n",
    "shape, loc, scale = stats.lognorm.fit(global_loss_list)\n",
    "pdf_global_loss =  stats.lognorm.pdf(global_loss_list, shape, loc, scale)\n",
    "\n",
    "for i in range(len(pdfs_loss)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_loss[i], pdf_global_loss))\n",
    "\n",
    "print(\"FREQUENCY\")\n",
    "for i in range(len(pdfs_freq)):\n",
    "    for j in range(i+1,len(pdfs_freq)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_freq[i], pdfs_freq[j]))\n",
    "\n",
    "\n",
    "shape, loc, scale = stats.lognorm.fit(global_freq_list)\n",
    "pdf_global_freq =  stats.lognorm.pdf(global_freq_list,shape, loc, scale)\n",
    "\n",
    "for i in range(len(pdfs_freq)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_freq[i], pdf_global_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10261017",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"_BETA_\")\n",
    "\n",
    "pdfs_loss = []\n",
    "pdfs_acc = []\n",
    "pdfs_freq = []\n",
    "for i in list(client_accuracy.keys()):\n",
    "\n",
    "    beta_params = stats.beta.fit(client_loss[i])\n",
    "    pdf_loss =  stats.beta.pdf(client_loss[i],beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "    pdfs_loss.append(pdf_loss)\n",
    "\n",
    "    beta_params = stats.beta.fit(client_accuracy[i])\n",
    "    pdf_acc = stats.beta.pdf(client_accuracy[i],beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "    pdfs_acc.append(pdf_acc)\n",
    "\n",
    "    beta_params  = stats.beta.fit(client_frequency[i])\n",
    "    pdf_freq = stats.beta.pdf(client_frequency[i],beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "    pdfs_freq.append(pdf_freq)\n",
    "\n",
    "\n",
    "print(\"ACCURACY\")\n",
    "for i in range(len(pdfs_acc)):\n",
    "    for j in range(i+1,len(pdfs_acc)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_acc[i], pdfs_acc[j]))\n",
    "\n",
    "\n",
    "beta_params = stats.beta.fit(global_acc_list)\n",
    "pdf_global_acc =  stats.beta.pdf(global_acc_list, beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "\n",
    "for i in range(len(pdfs_acc)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_acc[i], pdf_global_acc))\n",
    "\n",
    "print(\"LOSS\")\n",
    "for i in range(len(pdfs_loss)):\n",
    "    for j in range(i+1,len(pdfs_loss)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_loss[i], pdfs_loss[j]))\n",
    "\n",
    "\n",
    "beta_params = stats.beta.fit(global_loss_list)\n",
    "pdf_global_loss =  stats.beta.pdf(global_loss_list, beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "\n",
    "for i in range(len(pdfs_loss)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_loss[i], pdf_global_loss))\n",
    "\n",
    "print(\"FREQUENCY\")\n",
    "for i in range(len(pdfs_freq)):\n",
    "    for j in range(i+1,len(pdfs_freq)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_freq[i], pdfs_freq[j]))\n",
    "\n",
    "\n",
    "beta_params = stats.beta.fit(global_freq_list)\n",
    "pdf_global_freq =  stats.beta.pdf(global_freq_list,beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "\n",
    "for i in range(len(pdfs_freq)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_freq[i], pdf_global_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3cc154",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"_BURR_\")\n",
    "\n",
    "pdfs_loss = []\n",
    "pdfs_acc = []\n",
    "pdfs_freq = []\n",
    "for i in list(client_accuracy.keys()):\n",
    "\n",
    "    params = stats.burr.fit(client_loss[i])\n",
    "    pdf_loss =  stats.burr.pdf(client_loss[i],params[0], params[1], params[2], params[3])\n",
    "    pdfs_loss.append(pdf_loss)\n",
    "\n",
    "    beta_params = stats.burr.fit(client_accuracy[i])\n",
    "    pdf_acc = stats.burr.pdf(client_accuracy[i],beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "    pdfs_acc.append(pdf_acc)\n",
    "\n",
    "    beta_params  = stats.burr.fit(client_frequency[i])\n",
    "    pdf_freq = stats.burr.pdf(client_frequency[i],beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "    pdfs_freq.append(pdf_freq)\n",
    "\n",
    "\n",
    "print(\"ACCURACY\")\n",
    "for i in range(len(pdfs_acc)):\n",
    "    for j in range(i+1,len(pdfs_acc)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_acc[i], pdfs_acc[j]))\n",
    "\n",
    "\n",
    "beta_params = stats.burr.fit(global_acc_list)\n",
    "pdf_global_acc =  stats.burr.pdf(global_acc_list, beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "\n",
    "for i in range(len(pdfs_acc)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_acc[i], pdf_global_acc))\n",
    "\n",
    "print(\"LOSS\")\n",
    "for i in range(len(pdfs_loss)):\n",
    "    for j in range(i+1,len(pdfs_loss)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_loss[i], pdfs_loss[j]))\n",
    "\n",
    "\n",
    "beta_params = stats.burr.fit(global_loss_list)\n",
    "pdf_global_loss =  stats.burr.pdf(global_loss_list, beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "\n",
    "for i in range(len(pdfs_loss)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_loss[i], pdf_global_loss))\n",
    "\n",
    "print(\"FREQUENCY\")\n",
    "for i in range(len(pdfs_freq)):\n",
    "    for j in range(i+1,len(pdfs_freq)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_freq[i], pdfs_freq[j]))\n",
    "\n",
    "\n",
    "beta_params = stats.burr.fit(global_freq_list)\n",
    "pdf_global_freq =  stats.burr.pdf(global_freq_list,beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "\n",
    "for i in range(len(pdfs_freq)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_freq[i], pdf_global_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd01c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(client_loss.keys()):\n",
    "#     if(i== len(list(client_loss.keys()))-1):\n",
    "#         continue\n",
    "    print(\"client_\",i, \"loss: \", client_loss[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650336b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(client_loss.keys()):\n",
    "#     if(i== len(list(client_loss.keys()))-1):\n",
    "#         continue\n",
    "    print(\"client_\",i, \"freq: \", client_frequency[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a70793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdfs)):\n",
    "    for j in range(i+1,len(pdfs)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs[i], pdfs[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2620a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gamma\n",
    "shape, loc, scale = stats.gamma.fit(global_freq_list)\n",
    "pdf_global = stats.gamma.pdf(global_freq_list, shape, loc=loc, scale=scale)\n",
    "\n",
    "# df_mean = np.mean(global_loss_list)\n",
    "# df_std = np.std(global_loss_list)\n",
    "# pdf_global = stats.norm.pdf(global_loss_list, df_mean, df_std)\n",
    "\n",
    "# mean, std = stats.norm.fit(global_freq_list)\n",
    "# pdf_global =  stats.norm.pdf(global_freq_list, mean, std)\n",
    "\n",
    "# lognorm\n",
    "# shape, loc, scale = stats.lognorm.fit(global_loss_list)\n",
    "# pdf_global = stats.lognorm.pdf(global_loss_list, shape, loc, scale)\n",
    "\n",
    "# global_acc_list\n",
    "# global_freq_list\n",
    "\n",
    "# burr\n",
    "# burr_params = stats.beta.fit(global_freq_list)\n",
    "# pdf_global = stats.beta.pdf(global_freq_list, burr_params[0], burr_params[1], burr_params[2], burr_params[3])\n",
    "\n",
    "for i in range(len(pdfs)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs[i], pdf_global))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de13219",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c9992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdfs)):\n",
    "    for j in range(i+1,len(pdfs)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs[i], pdfs[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bbbe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape, loc, scale = stats.gamma.fit(global_loss_list)\n",
    "pdf_global = stats.gamma.pdf(global_loss_list, shape, loc=loc, scale=scale)\n",
    "\n",
    "for i in range(len(pdfs)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs[i], pdf_global))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670d1d42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:03:08.033027Z",
     "start_time": "2021-07-16T00:03:07.867893Z"
    }
   },
   "outputs": [],
   "source": [
    "score = global_model.evaluate(X_test, y_test, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcaa73e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:03:08.653744Z",
     "start_time": "2021-07-16T00:03:08.484057Z"
    }
   },
   "outputs": [],
   "source": [
    "nn_preds = global_model.predict(X_test)\n",
    "nn_preds = (nn_preds > 0.5)\n",
    "\n",
    "nn_precision =precision_score(y_test, nn_preds)\n",
    "nn_recall = recall_score(y_test, nn_preds)\n",
    "nn_accuracy = accuracy_score(y_test, nn_preds)\n",
    "nn_f1 = f1_score(y_test, nn_preds)\n",
    "\n",
    "\n",
    "print(\"Precision = {}\".format(nn_precision))\n",
    "print(\"Recall = {}\".format(nn_recall))\n",
    "print(\"Accuracy = {}\".format(nn_accuracy))\n",
    "print(\"f1 = {}\".format(nn_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6360dd5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:03:09.275052Z",
     "start_time": "2021-07-16T00:03:09.268152Z"
    }
   },
   "outputs": [],
   "source": [
    "arr = nn_preds > 0.5\n",
    "\n",
    "unique, counts = np.unique(arr, return_counts=True)\n",
    "\n",
    "np.asarray((unique, counts)).T"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
