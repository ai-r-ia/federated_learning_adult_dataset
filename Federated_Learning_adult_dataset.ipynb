{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cb54a96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T12:48:49.512456Z",
     "start_time": "2021-07-15T12:48:46.946937Z"
    }
   },
   "source": [
    "# Federated Learning Implementation with tensorflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b29fd2ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:57:57.329013Z",
     "start_time": "2021-07-15T23:57:57.321303Z"
    }
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Adult Dataset Salary Prediction \n",
    "# This is part of a study to investigate Differetinal privacy in Machine learning, Naturally we wish to compare it with federated learning.\n",
    "\n",
    "\n",
    "\n",
    "# Refrences:\n",
    "\n",
    "# [1] Federated Learning with Non-IID Data, Yue Zhao et al, arXiv: 1806.00582v1, 2 Jun 2018\n",
    "# [2] Communication-Efficient Learning of Deep Networks from Decentralized Data, H. Brendan McMahan et al, arXiv:1602.05629v3 [cs.LG] 28 Feb 2017\n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cd2233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc9550b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall numpy\n",
    "# !pip install numpy==1.21.4\n",
    "# !pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31dcf41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.__version__\n",
    "# !pip uninstall numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09b7dd46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:57:57.590963Z",
     "start_time": "2021-07-15T23:57:57.572204Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riash\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\riash\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\riash\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "C:\\Users\\riash\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.metrics import precision_score,recall_score, accuracy_score,confusion_matrix,f1_score\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import History\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00b9bf6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:52.574848Z",
     "start_time": "2021-07-15T23:59:52.208912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "39068    0\n",
      "39069    1\n",
      "39070    1\n",
      "39071    1\n",
      "39072    1\n",
      "Name: race_White, Length: 39073, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((9768, 94), (9768, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Train/Test Data seperation\n",
    "\n",
    "file_out = pd.read_csv('Data/adult_processed.csv')\n",
    "cols = []\n",
    "for i in list(file_out.columns):\n",
    "    if  i != 'income':\n",
    "        cols.append(i)\n",
    "\n",
    "feature_set1 = pd.read_csv('Data/train.csv')\n",
    "feature_set2 = pd.read_csv('Data/test.csv')\n",
    "\n",
    "print(feature_set1['race_White'])\n",
    "x = feature_set1[cols].copy().values\n",
    "y = feature_set1[['income']].copy().values\n",
    "        \n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(x)\n",
    "y_train = y\n",
    "\n",
    "x2 = feature_set2[cols].copy().values\n",
    "y2 = feature_set2[['income']].copy().values\n",
    "        \n",
    "X_test = sc.transform(x2)\n",
    "y_test = y2\n",
    "\n",
    "\n",
    "X_test.shape, y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1b1abdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39073, 94), (12919, 94), (26154, 94))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/Test data based on  gender: 4 sets\n",
    "\n",
    "# train\n",
    "\n",
    "female_features =  feature_set1[feature_set1['gender_Female']==1]\n",
    "x_female = female_features[cols].copy().values\n",
    "y_female = female_features[['income']].copy().values\n",
    "\n",
    "X_train_female = sc.fit_transform(x_female)\n",
    "y_train_female = y_female\n",
    "\n",
    "male_features = feature_set1[feature_set1['gender_Male']==1] \n",
    "x_male = male_features[cols].copy().values\n",
    "y_male = male_features[['income']].copy().values\n",
    "\n",
    "X_train_male = sc.fit_transform(x_male)\n",
    "y_train_male = y_male\n",
    "\n",
    "# test\n",
    "\n",
    "female_features2 =  feature_set2[feature_set2['gender_Female']==1]\n",
    "x_female2 = female_features2[cols].copy().values\n",
    "y_female2 = female_features2[['income']].copy().values\n",
    "\n",
    "X_test_female = sc.fit_transform(x_female2)\n",
    "y_test_female = y_female2 \n",
    "\n",
    "male_features2 = feature_set2[feature_set2['gender_Male']==1] \n",
    "x_male2 = male_features2[cols].copy().values\n",
    "y_male2 = male_features2[['income']].copy().values\n",
    "\n",
    "X_test_male = sc.fit_transform(x_male2)\n",
    "y_test_male = y_male2\n",
    "\n",
    "\n",
    "# checks\n",
    "X_train.shape, X_train_female.shape, X_train_male.shape\n",
    "# X_test.shape, X_test_female.shape, X_test_male.shape\n",
    "# y_train.shape, y_train_female.shape, y_train_male.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f11a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# female_features_above30 = female_features[female_features['age']>30]\n",
    "# x_female_age = female_features_above30[cols].copy().values\n",
    "# y_female_age = female_features_above30[['income']].copy().values\n",
    "\n",
    "# X_train_female_age = sc.fit_transform(x_female_age)\n",
    "# y_train_female_age = y_female_age\n",
    "\n",
    "# male_features_above30 = male_features[male_features['age']>30]\n",
    "# x_male_age = male_features_above30[cols].copy().values\n",
    "# y_male_age = male_features_above30[['income']].copy().values\n",
    "\n",
    "# X_train_male_age = sc.fit_transform(x_male_age)\n",
    "# y_train_male_age = y_male_age\n",
    "\n",
    "# # test\n",
    "\n",
    "# female_features_above30_2 =  female_features2[female_features2['age']>30]\n",
    "# x_female_age2 = female_features_above30_2[cols].copy().values\n",
    "# y_female_age2 = female_features_above30_2[['income']].copy().values\n",
    "\n",
    "# X_test_female_age = sc.fit_transform(x_female_age2)\n",
    "# y_test_female_age = y_female_age2 \n",
    "\n",
    "# male_features_above30_2 = male_features2[male_features2['age']>30]\n",
    "# x_male_age2 = male_features_above30_2[cols].copy().values\n",
    "# y_male_age2 = male_features_above30_2[['income']].copy().values\n",
    "\n",
    "# X_test_male_age = sc.fit_transform(x_male_age2)\n",
    "# y_test_male_age = y_male_age2\n",
    "\n",
    "\n",
    "# # checks\n",
    "# X_train.shape, X_train_female_age.shape, X_train_male_age.shape\n",
    "# X_test.shape, X_test_female.shape, X_test_male.shape\n",
    "# y_train.shape, y_train_female.shape, y_train_male.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "066207c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:51.783759Z",
     "start_time": "2021-07-15T23:59:51.727576Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# def create_clients(image_list, label_list, num_clients=10, initial='clients'):\n",
    "    \n",
    "#     ''' return: a dictionary with keys clients' names and value as \n",
    "#                 data shards - tuple of images and label lists.\n",
    "#         args: \n",
    "#             image_list: a list of numpy arrays of training images\n",
    "#             label_list:a list of binarized labels for each image\n",
    "#             num_client: number of fedrated members (clients)\n",
    "#             initials: the clients'name prefix, e.g, clients_1 \n",
    "            \n",
    "#     '''\n",
    "\n",
    "#     #create a list of client names\n",
    "# #     client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n",
    "\n",
    "# #     iid\n",
    "# #     #randomize the data\n",
    "# #     data = list(zip(image_list, label_list))\n",
    "# #     random.shuffle(data)\n",
    "    \n",
    "   \n",
    "    \n",
    "# #     non-iid //////////////////////////////////////\n",
    "#     max_y = np.argmax(label_list, axis=-1)\n",
    "#     sorted_zip = sorted(zip(max_y, label_list, image_list), key=lambda x: x[0])\n",
    "#     data = [(x,y) for _,y,x in sorted_zip]\n",
    "\n",
    "# # LOGIC:\n",
    "# #    image_list length-->total data items\n",
    "# #    taking 50 images in each shard--> num_shards = image_list/41 gives 953 shards\n",
    "# #    num_shard = num_shards + 1 if(image_list%50 >0) \n",
    "\n",
    "#     num_shards, num_imgs = 953, 41\n",
    "#     idx_shard = [i for i in range(num_shards)]\n",
    "#     dict_users = {i: np.array([]) for i in range(num_clients)}\n",
    "# #     dict_users = [i for i in range(num_clients)]\n",
    "# #     idxs = np.arange(num_shards*num_imgs)\n",
    "# #     labels = dataset.train_labels.numpy()\n",
    "\n",
    "#     max_y = np.argmax(label_list, axis=-1)\n",
    "# #     image_list = np.argmax(image_list, axis=-1)\n",
    "# #     print(idxs.shape, label_list.shape)\n",
    "    \n",
    "# #     idxs_labels = np.vstack((idxs, max_y))\n",
    "# #     idxs_labels = idxs_labels[:, idxs_labels[1, :].argsort()]\n",
    "# #     idxs = idxs_labels[0, :]\n",
    "\n",
    "\n",
    "# #   ////////////////////////////////////////////////////  \n",
    "#     #shard data and place at each client\n",
    "# #     size = len(data)//num_clients\n",
    "# #     shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n",
    "\n",
    "# #     #number of clients must equal number of shards\n",
    "# #     assert(len(shards) == len(client_names))\n",
    "\n",
    "# #     print(len(image_list))\n",
    "# #     for i in range(len(client_names)):\n",
    "# #         print(client_names[i], len(shards[i]))\n",
    "              \n",
    "# #     return {client_names[i] : shards[i] for i in range(len(client_names))} \n",
    "\n",
    "\n",
    "# clients = create_clients(X_train, y_train, num_clients=15, initial='client')\n",
    "# # print(clients)\n",
    "\n",
    "# for i in range(len(clients.keys())):\n",
    "#         print(i, len(clients[i]))\n",
    "\n",
    "# print(type(clients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76379dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender split\n",
    "\n",
    "dict_users = {i: np.array([]) for i in range(8)}\n",
    "data_out = []\n",
    "\n",
    "def create_hetero_clients( image_list, label_list, start_client = 0, num_clients=10, initial='clients'):\n",
    "    \n",
    "    selected_inds = []\n",
    "\n",
    "    max_y = np.argmax(label_list, axis=-1)\n",
    "    sorted_zip = sorted(zip(max_y, label_list, image_list), key=lambda x: x[0])\n",
    "    data = [(x,y) for _,y,x in sorted_zip]\n",
    "    \n",
    "    data_out = data\n",
    "    \n",
    "    num_shards, num_imgs = int(len(image_list)/30), 30\n",
    "    idx_shard = [i for i in range(num_shards)]\n",
    "\n",
    "    min_shard = 1\n",
    "    max_shard = 60  #953/15 = 63.53\n",
    "    \n",
    "    random_shard_size = np.random.randint(min_shard, max_shard+1,\n",
    "                                          size=(num_clients-start_client))\n",
    "    random_shard_size = np.around(random_shard_size /\n",
    "                                  sum(random_shard_size) * num_shards)\n",
    "    random_shard_size = random_shard_size.astype(int)\n",
    "\n",
    "\n",
    "    if sum(random_shard_size) > num_shards:\n",
    "        \n",
    "        for i in range(start_client, num_clients):\n",
    "            # First assign each client 1 shard to ensure every client has\n",
    "            # atleast one shard of data\n",
    "            rand_set = set(np.random.choice(idx_shard, 1, replace=False))\n",
    "            idx_shard = list(set(idx_shard) - rand_set)\n",
    "            for rand in rand_set:\n",
    "                ind1 = rand*num_imgs\n",
    "                ind2 = (rand+1)*num_imgs\n",
    "                if(len(dict_users[i]) == 0):\n",
    "                    dict_users[i] = data[ind1: ind2]\n",
    "                else:\n",
    "                    dict_users[i] = np.concatenate(\n",
    "                    (dict_users[i],data[ind1: ind2]),\n",
    "                    axis=0)\n",
    "                selected_inds.extend([[ind1, ind2]])\n",
    "\n",
    "        random_shard_size = random_shard_size-1\n",
    "\n",
    "        # Next, randomly assign the remaining shards\n",
    "        for i in range(start_client, num_clients):\n",
    "            if len(idx_shard) == 0:\n",
    "                continue\n",
    "#             print(random_shard_size)\n",
    "            shard_size = random_shard_size[i-start_client]\n",
    "            if shard_size > len(idx_shard):\n",
    "                shard_size = len(idx_shard)\n",
    "            rand_set = set(np.random.choice(idx_shard, shard_size,\n",
    "                                            replace=False))\n",
    "            idx_shard = list(set(idx_shard) - rand_set)\n",
    "            for rand in rand_set:\n",
    "                ind1 = rand*num_imgs\n",
    "                ind2 = (rand+1)*num_imgs\n",
    "                if(len(dict_users[i]) == 0):\n",
    "                    dict_users[i] = data[ind1: ind2]\n",
    "                else:\n",
    "                    dict_users[i] = np.concatenate(\n",
    "                    (dict_users[i],data[ind1: ind2]),\n",
    "                    axis=0)\n",
    "                selected_inds.extend([[ind1, ind2]])\n",
    "\n",
    "    else:\n",
    "\n",
    "        for i in range(start_client, num_clients):\n",
    "#             print(random_shard_size)\n",
    "            shard_size = random_shard_size[i-start_client]\n",
    "#             shard_size = random_shard_size[int(i/len(random_shard_size)) - 1]\n",
    "            rand_set = set(np.random.choice(idx_shard, shard_size,\n",
    "                                            replace=False))\n",
    "            idx_shard = list(set(idx_shard) - rand_set)\n",
    "            for rand in rand_set:\n",
    "                ind1 = rand*num_imgs\n",
    "                ind2 = (rand+1)*num_imgs\n",
    "                if(len(dict_users[i]) == 0):\n",
    "                    dict_users[i] = data[ind1: ind2]\n",
    "                else:\n",
    "                    dict_users[i] = np.concatenate(\n",
    "                    (dict_users[i],data[ind1: ind2]),\n",
    "                    axis=0)\n",
    "                selected_inds.extend([[ind1, ind2]])\n",
    "\n",
    "        if len(idx_shard) > 0:\n",
    "            # Add the leftover shards to the client with minimum images:\n",
    "            shard_size = len(idx_shard)\n",
    "            # Add the remaining shard to the client with lowest data\n",
    "            k = min(dict_users, key=lambda x: len(dict_users.get(x)))\n",
    "            rand_set = set(np.random.choice(idx_shard, shard_size,\n",
    "                                            replace=False))\n",
    "            idx_shard = list(set(idx_shard) - rand_set)\n",
    "            for rand in rand_set:\n",
    "                ind1 = rand*num_imgs\n",
    "                ind2 = (rand+1)*num_imgs\n",
    "                if(len(dict_users[k]) == 0):\n",
    "                    dict_users[k] = data[ind1: ind2]\n",
    "                else:\n",
    "                    dict_users[k] = np.concatenate(\n",
    "                    (dict_users[k],data[ind1: ind2]),\n",
    "                    axis=0)\n",
    "                selected_inds.extend([[ind1, ind2]])\n",
    "                \n",
    "                \n",
    "    return dict_users, selected_inds, data_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cdec0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_users = {i: np.array([]) for i in range(4)}\n",
    "\n",
    "def create_client_iid(image_list, label_list, client_num):    \n",
    "    max_y = np.argmax(label_list, axis=-1)\n",
    "    sorted_zip = sorted(zip(max_y, label_list, image_list), key=lambda x: x[0])\n",
    "    data = [(x,y) for _,y,x in sorted_zip]\n",
    "    \n",
    "    dict_users[client_num] = data\n",
    "    \n",
    "    return dict_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdd4dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hetero_clients():\n",
    "    \n",
    "    female_features =  feature_set1[feature_set1['gender_Female']==1]\n",
    "    x_female = female_features[cols].copy().values\n",
    "    y_female = female_features[['income']].copy().values\n",
    "\n",
    "    X_train_female = sc.fit_transform(x_female)\n",
    "    y_train_female = y_female\n",
    "\n",
    "    male_features = feature_set1[feature_set1['gender_Male']==1] \n",
    "    x_male = male_features[cols].copy().values\n",
    "    y_male = male_features[['income']].copy().values\n",
    "\n",
    "    X_train_male = sc.fit_transform(x_male)\n",
    "    y_train_male = y_male\n",
    "\n",
    "    # test\n",
    "\n",
    "    female_features2 =  feature_set2[feature_set2['gender_Female']==1]\n",
    "    x_female2 = female_features2[cols].copy().values\n",
    "    y_female2 = female_features2[['income']].copy().values\n",
    "\n",
    "    X_test_female = sc.fit_transform(x_female2)\n",
    "    y_test_female = y_female2 \n",
    "\n",
    "    male_features2 = feature_set2[feature_set2['gender_Male']==1] \n",
    "    x_male2 = male_features2[cols].copy().values\n",
    "    y_male2 = male_features2[['income']].copy().values\n",
    "\n",
    "    X_test_male = sc.fit_transform(x_male2)\n",
    "    y_test_male = y_male2\n",
    "\n",
    "#     shuffling male and female datalists\n",
    "#     print(X_train_male.shape)\n",
    "    data = list(zip(X_train_male, y_train_male))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    X_train_male, y_train_male = list(zip(*data))[0], list(zip(*data))[1]\n",
    "    data.clear()\n",
    "    \n",
    "    data = list(zip(X_train_female, y_train_female))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    X_train_female, y_train_female = list(zip(*data))[0], list(zip(*data))[1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 1 all male\n",
    "    clients, inds, data_out1 = create_hetero_clients(X_train_male[:5230], y_train_male[:5230], start_client = 0, num_clients=1, initial='client') \n",
    "    # 1 all female\n",
    "    clients2, inds2, data_out2 = create_hetero_clients(X_train_female[:2584], y_train_female[:2584], start_client = 1, num_clients=2, initial='client')\n",
    "    clients = {**clients, **clients2}\n",
    "\n",
    "    used_x = []\n",
    "    used_y = []\n",
    "    used_data = []\n",
    "  \n",
    "    for i,j in list(inds):\n",
    "        for x in range(i,j):\n",
    "            used_data.insert(len(used_data)-1,(data_out1[x]))  \n",
    "  \n",
    "    for x in used_data:\n",
    "        used_x.insert(len(used_x)-1,x[0])\n",
    "        used_y.insert(len(used_y)-1,x[1])  \n",
    "   \n",
    "    used_data.clear()\n",
    "\n",
    "    for i,j in list(inds2):\n",
    "        for x in range(i,j):\n",
    "            used_data.insert(len(used_data)-1,(data_out2[x]))  \n",
    "\n",
    "    for x in used_data:\n",
    "        used_x.insert(len(used_x)-1,x[0])\n",
    "        used_y.insert(len(used_y)-1,x[1])  \n",
    "\n",
    "    # 3 mix\n",
    "    X_train_mix = np.setdiff1d(X_train, np.array(used_x))#53834, 64278\n",
    "    y_train_mix = np.setdiff1d(y_train, np.array(used_y))\n",
    "\n",
    "#     print(X_train_mix.shape, X_train.shape)\n",
    "#     print(y_train_mix.shape, y_train.shape)\n",
    "\n",
    "    clients3, inds3 , data_out= create_hetero_clients(X_train_mix, y_train_mix, start_client = 2, num_clients=5, initial='client')\n",
    "    clients = {**clients, **clients3}\n",
    "    \n",
    "    return clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e891872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializer():\n",
    "    \n",
    "    female_features =  feature_set1[feature_set1['gender_Female']==1]\n",
    "    x_female = female_features[cols].copy().values\n",
    "    y_female = female_features[['income']].copy().values\n",
    "\n",
    "    X_train_female = sc.fit_transform(x_female)\n",
    "    y_train_female = y_female\n",
    "\n",
    "    male_features = feature_set1[feature_set1['gender_Male']==1] \n",
    "    x_male = male_features[cols].copy().values\n",
    "    y_male = male_features[['income']].copy().values\n",
    "\n",
    "    X_train_male = sc.fit_transform(x_male)\n",
    "    y_train_male = y_male\n",
    "\n",
    "    # test\n",
    "\n",
    "    female_features2 =  feature_set2[feature_set2['gender_Female']==1]\n",
    "    x_female2 = female_features2[cols].copy().values\n",
    "    y_female2 = female_features2[['income']].copy().values\n",
    "\n",
    "    X_test_female = sc.fit_transform(x_female2)\n",
    "    y_test_female = y_female2 \n",
    "\n",
    "    male_features2 = feature_set2[feature_set2['gender_Male']==1] \n",
    "    x_male2 = male_features2[cols].copy().values\n",
    "    y_male2 = male_features2[['income']].copy().values\n",
    "\n",
    "    X_test_male = sc.fit_transform(x_male2)\n",
    "    y_test_male = y_male2\n",
    "    \n",
    "#   train-- with age\n",
    "    female_features_above30 = female_features[female_features['age']>30]\n",
    "    x_female_age = female_features_above30[cols].copy().values\n",
    "    y_female_age = female_features_above30[['income']].copy().values\n",
    "\n",
    "    X_train_female_age = sc.fit_transform(x_female_age)\n",
    "    y_train_female_age = y_female_age\n",
    "\n",
    "    male_features_above30 = male_features[male_features['age']>30]\n",
    "    x_male_age = male_features_above30[cols].copy().values\n",
    "    y_male_age = male_features_above30[['income']].copy().values\n",
    "\n",
    "    X_train_male_age = sc.fit_transform(x_male_age)\n",
    "    y_train_male_age = y_male_age\n",
    "\n",
    "    # test\n",
    "\n",
    "    female_features_above30_2 =  female_features2[female_features2['age']>30]\n",
    "    x_female_age2 = female_features_above30_2[cols].copy().values\n",
    "    y_female_age2 = female_features_above30_2[['income']].copy().values\n",
    "\n",
    "    X_test_female_age = sc.fit_transform(x_female_age2)\n",
    "    y_test_female_age = y_female_age2 \n",
    "\n",
    "    male_features_above30_2 = male_features2[male_features2['age']>30]\n",
    "    x_male_age2 = male_features_above30_2[cols].copy().values\n",
    "    y_male_age2 = male_features_above30_2[['income']].copy().values\n",
    "\n",
    "    X_test_male_age = sc.fit_transform(x_male_age2)\n",
    "    y_test_male_age = y_male_age2\n",
    "    \n",
    "    return X_train_male_age, y_train_male_age,  X_train_female_age, y_train_female_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb1235d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializer_income():\n",
    "    \n",
    "    female_features =  feature_set1[feature_set1['gender_Female']==1]\n",
    "    female_features_above30 = female_features[female_features['income']==1]\n",
    "    x_female_age = female_features_above30[cols].copy().values\n",
    "    y_female_age = female_features_above30[['income']].copy().values\n",
    "    \n",
    "    female_features_below = female_features[female_features['income']==0]\n",
    "    x_female_less = female_features_below[cols].copy().values\n",
    "    y_female_less = female_features_below[['income']].copy().values\n",
    "\n",
    "    X_train_female_age = sc.fit_transform(x_female_age)\n",
    "    y_train_female_age = y_female_age\n",
    "    \n",
    "    X_train_female_less = sc.fit_transform(x_female_less)\n",
    "    y_train_female_less = y_female_less\n",
    "\n",
    "\n",
    "    male_features = feature_set1[feature_set1['gender_Male']==1] \n",
    "    male_features_above30 = male_features[male_features['income']==1]\n",
    "    x_male_age = male_features_above30[cols].copy().values\n",
    "    y_male_age = male_features_above30[['income']].copy().values\n",
    "    \n",
    "    male_features_below = male_features[male_features['income']==0]\n",
    "    x_male_less = male_features_below[cols].copy().values\n",
    "    y_male_less = male_features_below[['income']].copy().values\n",
    "\n",
    "    X_train_male_age = sc.fit_transform(x_male_age)\n",
    "    y_train_male_age = y_male_age\n",
    "    \n",
    "    X_train_male_less = sc.fit_transform(x_male_less)\n",
    "    y_train_male_less = y_male_less\n",
    "\n",
    "\n",
    "    # test\n",
    "\n",
    "    female_features2 =  feature_set2[feature_set2['gender_Female']==1]\n",
    "    female_features_above30_2 =  female_features2[female_features2['income']==1]\n",
    "    x_female_age2 = female_features_above30_2[cols].copy().values\n",
    "    y_female_age2 = female_features_above30_2[['income']].copy().values\n",
    "\n",
    "    X_test_female_age = sc.fit_transform(x_female_age2)\n",
    "    y_test_female_age = y_female_age2 \n",
    "\n",
    "\n",
    "    male_features2 = feature_set2[feature_set2['gender_Male']==1]\n",
    "    male_features_above30_2 = male_features2[male_features2['income']==1]\n",
    "    x_male_age2 = male_features_above30_2[cols].copy().values\n",
    "    y_male_age2 = male_features_above30_2[['income']].copy().values\n",
    "\n",
    "    X_test_male_age = sc.fit_transform(x_male_age2)\n",
    "    y_test_male_age = y_male_age2\n",
    "\n",
    "    \n",
    "    return [X_train_male_age, y_train_male_age,  X_train_female_age, y_train_female_age, X_train_male_less, y_train_male_less,  X_train_female_less, y_train_female_less]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4278841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hetero_clients_gender(train_sets):\n",
    "    \n",
    "    data = list(zip(train_sets[0], train_sets[1]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "#     print(type(train_sets), type(train_sets[0]),type(list(list(zip(*data))[0]) ), type(data))\n",
    "    \n",
    "    train_sets[0] = list(list(zip(*data))[0])\n",
    "    train_sets[1] = list(list(zip(*data))[1])\n",
    "    data.clear()\n",
    "    \n",
    "    data = list(zip(train_sets[2], train_sets[3]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    train_sets[2], train_sets[3] = list(zip(*data))[0], list(zip(*data))[1]\n",
    "    data.clear()\n",
    "    \n",
    "    data = list(zip(train_sets[4], train_sets[5]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    train_sets[4], train_sets[5] = list(zip(*data))[0], list(zip(*data))[1]\n",
    "    data.clear()\n",
    "    \n",
    "    data = list(zip(train_sets[6], train_sets[7]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    train_sets[6], train_sets[7] = list(zip(*data))[0], list(zip(*data))[1]\n",
    "    \n",
    "#     NON_IID\n",
    "    clients, inds, data_out1 = create_hetero_clients(train_sets[0], train_sets[1], start_client = 0, num_clients=1, initial='client') \n",
    "    \n",
    "    clients2, inds2, data_out2 = create_hetero_clients(train_sets[2], train_sets[3], start_client = 1, num_clients=2, initial='client')\n",
    "    clients = {**clients, **clients2}\n",
    "    \n",
    "    clients3, inds3, data_out3 = create_hetero_clients(train_sets[4], train_sets[5], start_client = 2, num_clients=3, initial='client')\n",
    "    clients = {**clients, **clients3}\n",
    "    \n",
    "    clients4, inds4, data_out4 = create_hetero_clients(train_sets[6], train_sets[7], start_client = 3, num_clients=4, initial='client')\n",
    "    clients = {**clients, **clients4}\n",
    "\n",
    "# #     IID\n",
    "#     clients = create_client_iid(train_sets[0], train_sets[1], 0)\n",
    "    \n",
    "#     clients2 = create_client_iid(train_sets[2], train_sets[3], 1)\n",
    "#     clients = {**clients, **clients2}\n",
    "    \n",
    "#     clients3 = create_client_iid(train_sets[4], train_sets[5], 2)\n",
    "#     clients = {**clients, **clients3}\n",
    "    \n",
    "#     clients4 = create_client_iid(train_sets[6], train_sets[7], 3)\n",
    "#     clients = {**clients, **clients4}\n",
    "    \n",
    "    \n",
    "#     ________________________________________________________\n",
    "#     used_x = []\n",
    "#     used_y = []\n",
    "#     used_data = []\n",
    "  \n",
    "#     for i,j in list(inds):\n",
    "#         for x in range(i,j):\n",
    "#             used_data.insert(len(used_data)-1,(data_out1[x]))  \n",
    "  \n",
    "#     for x in used_data:\n",
    "#         used_x.insert(len(used_x)-1,x[0])\n",
    "#         used_y.insert(len(used_y)-1,x[1])  \n",
    "   \n",
    "#     used_data.clear()\n",
    "\n",
    "#     for i,j in list(inds2):\n",
    "#         for x in range(i,j):\n",
    "#             used_data.insert(len(used_data)-1,(data_out2[x]))  \n",
    "\n",
    "#     for x in used_data:\n",
    "#         used_x.insert(len(used_x)-1,x[0])\n",
    "#         used_y.insert(len(used_y)-1,x[1])  \n",
    "\n",
    "#     # 3 mix\n",
    "#     X_train_mix = np.setdiff1d(X_train, np.array(used_x))#53834, 64278\n",
    "#     y_train_mix = np.setdiff1d(y_train, np.array(used_y))\n",
    "\n",
    "#     print(X_train_mix.shape, X_train.shape)\n",
    "#     print(type(X_train_mix), type(X_train))\n",
    "#     print(type(data_out))\n",
    "#     print(y_train_mix.shape, y_train.shape)\n",
    "\n",
    "#     clients3, inds3 , data_out= create_hetero_clients(X_train, y_train, start_client = 2, num_clients=5, initial='client')\n",
    "#     clients = {**clients, **clients3}\n",
    "    \n",
    "    return clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa04e453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializer_income_race_gender():\n",
    "    \n",
    "    female_features =  feature_set1[feature_set1['gender_Female']==1]\n",
    "    female_features_above50 = female_features[female_features['income']==1]\n",
    "    female_features_above50_white = female_features_above50[female_features_above50['race_White']==1]\n",
    "    female_features_above50_black = female_features_above50[female_features_above50['race_Black']==1]\n",
    "    \n",
    "#     white, female, >50k\n",
    "    x_female_white_more = female_features_above50_white[cols].copy().values\n",
    "    y_female_white_more = female_features_above50_white[['income']].copy().values\n",
    "    X_train_female_white_more = sc.fit_transform(x_female_white_more)\n",
    "    y_train_female_white_more = y_female_white_more\n",
    "    \n",
    "#     black, female, >50k\n",
    "    x_female_black_more = female_features_above50_black[cols].copy().values\n",
    "    y_female_black_more = female_features_above50_black[['income']].copy().values\n",
    "    X_train_female_black_more = sc.fit_transform(x_female_black_more)\n",
    "    y_train_female_black_more = y_female_black_more\n",
    "    \n",
    "    female_features_below = female_features[female_features['income']==0]\n",
    "    female_features_below_white = female_features_below[female_features_below['race_White']==1]\n",
    "    female_features_below_black = female_features_below[female_features_below['race_Black']==1]\n",
    "    \n",
    "#    white, female, <=50k\n",
    "    x_female_white_less = female_features_below_white[cols].copy().values\n",
    "    y_female_white_less = female_features_below_white[['income']].copy().values\n",
    "    X_train_female_white_less = sc.fit_transform(x_female_white_less)\n",
    "    y_train_female_white_less = y_female_white_less\n",
    "    \n",
    "#    black, female, <=50k\n",
    "    x_female_black_less = female_features_below_black[cols].copy().values\n",
    "    y_female_black_less = female_features_below_black[['income']].copy().values\n",
    "    X_train_female_black_less = sc.fit_transform(x_female_black_less)\n",
    "    y_train_female_black_less = y_female_black_less\n",
    "    \n",
    "\n",
    "\n",
    "    male_features = feature_set1[feature_set1['gender_Male']==1] \n",
    "    male_features_above50 = male_features[male_features['income']==1]\n",
    "    male_features_above50_white = male_features_above50[male_features_above50['race_White']==1]\n",
    "    male_features_above50_black = male_features_above50[male_features_above50['race_Black']==1]\n",
    "    \n",
    "#     white, male, >50k\n",
    "    x_male_white_more = male_features_above50_white[cols].copy().values\n",
    "    y_male_white_more = male_features_above50_white[['income']].copy().values\n",
    "    X_train_male_white_more = sc.fit_transform(x_male_white_more)\n",
    "    y_train_male_white_more = y_male_white_more\n",
    "    \n",
    "#     black, male, >50k\n",
    "    x_male_black_more = male_features_above50_black[cols].copy().values\n",
    "    y_male_black_more = male_features_above50_black[['income']].copy().values\n",
    "    X_train_male_black_more = sc.fit_transform(x_male_black_more)\n",
    "    y_train_male_black_more = y_male_black_more\n",
    "    \n",
    "    male_features_below = male_features[male_features['income']==0]\n",
    "    male_features_below_white = male_features_below[male_features_below['race_White']==1]\n",
    "    male_features_below_black = male_features_below[male_features_below['race_Black']==1]\n",
    "    \n",
    "#    white, male, <=50k\n",
    "    x_male_white_less = male_features_below_white[cols].copy().values\n",
    "    y_male_white_less = male_features_below_white[['income']].copy().values\n",
    "    X_train_male_white_less = sc.fit_transform(x_male_white_less)\n",
    "    y_train_male_white_less = y_male_white_less\n",
    "    \n",
    "#    black, male, <=50k\n",
    "    x_male_black_less = male_features_below_black[cols].copy().values\n",
    "    y_male_black_less = male_features_below_black[['income']].copy().values\n",
    "    X_train_male_black_less = sc.fit_transform(x_male_black_less)\n",
    "    y_train_male_black_less = y_male_black_less\n",
    "    \n",
    "#     print(\"fwm: \", X_train_female_white_more.shape, y_train_female_white_more.shape,\n",
    "#           \"fbm: \", X_train_female_black_more.shape, y_train_female_black_more.shape, \n",
    "#             \"fwl: \", X_train_female_white_less.shape, y_train_female_white_less.shape, \n",
    "#             \"fbl: \", X_train_female_black_less.shape,  y_train_female_black_less.shape,\n",
    "#             \"mwm: \", X_train_male_white_more.shape, y_train_male_white_more.shape,\n",
    "#             \"mbm: \", X_train_male_black_more.shape, y_train_male_black_more.shape,\n",
    "#             \"mwl: \", X_train_male_white_less.shape, y_train_male_white_less.shape,\n",
    "#             \"mbl: \", X_train_male_black_less.shape, y_train_male_black_less.shape)\n",
    "\n",
    "    \n",
    "    return [X_train_female_white_more, y_train_female_white_more, \n",
    "            X_train_female_black_more, y_train_female_black_more, \n",
    "            X_train_female_white_less, y_train_female_white_less, \n",
    "            X_train_female_black_less, y_train_female_black_less,\n",
    "            X_train_male_white_more, y_train_male_white_more,\n",
    "            X_train_male_black_more, y_train_male_black_more,\n",
    "            X_train_male_white_less, y_train_male_white_less,\n",
    "            X_train_male_black_less, y_train_male_black_less]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9784339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializer_income_race_gender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f8d5607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hetero_clients_gender_race(train_sets):\n",
    "    data = list(zip(train_sets[0], train_sets[1]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "#     print(type(train_sets), type(train_sets[0]),type(list(list(zip(*data))[0]) ), type(data))\n",
    "    \n",
    "    train_sets[0] = list(list(zip(*data))[0])\n",
    "    train_sets[1] = list(list(zip(*data))[1])\n",
    "    data.clear()\n",
    "    \n",
    "    data = list(zip(train_sets[2], train_sets[3]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    train_sets[2], train_sets[3] = list(zip(*data))[0], list(zip(*data))[1]\n",
    "    data.clear()\n",
    "    data = list(zip(train_sets[4], train_sets[5]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    train_sets[4], train_sets[5] = list(zip(*data))[0], list(zip(*data))[1]\n",
    "    data.clear()\n",
    "    \n",
    "    data = list(zip(train_sets[6], train_sets[7]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    train_sets[6], train_sets[7] = list(zip(*data))[0], list(zip(*data))[1]\n",
    "    data.clear()\n",
    "    \n",
    "    data = list(zip(train_sets[8], train_sets[9]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    train_sets[8], train_sets[9] = list(zip(*data))[0], list(zip(*data))[1]\n",
    "    data.clear()\n",
    "    \n",
    "    data = list(zip(train_sets[10], train_sets[11]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    train_sets[10], train_sets[11] = list(zip(*data))[0], list(zip(*data))[1]\n",
    "    \n",
    "    data = list(zip(train_sets[12], train_sets[13]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    train_sets[12], train_sets[13] = list(zip(*data))[0], list(zip(*data))[1]\n",
    "    data.clear()\n",
    "    \n",
    "    data = list(zip(train_sets[14], train_sets[15]))\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    train_sets[14], train_sets[15] = list(zip(*data))[0], list(zip(*data))[1]\n",
    "    \n",
    "#     for i in range(7):\n",
    "\n",
    "#         data = list(zip(train_sets[i], train_sets[i+1]))\n",
    "#         random.shuffle(data)\n",
    "\n",
    "# #         print(type(train_sets), type(train_sets[0]),type(list(list(zip(*data))[0]) ), type(data))\n",
    "\n",
    "#         train_sets[i], train_sets[i+1] = list(zip(*data))[0], list(zip(*data))[1]\n",
    "#         data.clear()\n",
    "    \n",
    "    \n",
    "    clients, inds, data_out1 = create_hetero_clients(train_sets[0], train_sets[1], start_client = 0, num_clients=1, initial='client') \n",
    "    \n",
    "    clients2, inds2, data_out2 = create_hetero_clients(train_sets[2], train_sets[3], start_client = 1, num_clients=2, initial='client')\n",
    "    clients = {**clients, **clients2}\n",
    "    \n",
    "    clients3, inds3, data_out3 = create_hetero_clients(train_sets[4], train_sets[5], start_client = 2, num_clients=3, initial='client')\n",
    "    clients = {**clients, **clients3}\n",
    "    \n",
    "    clients4, inds4, data_out4 = create_hetero_clients(train_sets[6], train_sets[7], start_client = 3, num_clients=4, initial='client')\n",
    "    clients = {**clients, **clients4}\n",
    "    \n",
    "    clients5, inds5, data_out5 = create_hetero_clients(train_sets[8], train_sets[9], start_client = 4, num_clients=5, initial='client')\n",
    "    clients = {**clients, **clients5}\n",
    "    \n",
    "    clients6, inds6, data_out6 = create_hetero_clients(train_sets[10], train_sets[11], start_client = 5, num_clients=6, initial='client')\n",
    "    clients = {**clients, **clients6}\n",
    "    \n",
    "    clients7, inds7, data_out7 = create_hetero_clients(train_sets[12], train_sets[13], start_client = 6, num_clients=7, initial='client')\n",
    "    clients = {**clients, **clients7}\n",
    "    \n",
    "    clients8, inds8, data_out8 = create_hetero_clients(train_sets[14], train_sets[15], start_client = 7, num_clients= 8, initial='client')\n",
    "    clients = {**clients, **clients8}\n",
    "    \n",
    "    return clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "715ed657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:52.579114Z",
     "start_time": "2021-07-15T23:59:52.576244Z"
    }
   },
   "outputs": [],
   "source": [
    "# take bs = 128 for 5 clients and 10 rounds\n",
    "def batch_data(data_shard, bs=64):\n",
    "    '''Takes in a clients data shard and create a tfds object off it\n",
    "    args:\n",
    "        shard: a data, label constituting a client's data shard\n",
    "        bs:batch size\n",
    "    return:\n",
    "        tfds object'''\n",
    "    data = []\n",
    "    label = []\n",
    "    for x in data_shard:\n",
    "        data.append(x[0])\n",
    "        label.append(x[1])\n",
    "    #seperate shard into data and labels lists\n",
    "#     data, label = zip(*data_shard)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
    "#     print( label[0])\n",
    "    return dataset.shuffle(len(label)).batch(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfd80728",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:54.563066Z",
     "start_time": "2021-07-15T23:59:52.773340Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#process and batch the training data for each client\n",
    "def batch_clients(clients):\n",
    "    clients_batched = dict()\n",
    "    for (client_name, data) in clients.items():\n",
    "#         print(\"data \",len(data))\n",
    "        clients_batched[client_name] = batch_data(data)#non-IID\n",
    "#         clients_batched[client_name] = batch_data(data,1) #IID\n",
    "    \n",
    "\n",
    "    #process and batch the test set  \n",
    "    test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))\n",
    "    \n",
    "#     test_batched\n",
    "    return clients_batched, test_batched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbece235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clients = get_hetero_clients_gender(list(train_sets) )\n",
    "# # print(\"client0: \", clients[0])\n",
    "\n",
    "# clients_batched, test_batched = batch_clients(clients)\n",
    "# print(\"client batched 0: \", len(clients_batched[0]))\n",
    "# print(\"test\" ,X_test.shape)\n",
    "# train_list = initializer_income()\n",
    "# for i in train_list:\n",
    "#     print(i.shape)\n",
    "    \n",
    "# client_names= list(clients_batched.keys())\n",
    "\n",
    "# for client in client_names:\n",
    "#     print(client,\" \", len(clients_batched[client]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dcf2ff7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:54.568193Z",
     "start_time": "2021-07-15T23:59:54.564443Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleMLP:\n",
    "    @staticmethod\n",
    "    def build(shape, classes=2 , learning_rate = 0.001, metric = \"accuracy\"):\n",
    "\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128, input_shape = (shape,)))\n",
    "#         model.add(Dense(128, Activation(\"relu\")))\n",
    "#         model.add(Dense(64, Activation(\"relu\")))\n",
    "#         model.add(Dense(32, Activation(\"relu\")))\n",
    "#         model.add(Dense(1))\n",
    "        \n",
    "        model.add(Dense(128, Activation(\"tanh\")))\n",
    "        model.add(Dense(64, Activation(\"tanh\")))\n",
    "        model.add(Dense(32, Activation(\"tanh\")))\n",
    "        model.add(Dense(1,Activation('sigmoid')))\n",
    "        \n",
    "\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f71dc14a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:00:30.156165Z",
     "start_time": "2021-07-16T00:00:30.152576Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.005\n",
    "comms_round = 10\n",
    "loss=tf.keras.losses.BinaryCrossentropy(from_logits = False)\n",
    "\n",
    "metrics = ['binary_accuracy']\n",
    "\n",
    "optimizer = SGD(learning_rate=lr, \n",
    "                decay=lr / comms_round, \n",
    "                momentum=0.5\n",
    "               )     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eebf9376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:00:30.412962Z",
     "start_time": "2021-07-16T00:00:30.399142Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def weight_scalling_factor(clients_trn_data, client_name):\n",
    "    client_names = list(clients_trn_data.keys())\n",
    "    #get the bs\n",
    "    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
    "    #first calculate the total training data points across clinets\n",
    "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n",
    "    # get the total number of data points held by a client\n",
    "    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n",
    "    return local_count/global_count\n",
    "\n",
    "\n",
    "def scale_model_weights(weight, scalar):\n",
    "    '''function for scaling a models weights'''\n",
    "    weight_final = []\n",
    "    steps = len(weight)\n",
    "    for i in range(steps):\n",
    "        weight_final.append(scalar * weight[i])\n",
    "    return weight_final\n",
    "\n",
    "\n",
    "\n",
    "def sum_scaled_weights(scaled_weight_list):\n",
    "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
    "    avg_grad = list()\n",
    "    #get the average grad accross all client gradients\n",
    "#     print(len(scaled_weight_list))\n",
    "    for grad_list_tuple in zip(*scaled_weight_list):\n",
    "#         print(len(grad_list_tuple))\n",
    "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
    "        avg_grad.append(layer_mean)\n",
    "        \n",
    "    return avg_grad\n",
    "\n",
    "\n",
    "def test_model(X_test, Y_test,  model, comm_round):\n",
    "    \n",
    "#     cce = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "#     cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    logits = model.predict(X_test)\n",
    "\n",
    "    score = global_model.evaluate(X_test, y_test, verbose=0)\n",
    "    acc = score[1] ; loss = score[0]\n",
    "    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n",
    "\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4aef41d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:01:47.756094Z",
     "start_time": "2021-07-16T00:00:30.586083Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154/154 [==============================] - 0s 2ms/step - loss: 0.6520 - binary_accuracy: 0.6244\n",
      "client 0 loss --> [0.6520453095436096] freq-> [154] accuracy-> [0.6243902444839478]\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6949 - binary_accuracy: 0.5042\n",
      "client 5 loss --> [0.6948809623718262] freq-> [42] accuracy-> [0.5041666626930237]\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.7229 - binary_accuracy: 0.4250\n",
      "client 1 loss --> [0.722898006439209] freq-> [12] accuracy-> [0.42500001192092896]\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.4156 - binary_accuracy: 0.9039\n",
      "client 4 loss --> [0.4156477153301239] freq-> [900] accuracy-> [0.9039409756660461]\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 0.6314 - binary_accuracy: 0.6750\n",
      "client 3 loss --> [0.6314299702644348] freq-> [214] accuracy-> [0.675000011920929]\n",
      "1921/1921 [==============================] - 6s 3ms/step - loss: 0.2977 - binary_accuracy: 0.9430\n",
      "client 6 loss --> [0.2976628541946411] freq-> [1921] accuracy-> [0.9430453777313232]\n",
      "1504/1504 [==============================] - 5s 3ms/step - loss: 0.3610 - binary_accuracy: 0.9230\n",
      "client 7 loss --> [0.36101633310317993] freq-> [1504] accuracy-> [0.9229738116264343]\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 0.4114 - binary_accuracy: 0.9062\n",
      "client 2 loss --> [0.41144952178001404] freq-> [1148] accuracy-> [0.90625]\n",
      "comm_round: 0 | global_acc: 73.864% | global_loss: 0.6113995909690857\n",
      "global_loss_list:  [0.6113995909690857]\n",
      "global_acc_list:  [0.7386363744735718]\n",
      "global_freq_list:  [5895]\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.4985 - binary_accuracy: 0.0000e+00\n",
      "client 1 loss --> [0.72289801 1.49852931] freq-> [12 13] accuracy-> [0.42500001 0.        ]\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.4167 - binary_accuracy: 0.0084\n",
      "client 5 loss --> [0.69488096 1.41669953] freq-> [42 47] accuracy-> [0.50416666 0.00841751]\n",
      "1013/1013 [==============================] - 3s 3ms/step - loss: 0.7179 - binary_accuracy: 0.5458\n",
      "client 4 loss --> [0.41564772 0.71785086] freq-> [ 900 1013] accuracy-> [0.90394098 0.54584879]\n",
      "2168/2168 [==============================] - 7s 3ms/step - loss: 0.1333 - binary_accuracy: 0.9967\n",
      "client 6 loss --> [0.29766285 0.13327065] freq-> [1921 2168] accuracy-> [0.94304538 0.99666232]\n",
      "241/241 [==============================] - 1s 3ms/step - loss: 0.2558 - binary_accuracy: 0.9891\n",
      "client 3 loss --> [0.63142997 0.25575614] freq-> [214 241] accuracy-> [0.67500001 0.98908383]\n",
      "1291/1291 [==============================] - 3s 3ms/step - loss: 0.1704 - binary_accuracy: 0.9952\n",
      "client 2 loss --> [0.41144952 0.17041089] freq-> [1148 1291] accuracy-> [0.90625    0.99518275]\n",
      "1529/1529 [==============================] - 5s 3ms/step - loss: 0.1661 - binary_accuracy: 0.9958\n",
      "client 7 loss --> [0.36101633 0.16614816] freq-> [1504 1529] accuracy-> [0.92297381 0.99583846]\n",
      "173/173 [==============================] - 0s 3ms/step - loss: 1.3222 - binary_accuracy: 0.0170\n",
      "client 0 loss --> [0.65204531 1.32216609] freq-> [154 173] accuracy-> [0.62439024 0.01698284]\n",
      "comm_round: 1 | global_acc: 74.601% | global_loss: 0.6273488998413086\n",
      "global_loss_list:  [0.6113995909690857, 0.6273488998413086]\n",
      "global_acc_list:  [0.7386363744735718, 0.7460073828697205]\n",
      "global_freq_list:  [5895, 6475]\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 1.6544 - binary_accuracy: 0.0069\n",
      "client 0 loss --> [0.65204531 1.32216609 1.65442705] freq-> [154 173 193] accuracy-> [0.62439024 0.01698284 0.00691057]\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.0052 - binary_accuracy: 0.0000e+00\n",
      "client 1 loss --> [0.72289801 1.49852931 2.00516534] freq-> [12 13 15] accuracy-> [0.42500001 0.         0.        ]\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 0.8554 - binary_accuracy: 0.4589\n",
      "client 4 loss --> [0.41564772 0.71785086 0.85538751] freq-> [ 900 1013 1125] accuracy-> [0.90394098 0.54584879 0.458875  ]\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 0.1523 - binary_accuracy: 0.9962\n",
      "client 3 loss --> [0.63142997 0.25575614 0.15227449] freq-> [214 241 268] accuracy-> [0.67500001 0.98908383 0.99619883]\n",
      "2415/2415 [==============================] - 7s 3ms/step - loss: 0.0882 - binary_accuracy: 0.9978\n",
      "client 6 loss --> [0.29766285 0.13327065 0.08817774] freq-> [1921 2168 2415] accuracy-> [0.94304538 0.99666232 0.99784464]\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.8926 - binary_accuracy: 0.0027\n",
      "client 5 loss --> [0.69488096 1.41669953 1.89260554] freq-> [42 47 52] accuracy-> [0.50416666 0.00841751 0.00272727]\n",
      "1435/1435 [==============================] - 4s 3ms/step - loss: 0.1078 - binary_accuracy: 0.9969\n",
      "client 2 loss --> [0.41144952 0.17041089 0.1078152 ] freq-> [1148 1291 1435] accuracy-> [0.90625    0.99518275 0.99690634]\n",
      "   1/1553 [..............................] - ETA: 0s - loss: 0.1736 - binary_accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0045s). Check your callbacks.\n",
      "1553/1553 [==============================] - 5s 3ms/step - loss: 0.1084 - binary_accuracy: 0.9972\n",
      "client 7 loss --> [0.36101633 0.16614816 0.10835388] freq-> [1504 1529 1553] accuracy-> [0.92297381 0.99583846 0.99716187]\n",
      "comm_round: 2 | global_acc: 74.795% | global_loss: 0.6444299817085266\n",
      "global_loss_list:  [0.6113995909690857, 0.6273488998413086, 0.6444299817085266]\n",
      "global_acc_list:  [0.7386363744735718, 0.7460073828697205, 0.7479525208473206]\n",
      "global_freq_list:  [5895, 6475, 7056]\n",
      "294/294 [==============================] - 1s 3ms/step - loss: 0.1192 - binary_accuracy: 0.9968\n",
      "client 3 loss --> [0.63142997 0.25575614 0.15227449 0.1191789 ] freq-> [214 241 268 294] accuracy-> [0.67500001 0.98908383 0.99619883 0.9968102 ]\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.2509 - binary_accuracy: 0.0000e+00\n",
      "client 1 loss --> [0.72289801 1.49852931 2.00516534 2.25087428] freq-> [12 13 15 16] accuracy-> [0.42500001 0.         0.         0.        ]\n",
      "1238/1238 [==============================] - 3s 2ms/step - loss: 0.8962 - binary_accuracy: 0.4617\n",
      "client 4 loss --> [0.41564772 0.71785086 0.85538751 0.89620405] freq-> [ 900 1013 1125 1238] accuracy-> [0.90394098 0.54584879 0.458875   0.46171716]\n",
      "2661/2661 [==============================] - 8s 3ms/step - loss: 0.0717 - binary_accuracy: 0.9987\n",
      "client 6 loss --> [0.29766285 0.13327065 0.08817774 0.07168613] freq-> [1921 2168 2415 2661] accuracy-> [0.94304538 0.99666232 0.99784464 0.99869627]\n",
      "1577/1577 [==============================] - 5s 3ms/step - loss: 0.0874 - binary_accuracy: 0.9982\n",
      "client 7 loss --> [0.36101633 0.16614816 0.10835388 0.08735743] freq-> [1504 1529 1553 1577] accuracy-> [0.92297381 0.99583846 0.99716187 0.99824613]\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 2.1194 - binary_accuracy: 0.0000e+00\n",
      "client 5 loss --> [0.69488096 1.41669953 1.89260554 2.11936712] freq-> [42 47 52 57] accuracy-> [0.50416666 0.00841751 0.00272727 0.        ]\n",
      "212/212 [==============================] - 0s 2ms/step - loss: 1.8775 - binary_accuracy: 0.0062\n",
      "client 0 loss --> [0.65204531 1.32216609 1.65442705 1.87752938] freq-> [154 173 193 212] accuracy-> [0.62439024 0.01698284 0.00691057 0.00620843]\n",
      "1578/1578 [==============================] - 4s 3ms/step - loss: 0.0870 - binary_accuracy: 0.9978\n",
      "client 2 loss --> [0.41144952 0.17041089 0.1078152  0.08696163] freq-> [1148 1291 1435 1578] accuracy-> [0.90625    0.99518275 0.99690634 0.99779165]\n",
      "comm_round: 3 | global_acc: 74.826% | global_loss: 0.6532267928123474\n",
      "global_loss_list:  [0.6113995909690857, 0.6273488998413086, 0.6444299817085266, 0.6532267928123474]\n",
      "global_acc_list:  [0.7386363744735718, 0.7460073828697205, 0.7479525208473206, 0.7482596039772034]\n",
      "global_freq_list:  [5895, 6475, 7056, 7633]\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 2.2073 - binary_accuracy: 0.0000e+00\n",
      "client 5 loss --> [0.69488096 1.41669953 1.89260554 2.11936712 2.2073369 ] freq-> [42 47 52 57 62] accuracy-> [0.50416666 0.00841751 0.00272727 0.         0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 1s 3ms/step - loss: 0.1057 - binary_accuracy: 0.9972\n",
      "client 3 loss --> [0.63142997 0.25575614 0.15227449 0.1191789  0.10566977] freq-> [214 241 268 294 321] accuracy-> [0.67500001 0.98908383 0.99619883 0.9968102  0.99717349]\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0774 - binary_accuracy: 0.9988\n",
      "client 7 loss --> [0.36101633 0.16614816 0.10835388 0.08735743 0.07736473] freq-> [1504 1529 1553 1577 1602] accuracy-> [0.92297381 0.99583846 0.99716187 0.99824613 0.99877048]\n",
      "1350/1350 [==============================] - 4s 3ms/step - loss: 0.9111 - binary_accuracy: 0.4711\n",
      "client 4 loss --> [0.41564772 0.71785086 0.85538751 0.89620405 0.91105551] freq-> [ 900 1013 1125 1238 1350] accuracy-> [0.90394098 0.54584879 0.458875   0.46171716 0.4710764 ]\n",
      "2908/2908 [==============================] - 6s 2ms/step - loss: 0.0651 - binary_accuracy: 0.9990\n",
      "client 6 loss --> [0.29766285 0.13327065 0.08817774 0.07168613 0.06509247] freq-> [1921 2168 2415 2661 2908] accuracy-> [0.94304538 0.99666232 0.99784464 0.99869627 0.99902183]\n",
      "1722/1722 [==============================] - 5s 3ms/step - loss: 0.0770 - binary_accuracy: 0.9987\n",
      "client 2 loss --> [0.41144952 0.17041089 0.1078152  0.08696163 0.07697608] freq-> [1148 1291 1435 1578 1722] accuracy-> [0.90625    0.99518275 0.99690634 0.99779165 0.99872911]\n",
      "231/231 [==============================] - 1s 3ms/step - loss: 1.9614 - binary_accuracy: 0.0057\n",
      "client 0 loss --> [0.65204531 1.32216609 1.65442705 1.87752938 1.96135139] freq-> [154 173 193 212 231] accuracy-> [0.62439024 0.01698284 0.00691057 0.00620843 0.00569106]\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 2.3779 - binary_accuracy: 0.0000e+00\n",
      "client 1 loss --> [0.72289801 1.49852931 2.00516534 2.25087428 2.37785101] freq-> [12 13 15 16 17] accuracy-> [0.42500001 0.         0.         0.         0.        ]\n",
      "comm_round: 4 | global_acc: 74.877% | global_loss: 0.6582056283950806\n",
      "global_loss_list:  [0.6113995909690857, 0.6273488998413086, 0.6444299817085266, 0.6532267928123474, 0.6582056283950806]\n",
      "global_acc_list:  [0.7386363744735718, 0.7460073828697205, 0.7479525208473206, 0.7482596039772034, 0.7487714886665344]\n",
      "global_freq_list:  [5895, 6475, 7056, 7633, 8213]\n",
      "1463/1463 [==============================] - 5s 3ms/step - loss: 0.8668 - binary_accuracy: 0.5209\n",
      "client 4 loss --> [0.41564772 0.71785086 0.85538751 0.89620405 0.91105551 0.86678201] freq-> [ 900 1013 1125 1238 1350 1463] accuracy-> [0.90394098 0.54584879 0.458875   0.46171716 0.4710764  0.52091879]\n",
      "3154/3154 [==============================] - 10s 3ms/step - loss: 0.0602 - binary_accuracy: 0.9990\n",
      "client 6 loss --> [0.29766285 0.13327065 0.08817774 0.07168613 0.06509247 0.06022613] freq-> [1921 2168 2415 2661 2908 3154] accuracy-> [0.94304538 0.99666232 0.99784464 0.99869627 0.99902183 0.99897444]\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.0712 - binary_accuracy: 0.9990\n",
      "client 2 loss --> [0.41144952 0.17041089 0.1078152  0.08696163 0.07697608 0.07115313] freq-> [1148 1291 1435 1578 1722 1865] accuracy-> [0.90625    0.99518275 0.99690634 0.99779165 0.99872911 0.99901122]\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 1.9703 - binary_accuracy: 0.0046\n",
      "client 0 loss --> [0.65204531 1.32216609 1.65442705 1.87752938 1.96135139 1.97029376] freq-> [154 173 193 212 231 250] accuracy-> [0.62439024 0.01698284 0.00691057 0.00620843 0.00569106 0.00456535]\n",
      "348/348 [==============================] - 1s 3ms/step - loss: 0.1000 - binary_accuracy: 0.9967\n",
      "client 3 loss --> [0.63142997 0.25575614 0.15227449 0.1191789  0.10566977 0.09996787] freq-> [214 241 268 294 321 348] accuracy-> [0.67500001 0.98908383 0.99619883 0.9968102  0.99717349 0.99671614]\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 2.2749 - binary_accuracy: 0.0000e+00\n",
      "client 5 loss --> [0.69488096 1.41669953 1.89260554 2.11936712 2.2073369  2.27492952] freq-> [42 47 52 57 62 68] accuracy-> [0.50416666 0.00841751 0.00272727 0.         0.         0.        ]\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.4381 - binary_accuracy: 0.0000e+00\n",
      "client 1 loss --> [0.72289801 1.49852931 2.00516534 2.25087428 2.37785101 2.43814564] freq-> [12 13 15 16 17 19] accuracy-> [0.42500001 0.         0.         0.         0.         0.        ]\n",
      "1626/1626 [==============================] - 5s 3ms/step - loss: 0.0758 - binary_accuracy: 0.9987\n",
      "client 7 loss --> [0.36101633 0.16614816 0.10835388 0.08735743 0.07736473 0.07575239] freq-> [1504 1529 1553 1577 1602 1626] accuracy-> [0.92297381 0.99583846 0.99716187 0.99824613 0.99877048 0.99870241]\n",
      "comm_round: 5 | global_acc: 74.805% | global_loss: 0.6601266860961914\n",
      "global_loss_list:  [0.6113995909690857, 0.6273488998413086, 0.6444299817085266, 0.6532267928123474, 0.6582056283950806, 0.6601266860961914]\n",
      "global_acc_list:  [0.7386363744735718, 0.7460073828697205, 0.7479525208473206, 0.7482596039772034, 0.7487714886665344, 0.7480548620223999]\n",
      "global_freq_list:  [5895, 6475, 7056, 7633, 8213, 8793]\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0968 - binary_accuracy: 0.9968\n",
      "client 3 loss --> [0.63142997 0.25575614 0.15227449 0.1191789  0.10566977 0.09996787\n",
      " 0.09680084] freq-> [214 241 268 294 321 348 375] accuracy-> [0.67500001 0.98908383 0.99619883 0.9968102  0.99717349 0.99671614\n",
      " 0.99678361]\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 2.4508 - binary_accuracy: 0.0000e+00\n",
      "client 1 loss --> [0.72289801 1.49852931 2.00516534 2.25087428 2.37785101 2.43814564\n",
      " 2.45077205] freq-> [12 13 15 16 17 19 20] accuracy-> [0.42500001 0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "3401/3401 [==============================] - 11s 3ms/step - loss: 0.0580 - binary_accuracy: 0.9990\n",
      "client 6 loss --> [0.29766285 0.13327065 0.08817774 0.07168613 0.06509247 0.06022613\n",
      " 0.05800061] freq-> [1921 2168 2415 2661 2908 3154 3401] accuracy-> [0.94304538 0.99666232 0.99784464 0.99869627 0.99902183 0.99897444\n",
      " 0.99900287]\n",
      "1575/1575 [==============================] - 5s 3ms/step - loss: 0.8590 - binary_accuracy: 0.5361\n",
      "client 4 loss --> [0.41564772 0.71785086 0.85538751 0.89620405 0.91105551 0.86678201\n",
      " 0.85903096] freq-> [ 900 1013 1125 1238 1350 1463 1575] accuracy-> [0.90394098 0.54584879 0.458875   0.46171716 0.4710764  0.52091879\n",
      " 0.53606153]\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 1.9430 - binary_accuracy: 0.0048\n",
      "client 0 loss --> [0.65204531 1.32216609 1.65442705 1.87752938 1.96135139 1.97029376\n",
      " 1.94301367] freq-> [154 173 193 212 231 250 270] accuracy-> [0.62439024 0.01698284 0.00691057 0.00620843 0.00569106 0.00456535\n",
      " 0.00481998]\n",
      "1650/1650 [==============================] - 5s 3ms/step - loss: 0.0740 - binary_accuracy: 0.9987\n",
      "client 7 loss --> [0.36101633 0.16614816 0.10835388 0.08735743 0.07736473 0.07575239\n",
      " 0.07398056] freq-> [1504 1529 1553 1577 1602 1626 1650] accuracy-> [0.92297381 0.99583846 0.99716187 0.99824613 0.99877048 0.99870241\n",
      " 0.99871212]\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2.2805 - binary_accuracy: 0.0000e+00\n",
      "client 5 loss --> [0.69488096 1.41669953 1.89260554 2.11936712 2.2073369  2.27492952\n",
      " 2.28054476] freq-> [42 47 52 57 62 68 73] accuracy-> [0.50416666 0.00841751 0.00272727 0.         0.         0.\n",
      " 0.        ]\n",
      "2009/2009 [==============================] - 6s 3ms/step - loss: 0.0694 - binary_accuracy: 0.9990\n",
      "client 2 loss --> [0.41144952 0.17041089 0.1078152  0.08696163 0.07697608 0.07115313\n",
      " 0.06942742] freq-> [1148 1291 1435 1578 1722 1865 2009] accuracy-> [0.90625    0.99518275 0.99690634 0.99779165 0.99872911 0.99901122\n",
      " 0.99903518]\n",
      "comm_round: 6 | global_acc: 74.765% | global_loss: 0.6639480590820312\n",
      "global_loss_list:  [0.6113995909690857, 0.6273488998413086, 0.6444299817085266, 0.6532267928123474, 0.6582056283950806, 0.6601266860961914, 0.6639480590820312]\n",
      "global_acc_list:  [0.7386363744735718, 0.7460073828697205, 0.7479525208473206, 0.7482596039772034, 0.7487714886665344, 0.7480548620223999, 0.747645378112793]\n",
      "global_freq_list:  [5895, 6475, 7056, 7633, 8213, 8793, 9373]\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.7942 - binary_accuracy: 0.5885\n",
      "client 4 loss --> [0.41564772 0.71785086 0.85538751 0.89620405 0.91105551 0.86678201\n",
      " 0.85903096 0.79422253] freq-> [ 900 1013 1125 1238 1350 1463 1575 1688] accuracy-> [0.90394098 0.54584879 0.458875   0.46171716 0.4710764  0.52091879\n",
      " 0.53606153 0.5885185 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/401 [==============================] - 1s 3ms/step - loss: 0.0949 - binary_accuracy: 0.9966\n",
      "client 3 loss --> [0.63142997 0.25575614 0.15227449 0.1191789  0.10566977 0.09996787\n",
      " 0.09680084 0.09486126] freq-> [214 241 268 294 321 348 375 401] accuracy-> [0.67500001 0.98908383 0.99619883 0.9968102  0.99717349 0.99671614\n",
      " 0.99678361 0.99656922]\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 1.9033 - binary_accuracy: 0.0053\n",
      "client 0 loss --> [0.65204531 1.32216609 1.65442705 1.87752938 1.96135139 1.97029376\n",
      " 1.94301367 1.90330005] freq-> [154 173 193 212 231 250 270 289] accuracy-> [0.62439024 0.01698284 0.00691057 0.00620843 0.00569106 0.00456535\n",
      " 0.00481998 0.00525745]\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 2.2754 - binary_accuracy: 0.0024\n",
      "client 5 loss --> [0.69488096 1.41669953 1.89260554 2.11936712 2.2073369  2.27492952\n",
      " 2.28054476 2.27543497] freq-> [42 47 52 57 62 68 73 78] accuracy-> [0.50416666 0.00841751 0.00272727 0.         0.         0.\n",
      " 0.         0.00242424]\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.4692 - binary_accuracy: 0.0000e+00\n",
      "client 1 loss --> [0.72289801 1.49852931 2.00516534 2.25087428 2.37785101 2.43814564\n",
      " 2.45077205 2.46920943] freq-> [12 13 15 16 17 19 20 22] accuracy-> [0.42500001 0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "1675/1675 [==============================] - 5s 3ms/step - loss: 0.0720 - binary_accuracy: 0.9987\n",
      "client 7 loss --> [0.36101633 0.16614816 0.10835388 0.08735743 0.07736473 0.07575239\n",
      " 0.07398056 0.07203526] freq-> [1504 1529 1553 1577 1602 1626 1650 1675] accuracy-> [0.92297381 0.99583846 0.99716187 0.99824613 0.99877048 0.99870241\n",
      " 0.99871212 0.99866557]\n",
      "2152/2152 [==============================] - 7s 3ms/step - loss: 0.0664 - binary_accuracy: 0.9992\n",
      "client 2 loss --> [0.41144952 0.17041089 0.1078152  0.08696163 0.07697608 0.07115313\n",
      " 0.06942742 0.06638124] freq-> [1148 1291 1435 1578 1722 1865 2009 2152] accuracy-> [0.90625    0.99518275 0.99690634 0.99779165 0.99872911 0.99901122\n",
      " 0.99903518 0.99915034]\n",
      "3647/3647 [==============================] - 13s 3ms/step - loss: 0.0579 - binary_accuracy: 0.9990\n",
      "client 6 loss --> [0.29766285 0.13327065 0.08817774 0.07168613 0.06509247 0.06022613\n",
      " 0.05800061 0.05786391] freq-> [1921 2168 2415 2661 2908 3154 3401 3647] accuracy-> [0.94304538 0.99666232 0.99784464 0.99869627 0.99902183 0.99897444\n",
      " 0.99900287 0.99902314]\n",
      "comm_round: 7 | global_acc: 74.693% | global_loss: 0.6651818752288818\n",
      "global_loss_list:  [0.6113995909690857, 0.6273488998413086, 0.6444299817085266, 0.6532267928123474, 0.6582056283950806, 0.6601266860961914, 0.6639480590820312, 0.6651818752288818]\n",
      "global_acc_list:  [0.7386363744735718, 0.7460073828697205, 0.7479525208473206, 0.7482596039772034, 0.7487714886665344, 0.7480548620223999, 0.747645378112793, 0.7469287514686584]\n",
      "global_freq_list:  [5895, 6475, 7056, 7633, 8213, 8793, 9373, 9952]\n",
      "1699/1699 [==============================] - 6s 3ms/step - loss: 0.0723 - binary_accuracy: 0.9987\n",
      "client 7 loss --> [0.36101633 0.16614816 0.10835388 0.08735743 0.07736473 0.07575239\n",
      " 0.07398056 0.07203526 0.07229277] freq-> [1504 1529 1553 1577 1602 1626 1650 1675 1699] accuracy-> [0.92297381 0.99583846 0.99716187 0.99824613 0.99877048 0.99870241\n",
      " 0.99871212 0.99866557 0.99867553]\n",
      "3894/3894 [==============================] - 15s 4ms/step - loss: 0.0562 - binary_accuracy: 0.9991\n",
      "client 6 loss --> [0.29766285 0.13327065 0.08817774 0.07168613 0.06509247 0.06022613\n",
      " 0.05800061 0.05786391 0.05624533] freq-> [1921 2168 2415 2661 2908 3154 3401 3647 3894] accuracy-> [0.94304538 0.99666232 0.99784464 0.99869627 0.99902183 0.99897444\n",
      " 0.99900287 0.99902314 0.999089  ]\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.4550 - binary_accuracy: 0.0000e+00\n",
      "client 1 loss --> [0.72289801 1.49852931 2.00516534 2.25087428 2.37785101 2.43814564\n",
      " 2.45077205 2.46920943 2.4550333 ] freq-> [12 13 15 16 17 19 20 22 23] accuracy-> [0.42500001 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "1800/1800 [==============================] - 6s 3ms/step - loss: 0.7825 - binary_accuracy: 0.5984\n",
      "client 4 loss --> [0.41564772 0.71785086 0.85538751 0.89620405 0.91105551 0.86678201\n",
      " 0.85903096 0.79422253 0.78250259] freq-> [ 900 1013 1125 1238 1350 1463 1575 1688 1800] accuracy-> [0.90394098 0.54584879 0.458875   0.46171716 0.4710764  0.52091879\n",
      " 0.53606153 0.5885185  0.59837675]\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.2590 - binary_accuracy: 0.0030\n",
      "client 5 loss --> [0.69488096 1.41669953 1.89260554 2.11936712 2.2073369  2.27492952\n",
      " 2.28054476 2.27543497 2.25895619] freq-> [42 47 52 57 62 68 73 78 83] accuracy-> [0.50416666 0.00841751 0.00272727 0.         0.         0.\n",
      " 0.         0.00242424 0.0030303 ]\n",
      "2295/2295 [==============================] - 5s 2ms/step - loss: 0.0666 - binary_accuracy: 0.9993\n",
      "client 2 loss --> [0.41144952 0.17041089 0.1078152  0.08696163 0.07697608 0.07115313\n",
      " 0.06942742 0.06638124 0.06655346] freq-> [1148 1291 1435 1578 1722 1865 2009 2152 2295] accuracy-> [0.90625    0.99518275 0.99690634 0.99779165 0.99872911 0.99901122\n",
      " 0.99903518 0.99915034 0.99927831]\n",
      "428/428 [==============================] - 1s 2ms/step - loss: 0.0963 - binary_accuracy: 0.9962\n",
      "client 3 loss --> [0.63142997 0.25575614 0.15227449 0.1191789  0.10566977 0.09996787\n",
      " 0.09680084 0.09486126 0.09631293] freq-> [214 241 268 294 321 348 375 401 428] accuracy-> [0.67500001 0.98908383 0.99619883 0.9968102  0.99717349 0.99671614\n",
      " 0.99678361 0.99656922 0.99619883]\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 1.9026 - binary_accuracy: 0.0050\n",
      "client 0 loss --> [0.65204531 1.32216609 1.65442705 1.87752938 1.96135139 1.97029376\n",
      " 1.94301367 1.90330005 1.90260971] freq-> [154 173 193 212 231 250 270 289 308] accuracy-> [0.62439024 0.01698284 0.00691057 0.00620843 0.00569106 0.00456535\n",
      " 0.00481998 0.00525745 0.00497967]\n",
      "comm_round: 8 | global_acc: 74.672% | global_loss: 0.6713257431983948\n",
      "global_loss_list:  [0.6113995909690857, 0.6273488998413086, 0.6444299817085266, 0.6532267928123474, 0.6582056283950806, 0.6601266860961914, 0.6639480590820312, 0.6651818752288818, 0.6713257431983948]\n",
      "global_acc_list:  [0.7386363744735718, 0.7460073828697205, 0.7479525208473206, 0.7482596039772034, 0.7487714886665344, 0.7480548620223999, 0.747645378112793, 0.7469287514686584, 0.746724009513855]\n",
      "global_freq_list:  [5895, 6475, 7056, 7633, 8213, 8793, 9373, 9952, 10530]\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.4696 - binary_accuracy: 0.0000e+00\n",
      "client 1 loss --> [0.72289801 1.49852931 2.00516534 2.25087428 2.37785101 2.43814564\n",
      " 2.45077205 2.46920943 2.4550333  2.46961331] freq-> [12 13 15 16 17 19 20 22 23 24] accuracy-> [0.42500001 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "1724/1724 [==============================] - 4s 2ms/step - loss: 0.0713 - binary_accuracy: 0.9987\n",
      "client 7 loss --> [0.36101633 0.16614816 0.10835388 0.08735743 0.07736473 0.07575239\n",
      " 0.07398056 0.07203526 0.07229277 0.0713386 ] freq-> [1504 1529 1553 1577 1602 1626 1650 1675 1699 1724] accuracy-> [0.92297381 0.99583846 0.99716187 0.99824613 0.99877048 0.99870241\n",
      " 0.99871212 0.99866557 0.99867553 0.99867612]\n",
      "327/327 [==============================] - 1s 2ms/step - loss: 1.8362 - binary_accuracy: 0.0054\n",
      "client 0 loss --> [0.65204531 1.32216609 1.65442705 1.87752938 1.96135139 1.97029376\n",
      " 1.94301367 1.90330005 1.90260971 1.83616412] freq-> [154 173 193 212 231 250 270 289 308 327] accuracy-> [0.62439024 0.01698284 0.00691057 0.00620843 0.00569106 0.00456535\n",
      " 0.00481998 0.00525745 0.00497967 0.00540411]\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 2.2516 - binary_accuracy: 0.0030\n",
      "client 5 loss --> [0.69488096 1.41669953 1.89260554 2.11936712 2.2073369  2.27492952\n",
      " 2.28054476 2.27543497 2.25895619 2.25160861] freq-> [42 47 52 57 62 68 73 78 83 88] accuracy-> [0.50416666 0.00841751 0.00272727 0.         0.         0.\n",
      " 0.         0.00242424 0.0030303  0.0030303 ]\n",
      "1913/1913 [==============================] - 6s 3ms/step - loss: 0.7308 - binary_accuracy: 0.6364\n",
      "client 4 loss --> [0.41564772 0.71785086 0.85538751 0.89620405 0.91105551 0.86678201\n",
      " 0.85903096 0.79422253 0.78250259 0.73078024] freq-> [ 900 1013 1125 1238 1350 1463 1575 1688 1800 1913] accuracy-> [0.90394098 0.54584879 0.458875   0.46171716 0.4710764  0.52091879\n",
      " 0.53606153 0.5885185  0.59837675 0.63639706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2439/2439 [==============================] - 8s 3ms/step - loss: 0.0639 - binary_accuracy: 0.9994\n",
      "client 2 loss --> [0.41144952 0.17041089 0.1078152  0.08696163 0.07697608 0.07115313\n",
      " 0.06942742 0.06638124 0.06655346 0.06392072] freq-> [1148 1291 1435 1578 1722 1865 2009 2152 2295 2439] accuracy-> [0.90625    0.99518275 0.99690634 0.99779165 0.99872911 0.99901122\n",
      " 0.99903518 0.99915034 0.99927831 0.99937844]\n",
      "4140/4140 [==============================] - 16s 4ms/step - loss: 0.0557 - binary_accuracy: 0.9992\n",
      "client 6 loss --> [0.29766285 0.13327065 0.08817774 0.07168613 0.06509247 0.06022613\n",
      " 0.05800061 0.05786391 0.05624533 0.05568424] freq-> [1921 2168 2415 2661 2908 3154 3401 3647 3894 4140] accuracy-> [0.94304538 0.99666232 0.99784464 0.99869627 0.99902183 0.99897444\n",
      " 0.99900287 0.99902314 0.999089   0.99917346]\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 0.0945 - binary_accuracy: 0.9959\n",
      "client 3 loss --> [0.63142997 0.25575614 0.15227449 0.1191789  0.10566977 0.09996787\n",
      " 0.09680084 0.09486126 0.09631293 0.09454678] freq-> [214 241 268 294 321 348 375 401 428 455] accuracy-> [0.67500001 0.98908383 0.99619883 0.9968102  0.99717349 0.99671614\n",
      " 0.99678361 0.99656922 0.99619883 0.99590641]\n",
      "comm_round: 9 | global_acc: 74.652% | global_loss: 0.674037516117096\n",
      "global_loss_list:  [0.6113995909690857, 0.6273488998413086, 0.6444299817085266, 0.6532267928123474, 0.6582056283950806, 0.6601266860961914, 0.6639480590820312, 0.6651818752288818, 0.6713257431983948, 0.674037516117096]\n",
      "global_acc_list:  [0.7386363744735718, 0.7460073828697205, 0.7479525208473206, 0.7482596039772034, 0.7487714886665344, 0.7480548620223999, 0.747645378112793, 0.7469287514686584, 0.746724009513855, 0.7465192675590515]\n",
      "global_freq_list:  [5895, 6475, 7056, 7633, 8213, 8793, 9373, 9952, 10530, 11110]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#initialize global model\n",
    "smlp_global = SimpleMLP()\n",
    "global_model = smlp_global.build(X_train.shape[1] ,classes=2)\n",
    "global_model.compile(optimizer=optimizer, loss=loss, metrics=metrics) \n",
    "client_names = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "# client_names = [0, 1, 2, 3]\n",
    "global_loss_list = []\n",
    "global_freq_list = []\n",
    "global_acc_list = []\n",
    "client_loss = {i: np.array([]) for i in range(len(client_names))}\n",
    "client_accuracy = {i: np.array([]) for i in range(len(client_names))}\n",
    "client_frequency = {i: np.array([]) for i in range(len(client_names))}\n",
    "\n",
    "# train_sets = initializer_income()\n",
    "train_sets = initializer_income_race_gender()\n",
    "# print(\"TRAIN SETS\", len(train_sets))\n",
    "\n",
    "#commence global training loop\n",
    "for comm_round in range(comms_round):\n",
    "    epoch_freq = 0\n",
    "#     clients = create_clients(X_train, y_train, num_clients=15, initial='client')\n",
    "#     clients = get_hetero_clients()\n",
    "#     clients = get_hetero_clients_gender(list(train_sets) )\n",
    "    clients = get_hetero_clients_gender_race(list(train_sets) )\n",
    "\n",
    "    clients_batched, test_batched = batch_clients(clients)\n",
    "#     print(len(clients_batched))\n",
    "    \n",
    "    # get the global model's weights - will serve as the initial weights for all local models\n",
    "    global_weights = global_model.get_weights()\n",
    "    \n",
    "    #initial list to collect local model weights after scalling\n",
    "    scaled_local_weight_list = list()\n",
    "\n",
    "    #randomize client data - using keys\n",
    "    client_names= list(clients_batched.keys())\n",
    "    random.shuffle(client_names)\n",
    "    \n",
    "    #loop through each client and create new local model\n",
    "    for client in client_names:\n",
    "        smlp_local = SimpleMLP()\n",
    "        local_model = smlp_local.build(X_train.shape[1],classes=2)\n",
    "        local_model.compile(loss=loss, \n",
    "                      optimizer=optimizer, \n",
    "                      metrics=metrics)\n",
    "        \n",
    "        #set local model weight to the weight of the global model\n",
    "        local_model.set_weights(global_weights)\n",
    "        \n",
    "        #fit local model with client's data\n",
    "        history = local_model.fit(clients_batched[client], epochs=1, verbose=1)\n",
    "        \n",
    "#         get client acc, loss\n",
    "#         print(client)\n",
    "        if(len(client_loss[client])== 0):\n",
    "            client_loss[client] = [history.history['loss'][0]]\n",
    "            client_accuracy[client] = [history.history['binary_accuracy'][0]]\n",
    "            client_frequency[client] = [len(clients_batched[client])]\n",
    "        \n",
    "        else:\n",
    "            client_loss[client] = np.append(client_loss[client], (history.history['loss'][0]))\n",
    "            client_frequency[client] = np.append(client_frequency[client], len(clients_batched[client]))\n",
    "            client_accuracy[client] = np.append(client_accuracy[client], (history.history['binary_accuracy'][0]))\n",
    "        \n",
    "        epoch_freq += len(clients_batched[client])\n",
    "        \n",
    "        print(\"client\", client, \"loss -->\" ,client_loss[client], \"freq->\", client_frequency[client], \"accuracy->\", client_accuracy[client])\n",
    "        \n",
    "        #scale the model weights and add to list\n",
    "        scaling_factor = weight_scalling_factor(clients_batched, client)\n",
    "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "        scaled_local_weight_list.append(scaled_weights)\n",
    "        \n",
    "        #clear session to free memory after each communication round\n",
    "        K.clear_session()\n",
    "        \n",
    "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "    \n",
    "    #update global model \n",
    "    global_model.set_weights(average_weights)\n",
    "    \n",
    "    global_freq_list.append(epoch_freq)\n",
    "    epoch_freq = 0\n",
    "    \n",
    "\n",
    "#     test global model and print out metrics after each communications round\n",
    "    for(X_test, Y_test) in test_batched:\n",
    "        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)\n",
    "        global_loss_list.append(global_loss)\n",
    "        global_acc_list.append(global_acc)\n",
    "        \n",
    "        print(\"global_loss_list: \", global_loss_list )\n",
    "        print(\"global_acc_list: \", global_acc_list )\n",
    "        print(\"global_freq_list: \", global_freq_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2208b3c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats \n",
    "\n",
    "pdfs = []\n",
    "for i in list(client_accuracy.keys()):\n",
    "    print(\"client_\",i, \" loss: \", client_loss[i],\"freq: \", client_frequency[i], \"acc\", client_accuracy[i])\n",
    "    \n",
    "#     norm\n",
    "#     mean, std = stats.norm.fit(client_loss[i])\n",
    "#     pdf =  stats.norm.pdf(client_loss[i], mean, std)\n",
    "\n",
    "#     df_mean = np.mean(client_frequency[i])\n",
    "#     df_std = np.std(client_frequency[i])\n",
    "#     pdf = stats.norm.pdf(client_frequency[i], df_mean, df_std)\n",
    "    \n",
    "#     lognorm\n",
    "#     shape, loc, scale = stats.lognorm.fit(client_loss[i])\n",
    "#     pdf = stats.lognorm.pdf(client_loss[i], shape, loc, scale)\n",
    "\n",
    "#     beta\n",
    "#     beta_params = stats.beta.fit(client_loss[i])\n",
    "#     pdf = stats.beta.pdf(client_loss[i], beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "\n",
    "#     burr\n",
    "#     burr_params = stats.burr.fit(client_loss[i])\n",
    "#     pdf = stats.burr.pdf(client_loss[i], burr_params[0], burr_params[1], burr_params[2], burr_params[3])\n",
    "\n",
    "    \n",
    "#  gamma\n",
    "#     shape, loc, scale = stats.gamma.fit(client_loss[i])\n",
    "#     pdf = stats.gamma.pdf(client_loss[i], shape, loc=loc, scale=scale)\n",
    "    \n",
    "    pdfs.append(pdf)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    ax = sns.displot( x = pdf, kind = \"kde\", height=10, aspect=2,\n",
    "                linewidth = 5 )\n",
    "    plt.ylabel(\"Frequency\")\n",
    "#     plt.xlabel(\"Loss\")\n",
    "    plt.xlabel(\"Accuracy\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "739fe197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_ 0  freq:  [154 173 193 212 231 250 270 289 308 327]\n",
      "client_ 1  freq:  [12 13 15 16 17 19 20 22 23 24]\n",
      "client_ 2  freq:  [1148 1291 1435 1578 1722 1865 2009 2152 2295 2439]\n",
      "client_ 3  freq:  [214 241 268 294 321 348 375 401 428 455]\n",
      "client_ 4  freq:  [ 900 1013 1125 1238 1350 1463 1575 1688 1800 1913]\n",
      "client_ 5  freq:  [42 47 52 57 62 68 73 78 83 88]\n",
      "client_ 6  freq:  [1921 2168 2415 2661 2908 3154 3401 3647 3894 4140]\n",
      "client_ 7  freq:  [1504 1529 1553 1577 1602 1626 1650 1675 1699 1724]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats \n",
    "\n",
    "for i in list(client_accuracy.keys()):\n",
    "#     print(\"client_\",i, \"\\nloss: \", client_loss[i],\"\\nfreq: \", client_frequency[i], \"\\nacc\", client_accuracy[i])\n",
    "    print(\"client_\",i, \" freq: \", client_frequency[i])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80cb1f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_GAMMA_\n",
      "ACCURACY\n",
      "0  and  1 3.5001817549856585e+23\n",
      "0  and  2 7869143271.861214\n",
      "0  and  3 357034.07862304547\n",
      "0  and  4 518126.9362475103\n",
      "0  and  5 165104.89760287738\n",
      "0  and  6 19103681246.857594\n",
      "0  and  7 392016643.4018573\n",
      "1  and  2 3.50018175498558e+23\n",
      "1  and  3 3.5001817549856585e+23\n",
      "1  and  4 3.5001817549856585e+23\n",
      "1  and  5 3.5001817549856585e+23\n",
      "1  and  6 3.500181754985467e+23\n",
      "1  and  7 3.500181754985655e+23\n",
      "2  and  3 7868786239.209446\n",
      "2  and  4 7868625147.615849\n",
      "2  and  5 7869231109.581604\n",
      "2  and  6 11234537976.059536\n",
      "2  and  7 7477126628.530401\n",
      "3  and  4 161100.1784975285\n",
      "3  and  5 444871.7990126755\n",
      "3  and  6 19103324215.268982\n",
      "3  and  7 391659611.30970186\n",
      "4  and  5 605962.197813923\n",
      "4  and  6 19103163122.99236\n",
      "4  and  7 391498519.3510584\n",
      "5  and  6 19103769084.577984\n",
      "5  and  7 392104481.1222469\n",
      "6  and  7 18711664603.959282\n",
      "0  and global:  41259533824.28781\n",
      "1  and global:  3.5001817549852465e+23\n",
      "2  and global:  33390390564.280167\n",
      "3  and global:  41259176803.48961\n",
      "4  and global:  41259015707.19073\n",
      "5  and global:  41259621663.250084\n",
      "6  and global:  22155852588.220627\n",
      "7  and global:  40867517192.17992\n",
      "LOSS\n",
      "0  and  1 0.22051657214227194\n",
      "0  and  2 14774694.28399596\n",
      "0  and  3 4717296587.966944\n",
      "0  and  4 1661033.0837199779\n",
      "0  and  5 0.1598046861121252\n",
      "0  and  6 31.63787434757529\n",
      "0  and  7 4686093.701512583\n",
      "1  and  2 14774694.504512532\n",
      "1  and  3 4717296588.187131\n",
      "1  and  4 1661033.0432750282\n",
      "1  and  5 0.06072497058341592\n",
      "1  and  6 31.858060977126417\n",
      "1  and  7 4686093.921699212\n",
      "2  and  3 4702521897.798205\n",
      "2  and  4 13113661.556582669\n",
      "2  and  5 14774694.443800645\n",
      "2  and  6 14774665.688301405\n",
      "2  and  7 10088608.07593358\n",
      "3  and  4 4715635555.235035\n",
      "3  and  5 4717296588.126406\n",
      "3  and  6 4717296562.071834\n",
      "3  and  7 4712610502.249417\n",
      "4  and  5 1661033.0135691038\n",
      "4  and  6 1661030.5133884917\n",
      "4  and  7 3025060.9600235075\n",
      "5  and  6 31.797336006543002\n",
      "5  and  7 4686093.860974241\n",
      "6  and  7 4686063.665686254\n",
      "0  and global:  7654705523.434952\n",
      "1  and global:  7654705523.655138\n",
      "2  and global:  7639930862.044109\n",
      "3  and global:  2937408981.9449573\n",
      "4  and global:  7653044490.611863\n",
      "5  and global:  7654705523.594413\n",
      "6  and global:  7654705517.384555\n",
      "7  and global:  7650019469.851103\n",
      "FREQUENCY\n",
      "0  and  1 0.061555536385285624\n",
      "0  and  2 0.0041382116829178405\n",
      "0  and  3 0.0013400631914867798\n",
      "0  and  4 0.003961905318923298\n",
      "0  and  5 0.013010983461184001\n",
      "0  and  6 0.004406344593409131\n",
      "0  and  7 0.00100519614650254\n",
      "1  and  2 0.06569374806820347\n",
      "1  and  3 0.0628955995767724\n",
      "1  and  4 0.06551744170420892\n",
      "1  and  5 0.048544552924101626\n",
      "1  and  6 0.06596188097869476\n",
      "1  and  7 0.06256073253178818\n",
      "2  and  3 0.0027981484914310598\n",
      "2  and  4 0.00017630636399454234\n",
      "2  and  5 0.01714919514410184\n",
      "2  and  6 0.0002681329104912907\n",
      "2  and  7 0.0031330155364153\n",
      "3  and  4 0.002621842127436518\n",
      "3  and  5 0.014351046652670783\n",
      "3  and  6 0.00306628140192235\n",
      "3  and  7 0.00033486704498423994\n",
      "4  and  5 0.016972888780107297\n",
      "4  and  6 0.0004444392744858331\n",
      "4  and  7 0.002956709172420758\n",
      "5  and  6 0.017417328054593128\n",
      "5  and  7 0.014016179607686542\n",
      "6  and  7 0.003401148446906591\n",
      "0  and global:  0.004620694721391866\n",
      "1  and global:  0.0661762311066775\n",
      "2  and global:  0.00048248303847402575\n",
      "3  and global:  0.0032806315299050855\n",
      "4  and global:  0.000658789402468568\n",
      "5  and global:  0.017631678182575862\n",
      "6  and global:  0.00021435012798273496\n",
      "7  and global:  0.003615498574889326\n"
     ]
    }
   ],
   "source": [
    "print(\"_GAMMA_\")\n",
    "\n",
    "pdfs_loss_gamma = []\n",
    "pdfs_acc_gamma = []\n",
    "pdfs_freq_gamma = []\n",
    "for i in list(client_accuracy.keys()):\n",
    "#     print(\"client_\",i, \"\\nloss: \", client_loss[i],\"\\nfreq: \", client_frequency[i], \"\\nacc\", client_accuracy[i])\n",
    "\n",
    "    shape, loc, scale = stats.gamma.fit(client_loss[i])\n",
    "    pdf_loss_gamma =  stats.gamma.pdf(client_loss[i], shape, loc, scale)\n",
    "    pdfs_loss_gamma.append(pdf_loss_gamma)\n",
    "\n",
    "    shape, loc, scale= stats.gamma.fit(client_accuracy[i])\n",
    "    pdf_acc_gamma = stats.gamma.pdf(client_accuracy[i],shape, loc, scale)\n",
    "    pdfs_acc_gamma.append(pdf_acc_gamma)\n",
    "\n",
    "    shape, loc, scale  = stats.gamma.fit(client_frequency[i])\n",
    "    pdf_freq_gamma = stats.gamma.pdf(client_frequency[i],shape, loc, scale )\n",
    "    pdfs_freq_gamma.append(pdf_freq_gamma)\n",
    "\n",
    "\n",
    "print(\"ACCURACY\")\n",
    "for i in range(len(pdfs_acc_gamma)):\n",
    "    for j in range(i+1,len(pdfs_acc_gamma)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_acc_gamma[i], pdfs_acc_gamma[j]))\n",
    "\n",
    "\n",
    "shape, loc, scale = stats.gamma.fit(global_acc_list)\n",
    "pdf_global_acc_gamma =  stats.gamma.pdf(global_acc_list, shape, loc, scale)\n",
    "\n",
    "for i in range(len(pdfs_acc_gamma)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_acc_gamma[i], pdf_global_acc_gamma))\n",
    "\n",
    "print(\"LOSS\")\n",
    "for i in range(len(pdfs_loss_gamma)):\n",
    "    for j in range(i+1,len(pdfs_loss_gamma)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_loss_gamma[i], pdfs_loss_gamma[j]))\n",
    "\n",
    "\n",
    "shape, loc, scale = stats.gamma.fit(global_loss_list)\n",
    "pdf_global_loss_gamma =  stats.gamma.pdf(global_loss_list, shape, loc, scale)\n",
    "\n",
    "for i in range(len(pdfs_loss_gamma)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_loss_gamma[i], pdf_global_loss_gamma))\n",
    "\n",
    "print(\"FREQUENCY\")\n",
    "for i in range(len(pdfs_freq_gamma)):\n",
    "    for j in range(i+1,len(pdfs_freq_gamma)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_freq_gamma[i], pdfs_freq_gamma[j]))\n",
    "\n",
    "\n",
    "shape, loc, scale = stats.gamma.fit(global_freq_list)\n",
    "pdf_global_freq_gamma =  stats.gamma.pdf(global_freq_list,shape, loc, scale)\n",
    "\n",
    "for i in range(len(pdfs_freq_gamma)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_freq_gamma[i], pdf_global_freq_gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30032e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(pdfs_loss_gamma)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_loss_gamma[i], pdf_global_loss_gamma))\n",
    "    M = ot.dist(pdfs_loss_gamma[i], pdf_global_loss_gamma, metric='euclidean')\n",
    "    W = ot.emd2(pdfs_loss_gamma[i], pdf_global_loss_gamma, M)\n",
    "    print(\"actual \", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8c29d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_NORM_\n",
      "ACCURACY\n",
      "0  and  1 0.8325300686638157\n",
      "0  and  2 10.459736423104237\n",
      "0  and  3 1.698031063319809\n",
      "0  and  4 0.6592378845059876\n",
      "0  and  5 0.42290213571143564\n",
      "0  and  6 18.528715177097837\n",
      "0  and  7 13.219825443615902\n",
      "1  and  2 9.627206354440421\n",
      "1  and  3 0.8655009946559932\n",
      "1  and  4 0.32002245930806605\n",
      "1  and  5 0.4096279329523801\n",
      "1  and  6 17.696185108434015\n",
      "1  and  7 12.387295374952084\n",
      "2  and  3 8.761705359784427\n",
      "2  and  4 9.800498538598248\n",
      "2  and  5 10.036834287392804\n",
      "2  and  6 8.068978753993596\n",
      "2  and  7 2.7600890205116646\n",
      "3  and  4 1.0479685475623837\n",
      "3  and  5 1.275128927608373\n",
      "3  and  6 16.830684113778027\n",
      "3  and  7 11.521794380296091\n",
      "4  and  5 0.41552401074085465\n",
      "4  and  6 17.86947729259185\n",
      "4  and  7 12.560587559109912\n",
      "5  and  6 18.105813041386398\n",
      "5  and  7 12.796923307904466\n",
      "6  and  7 5.308889733481931\n",
      "0  and global:  116.55554794469576\n",
      "1  and global:  115.72301787603195\n",
      "2  and global:  106.09581152159153\n",
      "3  and global:  114.85751688137596\n",
      "4  and global:  115.89631006018978\n",
      "5  and global:  116.13264580898432\n",
      "6  and global:  98.02683276759791\n",
      "7  and global:  103.33572250107987\n",
      "LOSS\n",
      "0  and  1 0.2263963719578554\n",
      "0  and  2 2.4129205474004163\n",
      "0  and  3 1.2704907536330314\n",
      "0  and  4 1.4787686693468602\n",
      "0  and  5 0.16566362160853892\n",
      "0  and  6 3.7632501494387287\n",
      "0  and  7 2.9819330218239486\n",
      "1  and  2 2.6393169193582717\n",
      "1  and  3 1.496887125590887\n",
      "1  and  4 1.7051650413047155\n",
      "1  and  5 0.060732750349316474\n",
      "1  and  6 3.9896465213965846\n",
      "1  and  7 3.208329393781804\n",
      "2  and  3 1.1424297937673844\n",
      "2  and  4 0.9375641506137123\n",
      "2  and  5 2.578584169008955\n",
      "2  and  6 1.3503296020383129\n",
      "2  and  7 0.569012474423533\n",
      "3  and  4 0.3000020347142675\n",
      "3  and  5 1.4361543752415704\n",
      "3  and  6 2.492759395805697\n",
      "3  and  7 1.7114422681909174\n",
      "4  and  5 1.6444322909553992\n",
      "4  and  6 2.2844814800918685\n",
      "4  and  7 1.5031643524770888\n",
      "5  and  6 3.9289137710472675\n",
      "5  and  7 3.1475966434324874\n",
      "6  and  7 0.7813171276147799\n",
      "0  and global:  14.191481446599221\n",
      "1  and global:  14.417877818557077\n",
      "2  and global:  11.778560899198805\n",
      "3  and global:  12.92099069296619\n",
      "4  and global:  12.71271277725236\n",
      "5  and global:  14.357145068207759\n",
      "6  and global:  10.428231297160492\n",
      "7  and global:  11.20954842477527\n",
      "FREQUENCY\n",
      "0  and  1 0.06155314818732709\n",
      "0  and  2 0.0041382495420010145\n",
      "0  and  3 0.0013401049330001278\n",
      "0  and  4 0.003961938678467752\n",
      "0  and  5 0.013011209351361921\n",
      "0  and  6 0.004406379243408383\n",
      "0  and  7 0.001005243975558933\n",
      "1  and  2 0.06569139772932811\n",
      "1  and  3 0.06289325312032723\n",
      "1  and  4 0.06551508686579485\n",
      "1  and  5 0.048541938835965165\n",
      "1  and  6 0.06595952743073548\n",
      "1  and  7 0.06255839216288603\n",
      "2  and  3 0.0027981446090008864\n",
      "2  and  4 0.00017631086353326104\n",
      "2  and  5 0.017149458893362935\n",
      "2  and  6 0.0002681297014073686\n",
      "2  and  7 0.0031330055664420815\n",
      "3  and  4 0.002621833745467625\n",
      "3  and  5 0.014351314284362048\n",
      "3  and  6 0.0030662743104082546\n",
      "3  and  7 0.000334860957441195\n",
      "4  and  5 0.01697314802982967\n",
      "4  and  6 0.00044444056494062964\n",
      "4  and  7 0.0029566947029088203\n",
      "5  and  6 0.017417588594770304\n",
      "5  and  7 0.014016453326920853\n",
      "6  and  7 0.0034011352678494497\n",
      "0  and global:  0.0046207285698786765\n",
      "1  and global:  0.06617387675720578\n",
      "2  and global:  0.0004824790278776623\n",
      "3  and global:  0.003280623636878548\n",
      "4  and global:  0.0006587898914109234\n",
      "5  and global:  0.017631937921240598\n",
      "6  and global:  0.0002143493264702938\n",
      "7  and global:  0.003615484594319744\n"
     ]
    }
   ],
   "source": [
    "print(\"_NORM_\")\n",
    "\n",
    "pdfs_loss_norm = []\n",
    "pdfs_acc_norm = []\n",
    "pdfs_freq_norm = []\n",
    "for i in list(client_accuracy.keys()):\n",
    "#     print(\"client_\",i, \" loss: \", client_loss[i],\"freq: \", client_frequency[i], \"acc\", client_accuracy[i])\n",
    "    \n",
    "    mean, std = stats.norm.fit(client_loss[i])\n",
    "    pdf_loss_norm =  stats.norm.pdf(client_loss[i], mean, std)\n",
    "    pdfs_loss_norm.append(pdf_loss_norm)\n",
    "\n",
    "    mean, std = stats.norm.fit(client_accuracy[i])\n",
    "    pdf_acc_norm = stats.norm.pdf(client_accuracy[i],mean, std )\n",
    "    pdfs_acc_norm.append(pdf_acc_norm)\n",
    "    \n",
    "    mean, std  = stats.norm.fit(client_frequency[i])\n",
    "    pdf_freq_norm = stats.norm.pdf(client_frequency[i], mean, std )\n",
    "    pdfs_freq_norm.append(pdf_freq_norm)\n",
    "    \n",
    "    \n",
    "print(\"ACCURACY\")\n",
    "for i in range(len(pdfs_acc_norm)):\n",
    "    for j in range(i+1,len(pdfs_acc_norm)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_acc_norm[i], pdfs_acc_norm[j]))\n",
    "        \n",
    "        \n",
    "mean, std = stats.norm.fit(global_acc_list)\n",
    "pdf_global_acc_norm =  stats.norm.pdf(global_acc_list, mean, std)\n",
    "\n",
    "for i in range(len(pdfs_acc_norm)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_acc_norm[i], pdf_global_acc_norm))\n",
    "    \n",
    "print(\"LOSS\")\n",
    "for i in range(len(pdfs_loss_norm)):\n",
    "    for j in range(i+1,len(pdfs_loss_norm)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_loss_norm[i], pdfs_loss_norm[j]))\n",
    "        \n",
    "        \n",
    "mean, std = stats.norm.fit(global_loss_list)\n",
    "pdf_global_loss_norm =  stats.norm.pdf(global_loss_list, mean, std)\n",
    "\n",
    "for i in range(len(pdfs_loss_norm)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_loss_norm[i], pdf_global_loss_norm))\n",
    "    \n",
    "print(\"FREQUENCY\")\n",
    "for i in range(len(pdfs_freq_norm)):\n",
    "    for j in range(i+1,len(pdfs_freq_norm)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_freq_norm[i], pdfs_freq_norm[j]))\n",
    "        \n",
    "        \n",
    "mean, std = stats.norm.fit(global_freq_list)\n",
    "pdf_global_freq_norm =  stats.norm.pdf(global_freq_list, mean, std)\n",
    "\n",
    "for i in range(len(pdfs_freq_norm)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_freq_norm[i], pdf_global_freq_norm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24a177e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_LOGNORM_\n",
      "ACCURACY\n",
      "0  and  1 6.109867828617498e+18\n",
      "0  and  2 79709480807.47874\n",
      "0  and  3 79709480814.391\n",
      "0  and  4 79709480810.03777\n",
      "0  and  5 1.6971964477274035e+17\n",
      "0  and  6 79709480801.30351\n",
      "0  and  7 79709480805.46625\n",
      "1  and  2 6.10986790832698e+18\n",
      "1  and  3 6.10986790832698e+18\n",
      "1  and  4 6.10986790832698e+18\n",
      "1  and  5 5.940148183844758e+18\n",
      "1  and  6 6.10986790832698e+18\n",
      "1  and  7 6.10986790832698e+18\n",
      "2  and  3 8.798886019579744\n",
      "2  and  4 9.620161192220916\n",
      "2  and  5 1.6971972448222112e+17\n",
      "2  and  6 8.064896234963543\n",
      "2  and  7 2.608621289287474\n",
      "3  and  4 6.763128366138591\n",
      "3  and  5 1.6971972448222112e+17\n",
      "3  and  6 16.863782254543285\n",
      "3  and  7 11.407507308867217\n",
      "4  and  5 1.6971972448222112e+17\n",
      "4  and  6 14.00588899954047\n",
      "4  and  7 11.04412293698373\n",
      "5  and  6 1.6971972448222112e+17\n",
      "5  and  7 1.6971972448222112e+17\n",
      "6  and  7 5.456274945676069\n",
      "0  and global:  79709480793.47607\n",
      "1  and global:  6.10986790832698e+18\n",
      "2  and global:  25.754946932579383\n",
      "3  and global:  34.55383295215913\n",
      "4  and global:  30.170699859880774\n",
      "5  and global:  1.697197244822211e+17\n",
      "6  and global:  17.690050697615845\n",
      "7  and global:  23.14632564329191\n",
      "LOSS\n",
      "0  and  1 0.22680003033273918\n",
      "0  and  2 127642629847.09103\n",
      "0  and  3 283325675686.15894\n",
      "0  and  4 1.4824814062622755\n",
      "0  and  5 0.16340965376444838\n",
      "0  and  6 8451664.432559114\n",
      "0  and  7 356762726052.7163\n",
      "1  and  2 127642629847.27338\n",
      "1  and  3 283325675686.31433\n",
      "1  and  4 1.7092814365950144\n",
      "1  and  5 0.06339136742791164\n",
      "1  and  6 8451664.628246019\n",
      "1  and  7 356762726052.90234\n",
      "2  and  3 155683045839.19888\n",
      "2  and  4 127642629846.15292\n",
      "2  and  5 127642629847.21269\n",
      "2  and  6 127634178217.18904\n",
      "2  and  7 229120096205.629\n",
      "3  and  4 283325675685.34314\n",
      "3  and  5 283325675686.25916\n",
      "3  and  6 283317224035.2745\n",
      "3  and  7 73437050377.60309\n",
      "4  and  5 1.645891060026724\n",
      "4  and  6 8451663.329942504\n",
      "4  and  7 356762726051.67145\n",
      "5  and  6 8451664.564855643\n",
      "5  and  7 356762726052.8389\n",
      "6  and  7 356754274409.2717\n",
      "0  and global:  14.149724143550477\n",
      "1  and global:  14.376524173883215\n",
      "2  and global:  127642629847.19232\n",
      "3  and global:  283325675683.603\n",
      "4  and global:  12.667242737288205\n",
      "5  and global:  14.313133797314926\n",
      "6  and global:  8451658.94373009\n",
      "7  and global:  356762726049.0028\n",
      "FREQUENCY\n",
      "0  and  1 3057067514.6183133\n",
      "0  and  2 6644.163376197016\n",
      "0  and  3 1643282.336807157\n",
      "0  and  4 26728.73118429474\n",
      "0  and  5 172235.6442783698\n",
      "0  and  6 94975.05676701889\n",
      "0  and  7 2661220.4334895806\n",
      "1  and  2 3057060870.462868\n",
      "1  and  3 3055424232.288583\n",
      "1  and  4 3057040785.895042\n",
      "1  and  5 3056895278.9762454\n",
      "1  and  6 3056972539.5695715\n",
      "1  and  7 3054406294.191746\n",
      "2  and  3 1636638.1742856344\n",
      "2  and  4 20084.567826467424\n",
      "2  and  5 165591.48662285908\n",
      "2  and  6 88330.89339082188\n",
      "2  and  7 2654576.2711217343\n",
      "3  and  4 1616553.606459167\n",
      "3  and  5 1471046.6937597056\n",
      "3  and  6 1548307.2809887175\n",
      "3  and  7 1017938.0968360996\n",
      "4  and  5 145506.91879639166\n",
      "4  and  6 68246.32558272415\n",
      "4  and  7 2634491.7032952667\n",
      "5  and  6 77260.59332594191\n",
      "5  and  7 2488984.7904421296\n",
      "6  and  7 2566245.377824817\n",
      "0  and global:  331320.9079630696\n",
      "1  and global:  3056736193.7184424\n",
      "2  and global:  324676.74458687264\n",
      "3  and global:  1311961.4298593567\n",
      "4  and global:  304592.1767787749\n",
      "5  and global:  159085.26491561832\n",
      "6  and global:  236345.85119605073\n",
      "7  and global:  2329899.526695457\n"
     ]
    }
   ],
   "source": [
    "print(\"_LOGNORM_\")\n",
    "\n",
    "pdfs_loss = []\n",
    "pdfs_acc = []\n",
    "pdfs_freq = []\n",
    "for i in list(client_accuracy.keys()):\n",
    "#     print(\"client_\",i, \"\\nloss: \", client_loss[i],\"\\nfreq: \", client_frequency[i], \"\\nacc\", client_accuracy[i])\n",
    "\n",
    "    shape, loc, scale = stats.lognorm.fit(client_loss[i])\n",
    "    pdf_loss =  stats.lognorm.pdf(client_loss[i], shape, loc, scale)\n",
    "    pdfs_loss.append(pdf_loss)\n",
    "\n",
    "    shape, loc, scale= stats.lognorm.fit(client_accuracy[i])\n",
    "    pdf_acc = stats.lognorm.pdf(client_accuracy[i],shape, loc, scale)\n",
    "    pdfs_acc.append(pdf_acc)\n",
    "\n",
    "    shape, loc, scale  = stats.lognorm.fit(client_frequency[i])\n",
    "    pdf_freq = stats.lognorm.pdf(client_frequency[i],shape, loc, scale )\n",
    "    pdfs_freq.append(pdf_freq)\n",
    "\n",
    "\n",
    "print(\"ACCURACY\")\n",
    "for i in range(len(pdfs_acc)):\n",
    "    for j in range(i+1,len(pdfs_acc)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_acc[i], pdfs_acc[j]))\n",
    "\n",
    "\n",
    "shape, loc, scale = stats.lognorm.fit(global_acc_list)\n",
    "pdf_global_acc =  stats.lognorm.pdf(global_acc_list, shape, loc, scale)\n",
    "\n",
    "for i in range(len(pdfs_acc)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_acc[i], pdf_global_acc))\n",
    "\n",
    "print(\"LOSS\")\n",
    "for i in range(len(pdfs_loss)):\n",
    "    for j in range(i+1,len(pdfs_loss)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_loss[i], pdfs_loss[j]))\n",
    "\n",
    "\n",
    "shape, loc, scale = stats.lognorm.fit(global_loss_list)\n",
    "pdf_global_loss =  stats.lognorm.pdf(global_loss_list, shape, loc, scale)\n",
    "\n",
    "for i in range(len(pdfs_loss)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_loss[i], pdf_global_loss))\n",
    "\n",
    "print(\"FREQUENCY\")\n",
    "for i in range(len(pdfs_freq)):\n",
    "    for j in range(i+1,len(pdfs_freq)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_freq[i], pdfs_freq[j]))\n",
    "\n",
    "\n",
    "shape, loc, scale = stats.lognorm.fit(global_freq_list)\n",
    "pdf_global_freq =  stats.lognorm.pdf(global_freq_list,shape, loc, scale)\n",
    "\n",
    "for i in range(len(pdfs_freq)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_freq[i], pdf_global_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10261017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_BETA_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riash\\anaconda3\\lib\\site-packages\\scipy\\stats\\_continuous_distns.py:639: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sk = 2*(b-a)*np.sqrt(a + b + 1) / (a + b + 2) / np.sqrt(a*b)\n",
      "C:\\Users\\riash\\anaconda3\\lib\\site-packages\\scipy\\optimize\\minpack.py:175: RuntimeWarning: The number of calls to function has reached maxfev = 600.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "C:\\Users\\riash\\anaconda3\\lib\\site-packages\\scipy\\optimize\\minpack.py:175: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last five Jacobian evaluations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY\n",
      "0  and  1 7.307236233053098e+28\n",
      "0  and  2 37600461648677.42\n",
      "0  and  3 48198812766773.0\n",
      "0  and  4 48968916937776.31\n",
      "0  and  5 48844505240609.46\n",
      "0  and  6 48978053403745.07\n",
      "0  and  7 44051455739019.99\n",
      "1  and  2 7.307236233053103e+28\n",
      "1  and  3 7.3072362330531045e+28\n",
      "1  and  4 7.307236233053104e+28\n",
      "1  and  5 7.307236233053104e+28\n",
      "1  and  6 7.307236233053104e+28\n",
      "1  and  7 7.307236233053102e+28\n",
      "2  and  3 10598351118113.635\n",
      "2  and  4 11368455289108.766\n",
      "2  and  5 11244043591950.123\n",
      "2  and  6 11377591755067.637\n",
      "2  and  7 6450994090353.064\n",
      "3  and  4 770104171003.5665\n",
      "3  and  5 645692473836.4873\n",
      "3  and  6 779240636972.3181\n",
      "3  and  7 4147357027763.732\n",
      "4  and  5 124411697167.80614\n",
      "4  and  6 9136465968.751783\n",
      "4  and  7 4917461198761.089\n",
      "5  and  6 133548163136.5579\n",
      "5  and  7 4793049501600.219\n",
      "6  and  7 4926597664725.075\n",
      "0  and global:  238239896020545.4\n",
      "1  and global:  7.307236233053075e+28\n",
      "2  and global:  275840357669204.75\n",
      "3  and global:  286438708787318.3\n",
      "4  and global:  287208812958313.2\n",
      "5  and global:  287084401261154.9\n",
      "6  and global:  287217949424196.9\n",
      "7  and global:  282291351759554.6\n",
      "LOSS\n",
      "0  and  1 353086513869.58966\n",
      "0  and  2 625704185007.5367\n",
      "0  and  3 601345396248.4308\n",
      "0  and  4 612308990252.4236\n",
      "0  and  5 170051563451.07916\n",
      "0  and  6 9619369512165.635\n",
      "0  and  7 626150273442.9197\n",
      "1  and  2 272617671156.7146\n",
      "1  and  3 248258882397.76105\n",
      "1  and  4 259222476400.81454\n",
      "1  and  5 183034950419.6448\n",
      "1  and  6 9972456026023.438\n",
      "1  and  7 273063759591.8211\n",
      "2  and  3 24358788759.46\n",
      "2  and  4 13395194756.100967\n",
      "2  and  5 455652621559.27655\n",
      "2  and  6 10245073697172.484\n",
      "2  and  7 446088435.6647787\n",
      "3  and  4 10963594005.57126\n",
      "3  and  5 431293832800.351\n",
      "3  and  6 10220714908413.885\n",
      "3  and  7 24804877195.124775\n",
      "4  and  5 442257426803.36224\n",
      "4  and  6 10231678502416.443\n",
      "4  and  7 13841283191.108635\n",
      "5  and  6 9789421075613.766\n",
      "5  and  7 456098709994.3831\n",
      "6  and  7 10245519785607.215\n",
      "0  and global:  625549346868.8162\n",
      "1  and global:  272462833009.92758\n",
      "2  and global:  154838164.6307743\n",
      "3  and global:  24203950621.944965\n",
      "4  and global:  13240356616.392603\n",
      "5  and global:  455497783417.7913\n",
      "6  and global:  10244918859015.127\n",
      "7  and global:  600926599.3623089\n",
      "FREQUENCY\n",
      "0  and  1 2.220652626228219\n",
      "0  and  2 0.004581367677561024\n",
      "0  and  3 0.0015114701017898443\n",
      "0  and  4 0.1363751875820617\n",
      "0  and  5 0.4612214831003908\n",
      "0  and  6 1.582322789238371\n",
      "0  and  7 0.0016017589952226825\n",
      "1  and  2 2.22523399390578\n",
      "1  and  3 2.222164096330009\n",
      "1  and  4 2.0921404591245185\n",
      "1  and  5 1.7594311431278284\n",
      "1  and  6 0.6479308183370217\n",
      "1  and  7 2.2222543852234415\n",
      "2  and  3 0.003069897575771181\n",
      "2  and  4 0.13309353478126132\n",
      "2  and  5 0.4658028507779518\n",
      "2  and  6 1.577923770185364\n",
      "2  and  7 0.0037003509509938998\n",
      "3  and  4 0.13509929088577144\n",
      "3  and  5 0.46273295320218066\n",
      "3  and  6 1.5808919225642308\n",
      "3  and  7 0.0006908274096867855\n",
      "4  and  5 0.33270931599669057\n",
      "4  and  6 1.4459476016563093\n",
      "4  and  7 0.13574246307004081\n",
      "5  and  6 1.1500988775360375\n",
      "5  and  7 0.4628232420956135\n",
      "6  and  7 1.581569714172193\n",
      "0  and global:  0.005978573520716108\n",
      "1  and global:  2.226631199748935\n",
      "2  and global:  0.0013972058431550838\n",
      "3  and global:  0.0044671034189262635\n",
      "4  and global:  0.13449074062441638\n",
      "5  and global:  0.4672000566211069\n",
      "6  and global:  1.5787003814119134\n",
      "7  and global:  0.004376814525493426\n"
     ]
    }
   ],
   "source": [
    "print(\"_BETA_\")\n",
    "\n",
    "pdfs_loss = []\n",
    "pdfs_acc = []\n",
    "pdfs_freq = []\n",
    "for i in list(client_accuracy.keys()):\n",
    "\n",
    "    beta_params = stats.beta.fit(client_loss[i])\n",
    "    pdf_loss =  stats.beta.pdf(client_loss[i],beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "    pdfs_loss.append(pdf_loss)\n",
    "\n",
    "    beta_params = stats.beta.fit(client_accuracy[i])\n",
    "    pdf_acc = stats.beta.pdf(client_accuracy[i],beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "    pdfs_acc.append(pdf_acc)\n",
    "\n",
    "    beta_params  = stats.beta.fit(client_frequency[i])\n",
    "    pdf_freq = stats.beta.pdf(client_frequency[i],beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "    pdfs_freq.append(pdf_freq)\n",
    "\n",
    "\n",
    "print(\"ACCURACY\")\n",
    "for i in range(len(pdfs_acc)):\n",
    "    for j in range(i+1,len(pdfs_acc)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_acc[i], pdfs_acc[j]))\n",
    "\n",
    "\n",
    "beta_params = stats.beta.fit(global_acc_list)\n",
    "pdf_global_acc =  stats.beta.pdf(global_acc_list, beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "\n",
    "for i in range(len(pdfs_acc)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_acc[i], pdf_global_acc))\n",
    "\n",
    "print(\"LOSS\")\n",
    "for i in range(len(pdfs_loss)):\n",
    "    for j in range(i+1,len(pdfs_loss)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_loss[i], pdfs_loss[j]))\n",
    "\n",
    "\n",
    "beta_params = stats.beta.fit(global_loss_list)\n",
    "pdf_global_loss =  stats.beta.pdf(global_loss_list, beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "\n",
    "for i in range(len(pdfs_loss)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_loss[i], pdf_global_loss))\n",
    "\n",
    "print(\"FREQUENCY\")\n",
    "for i in range(len(pdfs_freq)):\n",
    "    for j in range(i+1,len(pdfs_freq)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_freq[i], pdfs_freq[j]))\n",
    "\n",
    "\n",
    "beta_params = stats.beta.fit(global_freq_list)\n",
    "pdf_global_freq =  stats.beta.pdf(global_freq_list,beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "\n",
    "for i in range(len(pdfs_freq)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_freq[i], pdf_global_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca3cc154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_BURR_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riash\\anaconda3\\lib\\site-packages\\scipy\\stats\\_continuous_distns.py:942: RuntimeWarning: overflow encountered in power\n",
      "  - sc.xlog1py(d_+1, x_**(-c_))))\n",
      "C:\\Users\\riash\\anaconda3\\lib\\site-packages\\scipy\\stats\\_continuous_distns.py:929: RuntimeWarning: overflow encountered in power\n",
      "  f2 = lambda x_, c_, d_: (c_ * d_ * (x_ ** (-c_ - 1.0)) /\n",
      "C:\\Users\\riash\\anaconda3\\lib\\site-packages\\scipy\\stats\\_continuous_distns.py:930: RuntimeWarning: overflow encountered in power\n",
      "  ((1 + x_ ** (-c_)) ** (d_ + 1.0))))\n",
      "C:\\Users\\riash\\anaconda3\\lib\\site-packages\\scipy\\stats\\_continuous_distns.py:929: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f2 = lambda x_, c_, d_: (c_ * d_ * (x_ ** (-c_ - 1.0)) /\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY\n",
      "0  and  1 9.632467572128582e+27\n",
      "0  and  2 41444361615586.05\n",
      "0  and  3 41444361615596.75\n",
      "0  and  4 41444361615607.33\n",
      "0  and  5 4.481935523269599e+19\n",
      "0  and  6 41444361615584.23\n",
      "0  and  7 41444361615585.336\n",
      "1  and  2 9.632467572128622e+27\n",
      "1  and  3 9.632467572128622e+27\n",
      "1  and  4 9.632467572128622e+27\n",
      "1  and  5 9.632467527309225e+27\n",
      "1  and  6 9.632467572128622e+27\n",
      "1  and  7 9.632467572128622e+27\n",
      "2  and  3 17.405240826672046\n",
      "2  and  4 30.113678715951945\n",
      "2  and  5 4.481939667705761e+19\n",
      "2  and  6 6.109357347514156\n",
      "2  and  7 2.644867905478688\n",
      "3  and  4 12.724712292977225\n",
      "3  and  5 4.481939667705761e+19\n",
      "3  and  6 23.5145981741862\n",
      "3  and  7 20.050108732150733\n",
      "4  and  5 4.481939667705761e+19\n",
      "4  and  6 36.20399101750616\n",
      "4  and  7 32.74869276729836\n",
      "5  and  6 4.481939667705761e+19\n",
      "5  and  7 4.481939667705761e+19\n",
      "6  and  7 3.4644894420354695\n",
      "0  and global:  41444361615583.23\n",
      "1  and global:  9.632467572128622e+27\n",
      "2  and global:  18.88400310048125\n",
      "3  and global:  36.2892439271533\n",
      "4  and global:  48.97863677047325\n",
      "5  and global:  4.481939667705761e+19\n",
      "6  and global:  12.774645752967094\n",
      "7  and global:  16.239135195002564\n",
      "LOSS\n",
      "0  and  1 nan\n",
      "0  and  2 nan\n",
      "0  and  3 nan\n",
      "0  and  4 nan\n",
      "0  and  5 nan\n",
      "0  and  6 nan\n",
      "0  and  7 nan\n",
      "1  and  2 nan\n",
      "1  and  3 nan\n",
      "1  and  4 nan\n",
      "1  and  5 nan\n",
      "1  and  6 nan\n",
      "1  and  7 nan\n",
      "2  and  3 782038.2021019952\n",
      "2  and  4 57506.06774511564\n",
      "2  and  5 57507.474677920385\n",
      "2  and  6 57493.267578002036\n",
      "2  and  7 29269.100591399332\n",
      "3  and  4 839533.6420631084\n",
      "3  and  5 839534.5676024959\n",
      "3  and  6 839506.9687639928\n",
      "3  and  7 811282.6256697116\n",
      "4  and  5 1.6507194556933353\n",
      "4  and  6 58.50867120462314\n",
      "4  and  7 28317.212255846658\n",
      "5  and  6 60.01442353468633\n",
      "5  and  7 28318.542849606303\n",
      "6  and  7 28259.755804628818\n",
      "0  and global:  nan\n",
      "1  and global:  nan\n",
      "2  and global:  57498.250617960235\n",
      "3  and global:  839530.5720602596\n",
      "4  and global:  16.234427795312904\n",
      "5  and global:  17.88514725100624\n",
      "6  and global:  47.140566428665224\n",
      "7  and global:  28306.207042509108\n",
      "FREQUENCY\n",
      "0  and  1 0.0687238736146832\n",
      "0  and  2 0.0038440424886690577\n",
      "0  and  3 0.001160969409141201\n",
      "0  and  4 0.00367676196969297\n",
      "0  and  5 0.012969043801782994\n",
      "0  and  6 0.0041010915149884775\n",
      "0  and  7 0.0007704665972037736\n",
      "1  and  2 0.07256791610335224\n",
      "1  and  3 0.06988484302382439\n",
      "1  and  4 0.07240063558437616\n",
      "1  and  5 0.0557548298129002\n",
      "1  and  6 0.07282496512967165\n",
      "1  and  7 0.06949434021188697\n",
      "2  and  3 0.002683073079527857\n",
      "2  and  4 0.00016728051897608721\n",
      "2  and  5 0.016813086290452046\n",
      "2  and  6 0.00025704902631942\n",
      "2  and  7 0.0030735758914652842\n",
      "3  and  4 0.0025157925605517697\n",
      "3  and  5 0.014130013210924193\n",
      "3  and  6 0.002940122105847277\n",
      "3  and  7 0.0003958053079826416\n",
      "4  and  5 0.01664580577147596\n",
      "4  and  6 0.0004243295452955072\n",
      "4  and  7 0.002906295372489197\n",
      "5  and  6 0.017070135316771467\n",
      "5  and  7 0.013739510398986767\n",
      "6  and  7 0.0033306249177847045\n",
      "0  and global:  0.004305008337911491\n",
      "1  and global:  0.07302888195259467\n",
      "2  and global:  0.00046096584924243286\n",
      "3  and global:  0.00314403892877029\n",
      "4  and global:  0.0006282463682185201\n",
      "5  and global:  0.01727405213969448\n",
      "6  and global:  0.0002039168229230128\n",
      "7  and global:  0.0035345417407077174\n"
     ]
    }
   ],
   "source": [
    "print(\"_BURR_\")\n",
    "\n",
    "pdfs_loss = []\n",
    "pdfs_acc = []\n",
    "pdfs_freq = []\n",
    "for i in list(client_accuracy.keys()):\n",
    "\n",
    "    params = stats.burr.fit(client_loss[i])\n",
    "    pdf_loss =  stats.burr.pdf(client_loss[i],params[0], params[1], params[2], params[3])\n",
    "    pdfs_loss.append(pdf_loss)\n",
    "\n",
    "    beta_params = stats.burr.fit(client_accuracy[i])\n",
    "    pdf_acc = stats.burr.pdf(client_accuracy[i],beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "    pdfs_acc.append(pdf_acc)\n",
    "\n",
    "    beta_params  = stats.burr.fit(client_frequency[i])\n",
    "    pdf_freq = stats.burr.pdf(client_frequency[i],beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "    pdfs_freq.append(pdf_freq)\n",
    "\n",
    "\n",
    "print(\"ACCURACY\")\n",
    "for i in range(len(pdfs_acc)):\n",
    "    for j in range(i+1,len(pdfs_acc)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_acc[i], pdfs_acc[j]))\n",
    "\n",
    "\n",
    "beta_params = stats.burr.fit(global_acc_list)\n",
    "pdf_global_acc =  stats.burr.pdf(global_acc_list, beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "\n",
    "for i in range(len(pdfs_acc)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_acc[i], pdf_global_acc))\n",
    "\n",
    "print(\"LOSS\")\n",
    "for i in range(len(pdfs_loss)):\n",
    "    for j in range(i+1,len(pdfs_loss)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_loss[i], pdfs_loss[j]))\n",
    "\n",
    "\n",
    "beta_params = stats.burr.fit(global_loss_list)\n",
    "pdf_global_loss =  stats.burr.pdf(global_loss_list, beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "\n",
    "for i in range(len(pdfs_loss)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_loss[i], pdf_global_loss))\n",
    "\n",
    "print(\"FREQUENCY\")\n",
    "for i in range(len(pdfs_freq)):\n",
    "    for j in range(i+1,len(pdfs_freq)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs_freq[i], pdfs_freq[j]))\n",
    "\n",
    "\n",
    "beta_params = stats.burr.fit(global_freq_list)\n",
    "pdf_global_freq =  stats.burr.pdf(global_freq_list,beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "\n",
    "for i in range(len(pdfs_freq)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs_freq[i], pdf_global_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd01c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(client_loss.keys()):\n",
    "#     if(i== len(list(client_loss.keys()))-1):\n",
    "#         continue\n",
    "    print(\"client_\",i, \"loss: \", client_loss[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650336b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(client_loss.keys()):\n",
    "#     if(i== len(list(client_loss.keys()))-1):\n",
    "#         continue\n",
    "    print(\"client_\",i, \"freq: \", client_frequency[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a70793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdfs)):\n",
    "    for j in range(i+1,len(pdfs)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs[i], pdfs[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2620a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gamma\n",
    "shape, loc, scale = stats.gamma.fit(global_freq_list)\n",
    "pdf_global = stats.gamma.pdf(global_freq_list, shape, loc=loc, scale=scale)\n",
    "\n",
    "# df_mean = np.mean(global_loss_list)\n",
    "# df_std = np.std(global_loss_list)\n",
    "# pdf_global = stats.norm.pdf(global_loss_list, df_mean, df_std)\n",
    "\n",
    "# mean, std = stats.norm.fit(global_freq_list)\n",
    "# pdf_global =  stats.norm.pdf(global_freq_list, mean, std)\n",
    "\n",
    "# lognorm\n",
    "# shape, loc, scale = stats.lognorm.fit(global_loss_list)\n",
    "# pdf_global = stats.lognorm.pdf(global_loss_list, shape, loc, scale)\n",
    "\n",
    "# global_acc_list\n",
    "# global_freq_list\n",
    "\n",
    "# burr\n",
    "# burr_params = stats.beta.fit(global_freq_list)\n",
    "# pdf_global = stats.beta.pdf(global_freq_list, burr_params[0], burr_params[1], burr_params[2], burr_params[3])\n",
    "\n",
    "for i in range(len(pdfs)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs[i], pdf_global))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de13219",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8879a3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fitter import Fitter, get_common_distributions, get_distributions\n",
    "\n",
    "# for i in list(client_loss.keys()):\n",
    "#     height = client_loss[i]\n",
    "\n",
    "#     f = Fitter(height,\n",
    "#                distributions=['gamma',\n",
    "#                               'lognorm',\n",
    "#                               \"beta\",\n",
    "#                               \"burr\",\n",
    "#                               \"norm\"])\n",
    "#     f.fit()\n",
    "#     f.summary()\n",
    "\n",
    "#     sns.set_style('white')\n",
    "#     sns.set_context(\"paper\", font_scale = 2)\n",
    "#     sns.displot(data=dataset, x=\"Height\", kind=\"hist\", bins = 100, aspect = 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93def9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 clients---> gender, race, income\n",
    "pdfs = []\n",
    "for i in list(client_loss.keys()):\n",
    "    if(i== len(list(client_loss.keys()))-1):\n",
    "        continue\n",
    "    print(\"client_\",i, \" loss: \", client_loss[i],\"freq: \", client_frequency[i])\n",
    "\n",
    "#     shape, loc, scale = stats.gamma.fit(client_loss[i])\n",
    "    \n",
    "#     # Printing the estimated parameters\n",
    "#     print(\"Shape:\", shape)\n",
    "#     print(\"Location:\", loc)\n",
    "#     print(\"Scale:\", scale)\n",
    "#     pdf = stats.gamma.pdf(client_loss[i], shape, loc=loc, scale=scale)\n",
    "    \n",
    "    \n",
    "    df_mean = np.mean(client_loss[i])\n",
    "    df_std = np.std(client_loss[i])\n",
    "    pdf = stats.norm.pdf(client_loss[i], df_mean, df_std)\n",
    "    pdfs.append(pdf)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    ax = sns.displot( x = pdf, kind = \"kde\", height=10, aspect=2,\n",
    "                linewidth = 5 )\n",
    "    ax.fig.suptitle('Original distribution', size = 20)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xlabel(\"Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c9992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdfs)):\n",
    "    for j in range(i+1,len(pdfs)):\n",
    "        print(i,\" and \", j , stats.wasserstein_distance(pdfs[i], pdfs[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bbbe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape, loc, scale = stats.gamma.fit(global_loss_list)\n",
    "pdf_global = stats.gamma.pdf(global_loss_list, shape, loc=loc, scale=scale)\n",
    "\n",
    "for i in range(len(pdfs)):\n",
    "    print(i,\" and global: \" , stats.wasserstein_distance(pdfs[i], pdf_global))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d36ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment plotter\n",
    "\n",
    "# for i in list(client_loss.keys()):\n",
    "#     if(i== len(list(client_loss.keys()))-1):\n",
    "#         continue\n",
    "#     print(\"client_\",i, \" loss: \", client_loss[i],\"freq: \", client_frequency[i])\n",
    "    \n",
    "# #     df_mean = np.mean(client_loss[i])\n",
    "# #     df_std = np.std(client_loss[i])\n",
    "# #     pdf = stats.norm.pdf(client_loss[i], df_mean, df_std)\n",
    "\n",
    "#     shape, loc, scale = stats.gamma.fit(client_loss[i])\n",
    "    \n",
    "#     # Printing the estimated parameters\n",
    "# #     print(\"Shape:\", shape)\n",
    "# #     print(\"Location:\", loc)\n",
    "# #     print(\"Scale:\", scale)\n",
    "#     pdf = stats.gamma.pdf(client_loss[i], shape, loc=loc, scale=scale)\n",
    "\n",
    "# #     plt.plot(client_loss[i], pdf, \"-o\", label = i)\n",
    "\n",
    "# #     client_loss[i] = stats.gamma.rvs(1, size=5000)+5\n",
    "#     sns.set_style(\"whitegrid\")\n",
    "\n",
    "#     ax = sns.displot( x = pdf, kind = \"kde\", height=10, aspect=2,\n",
    "#                 linewidth = 5 )\n",
    "#     ax.fig.suptitle('Original distribution', size = 20)\n",
    "# #     plt.plot(client_loss[i], client_frequency[i], \"-o\", label = i)\n",
    "# #     plt.legend()\n",
    "#     plt.ylabel(\"Frequency\")\n",
    "#     plt.xlabel(\"Loss\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670d1d42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:03:08.033027Z",
     "start_time": "2021-07-16T00:03:07.867893Z"
    }
   },
   "outputs": [],
   "source": [
    "score = global_model.evaluate(X_test, y_test, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcaa73e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:03:08.653744Z",
     "start_time": "2021-07-16T00:03:08.484057Z"
    }
   },
   "outputs": [],
   "source": [
    "nn_preds = global_model.predict(X_test)\n",
    "nn_preds = (nn_preds > 0.5)\n",
    "\n",
    "nn_precision =precision_score(y_test, nn_preds)\n",
    "nn_recall = recall_score(y_test, nn_preds)\n",
    "nn_accuracy = accuracy_score(y_test, nn_preds)\n",
    "nn_f1 = f1_score(y_test, nn_preds)\n",
    "\n",
    "\n",
    "print(\"Precision = {}\".format(nn_precision))\n",
    "print(\"Recall = {}\".format(nn_recall))\n",
    "print(\"Accuracy = {}\".format(nn_accuracy))\n",
    "print(\"f1 = {}\".format(nn_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6360dd5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:03:09.275052Z",
     "start_time": "2021-07-16T00:03:09.268152Z"
    }
   },
   "outputs": [],
   "source": [
    "arr = nn_preds > 0.5\n",
    "\n",
    "unique, counts = np.unique(arr, return_counts=True)\n",
    "\n",
    "np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a5ee99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T19:56:25.650336Z",
     "start_time": "2021-07-14T19:56:25.620Z"
    }
   },
   "outputs": [],
   "source": [
    "# pdf for client losses\n",
    "# x-loss\n",
    "# y- frequency\n",
    "# each client has one pdf for all rounds\n",
    "# using histogram\n",
    "\n",
    "\n",
    "# drop client\n",
    "# non iid\n",
    "# fedavg\n",
    "\n",
    "\n",
    "# gender dist\n",
    "# kernel density\n",
    "\n",
    "\n",
    "# non-iid, loss to accuracy\n",
    "# 4client"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
